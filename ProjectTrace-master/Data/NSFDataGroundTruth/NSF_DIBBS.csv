"AwardNumber","Title","NSFOrganization","Program(s)","StartDate","LastAmendmentDate","PrincipalInvestigator","State","Organization","AwardInstrument","ProgramManager","EndDate","AwardedAmountToDate","Co-PIName(s)","PIEmailAddress","OrganizationStreet","OrganizationCity","OrganizationState","OrganizationZip","OrganizationPhone","NSFDirectorate","ProgramElementCode(s)","ProgramReferenceCode(s)","ARRAAmount","Abstract"
"1724889","CIF21 DIBBs: PD: Enhancing and Personalizing Educational Resources through Tools for Experimentation","OAC","Data Cyberinfrastructure, ECR-EDU Core Research","07/01/2017","01/16/2020","Neil Heffernan","MA","Worcester Polytechnic Institute","Standard Grant","Amy Walton","06/30/2021","$544,644.00","Joseph Williams, Korinn Ostrow, Anthony Botelho","nth@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7726, 7980","7218, 7433, 8048, 8083","$0.00","This project would automate the creation and data analysis of randomized controlled experiments (RCEs).   RCEs are question sets designed and delivered to teachers and students in a classroom setting, and can be used to compare alternative educational strategies. This effort builds on an existing educational platform (ASSISTments) developed by the Principal Investigator, and uses a template-based approach to increase the efficiency and reliability of conducting educational research.  The goal is to lower the barriers to creating and learning from randomized controlled experiments. The project has the potential to facilitate large-scale learning in education research, reaching hundreds of schools and thousands of students.<br/><br/>The project builds upon two prior developments by this team.  <br/>  -  ASSISTments is an online learning platform originally designed to provide students with assistance and teachers with assessments (establishing the moniker).  The system is used primarily as an online tutoring system for middle or secondary education, supporting the delivery, collection, and grading of classwork and homework, providing immediate feedback for students and explicit reporting for teachers.  To date, 24 randomized controlled experiments comparing educational strategies have been published using this platform.  <br/>  -  In addition, AssistmentsTestBed.org is a testbed developed by the PI and his group under a separate NSF grant (#1440753), to identify best practices in education and allow other researchers to propose and run their own studies leveraging ASSISTments as a shared scientific instrument through this testbed.  Beneficiaries include education researchers, teachers, and students, with the existing tool being used in over 500 schools and in the education of over 50,000 students.  <br/>The current project improves two components of the infrastructure that have been resource-intensive bottlenecks in prior research.    One task automates the process of study creation and data analysis, through development of a Template Tool that enables studies within ASSISTments.  A second task automates statistical analyses and improves usability of the existing data reporting tool (Assessment of Learning Infrastructure, or ALI).  The improvements will be achieved, in part, by applying educational data mining algorithms (i.e., deep knowledge tracing) on student data collected before, during, and after experimentation.  These analytics will provide researchers with covariates that will significantly improve the agenda of personalizing education.  The resulting capability will assist researchers as they design and deliver question sets to teachers and students in a classroom setting, increase the efficiency and reliability of conducting educational research at scale, and streamline the research processes.<br/><br/>This award by the Office of Advanced Cyberinfrastructure is jointly supported by the NSF Directorate for Education and Human Resources, Division of Research on Learning in Formal and Informal Settings."
"1443019","CIF21 DIBBs: DIBBs for Intelligence and Security Informatics Research Community","OAC","Data Cyberinfrastructure, Cybersecurity Innovation","10/15/2014","09/08/2014","Hsinchun Chen","AZ","University of Arizona","Standard Grant","Amy Walton","09/30/2019","$1,499,531.00","Mark Patton, Catherine Larson","hchen@eller.arizona.edu","888 N EUCLID AVE RM 510","TUCSON","AZ","857194824","5206266000","CSE","7726, 8027","7433, 7434, 7726, 8027, 8048","$0.00","The growing number of cyber attacks on the Internet and other critical infrastructure has led to an increased sense of urgency in developing a better understanding of the motivation and methods behind such incursions. This project develops a research infrastructure for the Intelligence and Security Informatics (ISI) community comprised of experts across the computer, information, and social sciences. <br/><br/>The infrastructure consists of online archives and analysis tools. The archives contain a wide array of open source data including: discussions in online forums run by hackers, data from botnet command and control servers used to stage computer attacks, video streams and tweets and news summaries from economically and politically unstable states and regions. The analysis tools developed for this project support a range of research investigations. The social network analysis tool allows researchers to study how organizations form and how people interact with one another both virtually and in person. The data visualization tools are important for helping researchers pick out important patterns and trends in large sets of data of different types and from disparate sources. A new tool for adversarial data mining and deception detection allows researchers to deepen their enquiries and analysis of the intentions behind cyber-attacks. <br/><br/>Integrating these divergent data sources allows the security research community to more easily collaborate with other members of the community, rapidly test hypotheses, evaluate detection techniques, track down malicious actors, and identify weaknesses in a cyberinfrastructure network."
"1443037","CIF21 DIBBs: Collaborative Research: Cyberinfrastructure for Interpreting and Archiving U-series Geochronologic Data","OAC","Paleoclimate, Petrology and Geochemistry, Marine Geology and Geophysics, Data Cyberinfrastructure, EarthCube, EPSCoR Co-Funding","09/01/2014","08/25/2014","James Bowring","SC","College of Charleston","Standard Grant","Amy Walton","08/31/2019","$579,762.00","","bowringj@cofc.edu","66 GEORGE ST","CHARLESTON","SC","294240001","8439534973","CSE","1530, 1573, 1620, 7726, 8074, 9150","4444, 7433, 8048, 9150","$0.00","Uranium-series geochronology plays a critical role in understanding the time-scales and rates of climate change, sea-level change, and volcanic activity.  There are no standardized data-handling protocols or community-based open data archives for raw isotopic data and reduced results. The U-series geochronology community wants to change this and is encouraged by NSF's vision for 21st century cyberinfrastructure.  In this pilot demonstration project, software engineers and geochronologists collaborate to build open-source cyberinfrastructure that standardizes and facilitates U-series data analysis, reporting, and archiving and analysis and re-processing of the vast amounts of legacy data.  The project uses the NSF-funded EarthChem-Geochron data repository that archives results from many dating schemes, stimulating inter-domain sharing and discovery. This cyberinfrastructure supports teaching and training at all levels and provides non-experts access to new knowledge.  <br/><br/>This collaborative effort applies modern software engineering practices to solving the cyberinfrastructure problems of the U-series geochronology community, making the calculation, archiving, access, and interpretation activities of U-series geochronology as rigorous, seamless, and simple as possible.  Currently, isotopic dates from U-series data are calculated and analyzed using legacy, platform-dependent software, and dates are difficult to synthesize because they have been published with disparate decay constants and reporting norms. This pilot project includes new software to calculate, visualize, and interpret U-series dates from new and legacy data, and new schema for data archiving at Geochron.org. Importantly, this project advances the sustainability of NSF's software ecosystem by building upon the cyberinfrastructure architecture already developed for the U-Pb geochronology community under the EARTHTIME umbrella."
"1719477","Cybersecurity Big Data and Analytics Sharing Platform","DGE","Secure &Trustworthy Cyberspace","03/15/2017","03/08/2021","Hsinchun Chen","AZ","University of Arizona","Standard Grant","Li Yang","02/28/2022","$180,000.00","","hchen@eller.arizona.edu","888 N EUCLID AVE RM 510","TUCSON","AZ","857194824","5206266000","EDU","8060","7916","$0.00","Cybersecurity has become a significant issue that presents new challenges to individuals, industry, and government. To help deal with complex cybersecurity challenges, the international Intelligence and Security Informatics (ISI) community has published high-impact, Big Data driven cybersecurity research since 2003. Despite the many novel advances in data-driven cybersecurity research, there is no sharing platform that aggregates and provides data and tools used and developed in cybersecurity research for the larger cybersecurity community. The proposed project aims to fill this gap by developing the Cybersecurity Big Data and Analytics Sharing Platform to encourage cybersecurity researchers to share their data, tools, and analytical approaches. In addition, the project will support two Security Big Data and Analytics Sharing Workshops to engage the community in the platform development. Upon project completion, the platform will be open for access by the broad cybersecurity research and education community.<br/><br/>The proposed data sharing platform would enable the publication of high-impact, reproducible, and cutting edge research to advance scientific discoveries. Such a platform would also enhance the educational experience for cybersecurity students, specifically CyberCorps SFS students as they prepare to enter the cybersecurity workforce. The proposed project will provide value to both cybersecurity researchers and students by providing data for cutting-edge research and enhanced educational experiences. In addition, this project will also have significant value to government agencies and other organizations interested in developing cyber threat intelligence knowledge. The project team will consist of leading scholars in Big Data Security."
"1255781","CIF21 DIBBs: Conceptualization of the Social and Innovation Opportunities of Data Analysis","OAC","Data Cyberinfrastructure","03/15/2013","10/24/2014","Michael Zentner","IN","Purdue University","Standard Grant","Robert Chadduck","05/31/2015","$99,718.00","Michael Beyerlein, Gerhard Klimeck, Michael McLennan, Sabine Brunswicker","mzentner@ucsd.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","CSE","7726","7433, 8048","$0.00","CIF21 DIBBs: Conceptualization of the Social and Innovation Opportunities of Data Analysis<br/>This proposal presents an opportunity to work on the problem that scientists have access to continuously growing data repositories across economic and geographic boundaries. However, both individual innovation and the formation of rich collaborations still rely on traditional research and social mechanisms. While virtual organizations help with access to data environments among groups, members must still proactively seek to collaborate. The difficulty of sharing analysis tools, and the lack of understanding of how such tools are used, create friction that impedes extracting the greatest benefit from data and its usage. If the scientific community can formalize collection of User Data Interaction (UDI) data and develop actionable characteristic behavior patterns from it, the friction can be relieved and scientists can be connected in behaviorally meaningful ways that are not currently imagined. In this proposal is discussed the opportunity for working on the problem. Data is the lifeblood of science. Recent funding opportunities have fueled support for uploading, archiving, and managing data in more formal and standard ways. However, the actual use of data through data exploration tools is still a highly variable process. Interactive data exploration tools provide the opportunity to record researcher interactions during the exploration process. The pattern of interactions such users undertake while searching, exploring, and using data is a largely unexploited opportunity for new connections and new learning that could help researchers identify useful exploration modes or gaps, and even new collaborative partners that could increase interactions and innovation. Such data about how users explore data are here termed, ?User-Data Interaction (UDI) Data.? Creating cyberinfrastructure building blocks to support a standard for collecting UDI Data, community development of data exploration tools, and the exploration of UDI data could fundamentally change the practice of science and engineering. Having such data and analysis tools hosted within a shared cyberinfrastructure could also allow for unprecedented study of their use and effectiveness.<br/>The goal of this conceptualization research will be to define an implementation project for the DIBBs program. To achieve this goal, the approach will be to understand the kinds of data analysis tools that various user communities currently use, those that they would like to create and share, and to explore the ensuing UDI data that could be collected and leveraged. A data source will be characterized as any service into which a user can specify a query and receive a semi-structured result. By way of example, this may include an online database with which users interact through forms, a graphical interface to a data cube, or even an online simulation tool. The proposing team has access to three such toolkits in use by thousands of users today (Rappture Toolkit, iKNEER, and DataView) to study as sources of analysis tools and UDI data. Specifically, access to the developers of these systems will provide information about how such systems could generate UDI data and what its important features may be. Having built an understanding from active communities and small group discussions, the final step of information gathering will be two larger discussions held in conjunction with two events: HUBbub 2013 and an NSF S2I2 conceptualization project meeting. The Intellectual Merit: This research will identify the social and technological roadblocks to sharing data analysis tools, and the transformational potential of UDI data. The intellectual merit of this activity will be an evidence-based blueprint for a cyberinfrastructure environment that will automatically gather UDI data, develop patterns from those data, and facilitate amplified discovery and collaboration based on those patterns in a way that acceptably balances efficacy and privacy. Collaborations will increase and will be of greater substance. Broader Impacts: This work will pave the way for new scientific connections among researchers, educators, and students that will accelerate research and innovation. The difficulties that underrepresented groups inherently face in traditional methods of establishing scientific collaborations will be bridged by an implementation of the proposed work, allowing everyone to connect to tools and other researchers?not solely by established reputation, but based on their interactions with data. Because the work is not specific to one virtual organization or data tool, it will have a broad reach across diverse scientific communities that use data and data analysis tools."
"1261582","CIF21 DIBBs: Brown Dog","OAC","Data Cyberinfrastructure","10/01/2013","04/14/2017","Kenton McHenry","IL","University of Illinois at Urbana-Champaign","Cooperative Agreement","Amy Walton","09/30/2019","$10,519,716.00","Praveen Kumar, Barbara Minsker, Michael Dietze, Jong Lee","kmchenry@ncsa.uiuc.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","CSE","7726","7433, 8048","$0.00","The information age has made it trivial for anyone to create and then share vast amounts of digital data.  This includes unstructured collections made of data such as images, video, and audio to collections of born digital content made up of data such as documents and spreadsheets.  While the creation and sharing of content has been made easy, its inverse, the ability to search and use the contents of digital data, has been made exponentially more difficult.  In the physical analogue librarians have used the process of curation to standardize the format by which information is stored and diligently index holdings with metadata to allow both current and future generations to find information.  Digitally this does not happen as that curation overhead is an unwelcomed bottleneck to the creation of more data.  Though popular services such as modern search engines give the illusion that this is being done, this is largely over the portion of digital data that is text based and/or containing text metadata.  Unstructured collections and contents trapped behind difficult to read file formats, however, make up a significant part of our collective digital data assets and are largely not accessible. <br/>Science today not only uses but relies on software and digital content.  It is well known that science is not only responsible for a significant amount of our digital data holdings but that also much of this is un-curated data, what the scientific community currently refer to as ""long-tail"" data.  As such contemporary science, which relies on digital data and software, software which evolves and disappears quickly as underlying technology changes, is entering a realm where scientific results are no-longer easily reproducible and as such in essence no longer a science as science hinges on the fact that a documented procedure will result in the same result each time."
"1255849","CIF21 DIBBs: Building International Data Sharing Capacity in Lake Sciences, with Implications for the Broader Environmental Science Community","OAC","Data Cyberinfrastructure","07/15/2013","07/11/2013","Corinna Gries","WI","University of Wisconsin-Madison","Standard Grant","Robert Chadduck","06/30/2016","$102,759.00","Kathleen Weathers, Paul Hanson","cgries@wisc.edu","21 N PARK ST STE 6301","MADISON","WI","537151218","6082623822","CSE","7726","7433, 8048","$0.00","CIF21 DIBBs: Building international data sharing capacity in lake sciences, with implications for the broader environmental science community <br/>Environmental research, and science in general, are being transformed by the unprecedented amount and diversity of spatial and temporal data available for analysis. Hosts of new sensors and experimental techniques are driving this data flood. And while the transformational potential on science is understood, the reality of managing the data flows from collection through to analysis, especially integration with other data, insights, plus education, and outreach has not kept pace. A continuum of approaches exist for data archiving, publishing and sharing: from the single investigator with limited technical skills, or limited personal interest in archiving or sharing data, to the highly structured ecological observatory with an IT (Information Technology) department and the explicit goal of archiving data and making them accessible to researchers who were not involved in the sampling (e.g. NEON). Grassroots organizations like GLEON (the Global Lake Ecological Observatory Network) share many similarities with the single investigator approach without major IT support, but recognize data sharing as a mandatory first step to answer pressing research questions addressing climate and land-use change, diminishing ecosystem services, and large scale disruptions of ecosystem functioning on a global scale. It is  proposed  to collaborate with other groups invested in the area of environmental observations data management and develop a design and implementation plan for a data publishing and sharing system that will address not only GLEON?s needs but also those of environmental research communities that find themselves in a similar place along the outlined data management continuum, of which there is a growing number. We will leverage GLEON?s experience, organizational structure, community trust, and recognized need for data sharing, Our approach will be primarily based on deploying and testing technology components created by CUAHSI, DataONE, LTER, and DataTurbine in a prototype setting and to assess their applicability in the GLEON community through targeted focus groups.  The intellectual merits are twofold. First, prototyping and testing of existing technologies by our community members will provide valuable feedback to the original creators of the technology. Second, and most importantly, through our efforts, our community will develop a design and implementation plan for a data publishing and sharing system that is not only well conceived and sustainable, but owned and manageable by our community members, with potential implementation by dozens, if not hundreds, of ecological observatories.  Broader impact: This community is an international and multi-cultural grassroots organization based on the recognized need for collaboration, as very typical in the current and future landscape of environmental research approaches. Therefore, a community level data publishing and sharing design and implementation plan that considers aspects typical for these research approaches will benefit many other international grassroots research and education collaborations, and the approach will be transformational in developing such global infrastructures. Aspects of primary importance are governance, sustainability, buy-in, trust, appropriate credit, and last but not least, usability. Finally, during the evaluation phase many researchers and students will be exposed to and trained in the use of technology that is currently available to them, even if in the end it is not considered appropriate for the entire community."
"1443054","CIF21 DIBBs: Middleware and High Performance Analytics Libraries for Scalable Data Science","OAC","Tribal College & Univers Prog, EDUCATION AND WORKFORCE, Data Cyberinfrastructure","10/01/2014","06/02/2020","Geoffrey Fox","IN","Indiana University","Standard Grant","Amy Walton","09/30/2021","$5,283,170.00","Madhav Marathe, Shantenu Jha, Judy Fox, Fusheng Wang","gcfexchange@gmail.com","107 S INDIANA AVE","BLOOMINGTON","IN","474057000","3172783473","CSE","1744, 7361, 7726","7433, 8048, 9251","$0.00","Many scientific problems depend on the ability to analyze and compute on large amounts of data.  This analysis often does not scale well; its effectiveness is hampered by the increasing volume, variety and rate of change (velocity) of big data.  This project will design, develop and implement building blocks that enable a fundamental improvement in the ability to support data intensive analysis on a broad range of cyberinfrastructure, including that supported by NSF for the scientific community. The project will integrate features of traditional high-performance computing, such as scientific libraries, communication and resource management middleware, with the rich set of capabilities found in the commercial Big Data ecosystem. The latter includes many important software systems such as Hadoop, available from the Apache open source community.  A collaboration between university teams at Arizona, Emory, Indiana (lead), Kansas, Rutgers, Virginia Tech, and Utah provides the broad expertise needed to design and successfully execute the project.  The project will engage scientists and educators with annual workshops and activities at discipline-specific meetings, both to gather requirements for and feedback on its software.  It will include under-represented communities with summer experiences, and will develop curriculum modules that include demonstrations built as 'Data Analytics as a Service.'<br/><br/>The project will design and implement a software Middleware for Data-Intensive Analytics and Science (MIDAS) that will enable scalable applications with the performance of HPC (High Performance Computing) and the rich functionality of the commodity Apache Big Data Stack.  Further, this project will design and implement a set of cross-cutting high-performance data-analysis libraries; SPIDAL (Scalable Parallel Interoperable Data Analytics Library) will support new programming and execution models for data-intensive analysis in a wide range of science and engineering applications.   The project addresses major data challenges in seven different communities: Biomolecular Simulations, Network and Computational Social Science, Epidemiology, Computer Vision, Spatial Geographical Information Systems, Remote Sensing for Polar Science, and Pathology Informatics.  The project libraries will have the same beneficial impact on data analytics that scientific libraries such as PETSc, MPI and ScaLAPACK have had for supercomputer simulations.  These libraries will be implemented to be scalable and interoperable across a range of computing systems including clouds, clusters and supercomputers."
"1443013","CIF21 DIBBs: T2-C2: Timely and Trusted Curator and Coordinator Data Building Blocks","OAC","Data Cyberinfrastructure, Cybersecurity Innovation, DMREF","10/01/2014","12/23/2016","Klara Nahrstedt","IL","University of Illinois at Urbana-Champaign","Standard Grant","Amy Walton","09/30/2019","$1,500,000.00","David Nicol, John Rogers, N Aluru, Paul Braun, Brian Cunningham","klara@cs.uiuc.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","CSE","7726, 8027, 8292","024E, 7433, 7434, 8027, 8048, 9102","$0.00","A 2008 National Academy report on Integrated Computational Materials Engineering noted that in a rapidly changing and increasingly competitive global market, integrated innovative design and rapid product development must be supported by computationally based designs, fast engineering analysis, and efficient data management tools.  This project addresses the National Materials Review Board recommendations of reducing the cycle from the design of new materials to the fabrication of new devices using new materials. To address the materials-to-devices cycle challenge, the project  focuses on the potential of capturing, curating, correlating and coordinating materials-to-devices digital data in a real-time and trusted manner before fully archiving and publishing the data for wide access and sharing.  The software developed in this project is useful throughout the materials science and device fabrication fields, by automatically collecting, archiving, and providing collected information on all phases of materials and device fabrication development.<br/> <br/>The project develops the Timely and Trusted Curation and Coordination (T2-C2) Data Framework, consisting of two data blocks: <br/>1) T2-C2 Curator, providing  real-time acquisition and curation of digital data from selected materials-making / characterization and device-fabrication instruments in the collaborative research units at the university, the Material Research Lab (MRL) and the Micro-and-Nanotechnology Lab (MNTL) , and<br/>2) T2-C2 Coordinator, where collected data are filtered, correlations among data and dependency relations are identified, and the results are connected to other data processing capabilities. <br/>The goal of the T2-C2 framework is to enable reduction of the development time and cost of materials-making /characterization to device-making processes.<br/><br/>Through open-source software licenses and training programs, the project impacts material science,  device fabrication and other fields within the university, and other interdisciplinary research institutions and their materials design and manufacturing processes. Through courses, tutorials, workshops, and outreach, the project develops interdisciplinary scientists,  teaches the next generation of students, and informs broader audiences about the potential of timely and trusted data collection, curation, spatio-temporal analytics, and correlations between material-making/characterization and device-fabrication processes."
"1443047","CIF21 DIBBs: Domain-Aware Management of Heterogeneous Workflows: Active Data Management for Gravitational-Wave Science Workflows","OAC","PHYSICS AT THE INFO FRONTIER, Data Cyberinfrastructure","10/01/2014","08/16/2018","Duncan Brown","NY","Syracuse University","Continuing Grant","Amy Walton","09/30/2019","$1,078,712.00","Ewa Deelman, Jian Qin, Peter Couvares","dabrown@syr.edu","900 S CROUSE AVE","SYRACUSE","NY","132440001","3154432807","CSE","7553, 7726","062Z, 7433, 7569, 8048, 8084","$0.00","Analysis and management of large data sets are vital for progress in the data-intensive realm of scientific research and education.  Scientists are producing, analyzing, storing and retrieving massive amounts of data.  The anticipated growth in the analysis of scientific data raises complex issues of stewardship, curation and long-term access. Scientific data is tracked and described by metadata.  This award will fund the design, development, and deployment of metadata-aware workflows to enable the management of large data sets produced by scientific analysis.  Scientific workflows for data analysis are used by a broad community of scientists including astronomy, biology, ecology, and physics. Making workflows metadata-aware is an important step towards making scientific results easier to share, to reuse, and to support reproducibility.  This project will pilot new workflow tools using data from the Laser Interferometer Gravitational-wave Observatory (LIGO), a data-intensive project at the frontiers of astrophysics. The goal of LIGO is to use gravitational waves---ripples in the fabric of spacetime---to explore the physics of black holes and understand the nature of gravity.  <br/><br/>Efficient methods for accessing and mining the large data sets generated by LIGO's diverse gravitational-wave searches are critical to the overall success of gravitational-wave physics and astronomy.  Providing these capabilities will maximize existing NSF investments in LIGO, support new modes of collaboration within the LIGO Scientific Collaboration, and better enable scientists to explain their results to a wider community, including the critical issue of data and analysis provenance for LIGO's first detections.  The interdisciplinary collaboration involved in this project brings together computational and informatics theories and methods to solve data and workflow management problems in gravitational-wave physics.  The research generated from this project will make a significant contribution to the theory and methods in identification of science requirements, metadata modeling, eScience workflow management, data provenance, reproducibility, data discovery and analysis.  The LIGO scientists participating in this project will ensure that the needs of the community are met. The cyberinfrastructure and data-management scientists will ensure that the software products are well-designed and that the work funded by this award is useful to a broader community."
"1541450","CC*DNI DIBBS: Merging Science and Cyberinfrastructure Pathways: The Whole Tale","OAC","Data Cyberinfrastructure","03/01/2016","01/23/2022","Bertram Ludaescher","IL","University of Illinois at Urbana-Champaign","Cooperative Agreement","Alejandro Suarez","02/28/2023","$5,887,240.00","Victoria Stodden, Niall Gaffney, Matthew Turk, Kyle Chard","ludaesch@illinois.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","CSE","7726","7433, 8048, 8084","$0.00","Scholarly publications today are still mostly disconnected from the underlying data and code used to produce the published results and findings, despite an increasing recognition of the need to share all aspects of the research process.  As data become more open and transportable, a second layer of research output has emerged, linking research publications to the associated data, possibly along with its provenance.  This trend is rapidly followed by a new third layer: communicating the process of inquiry itself by sharing a complete computational narrative that links method descriptions with executable code and data, thereby introducing a new era of reproducible science and accelerated knowledge discovery.  In the Whole Tale (WT) project, all of these components are linked and accessible from scholarly publications. The third layer is broad, encompassing numerous research communities through science pathways (e.g., in astronomy, life and earth sciences, materials science, social science), and deep, using interconnected cyberinfrastructure pathways and shared technologies. <br/><br/>The goal of this project is to strengthen the second layer of research output, and to build a robust third layer that integrates all parts of the story, conveying the holistic experience of reproducible scientific inquiry by (1) exposing existing cyberinfrastructure through popular frontends, e.g., digital notebooks (IPython, Jupyter), traditional scripting environments, and workflow systems; (2) developing the necessary 'software glue' for seamless access to different backend capabilities, including from DataNet federations and Data Infrastructure Building Blocks (DIBBs) projects; and (3) enhancing the complete data-to-publication lifecycle by empowering scientists to create computational narratives in their usual programming environments, enhanced with new capabilities from the underlying cyberinfrastructure (e.g., identity management, advanced data access and provenance APIs, and Digital Object Identifier-based data publications).  The technologies and interfaces will be developed and stress-tested using a diverse set of data types, technical frameworks, and early adopters across a range of science domains."
"1255826","CIF21 DIBBs: Designing the Roadmap for Social Network Data Management","OAC","Data Cyberinfrastructure","05/01/2013","03/07/2013","Thomas Carsey","NC","University of North Carolina at Chapel Hill","Standard Grant","Robert Chadduck","12/31/2014","$109,738.00","","carsey@unc.edu","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","CSE","7726","7433, 8048","$0.00","CIF21 DIBBs: Designing the Roadmap for Social Network Data Management <br/>Scholarly interest in network analysis has increased dramatically in the social sciences and beyond. The explosion of social media tools such as Facebook, Flickr, and Twitter, along with new developments in machine learning and data mining have produced new types of behavioral data for scholars to analyze (Mislove et al., 2007). Significant advances in mathematics, statistics, and computer science have also produced unprecedented opportunities to analyze ?Big? social network data. Social network analysis sits at the cutting edge of social science and also links the social, natural, and computational sciences. Understanding the multi-faceted nature of social networks and their effects on human behavior is one of the grand challenges faced as this project seeks to maximize our investments in scientific research (NSF-ACCI, 2011). However, the community has not seen comparable advances in the management, archiving, and sharing of social network data. This presents a fundamental obstacle to advancing network science across the social, natural, and computational sciences. This proposal seeks to begin to remedy this problem. The data management needs social network scholars are complex. Network data often come from unstructured environments that require researchers to define and describe a set of units or actors (called nodes) and the connections (called edges) between them. Networks might be static or dynamic, include one type of node or multiple node types, and include edges that are uni-directional or bi-directional and weighted or unweighted. In addition, as relationships spread within the network and/or a network grows, the associated data management, data storage, and analytical memory requirements can grow exponentially.  This proposal brings together the social network analysis, information science, computer science, and data archive communities to develop a data infrastructure to support advanced analysis and research on social networks as well as to facilitate data sharing and archiving within this community. The group will address key questions concerning data storage architecture and lifecycle requirements, develop design specifications for creating a sustainable data infrastructure that will be discoverable, searchable, accessible, and usable to the entire research and education community, and initialize a prototype solution based on that plan.  Intellectual Merit: The proposed project will bring together the social network analysis community to work with information technology professionals to design a robust data management infrastructure to promote the sharing and interoperability of social network data. Effective data management for social network data amplifies the impact of research by revealing data quality issues early in the data collection process, ensuring that required data is retained and usable throughout the life of a research project. It also facilitates data sharing and reuse. A key to responsible data stewardship is the application and auditing of quality data management policies ? something included in this proposal. Providing a robust infrastructure to store, analyze, curate, share, and manage important social network data will increase researchers? production and provide an unprecedented view of the social world only visible through social network data.  Broader Impacts: The project will facilitate data sharing and increase social network data availability while assuring researchers that data management policies are followed. It will help formalize a community of network data experts that will begin developing best practices for the community. Availability of data particularly benefits early-stage researchers, and researchers at diverse institutions. Widespread availability of data facilitates citizen science and the integration of science and teaching at all levels of education. Managed data sharing is critical to the multi disciplinary research to answer the critical challenges facing society today. It would be difficult to overstate the importance of social network analysis to better understand human networks and social behavior."
"1443080","CIF21 DIBBs: Scalable Capabilities for Spatial Data Synthesis","OAC","Geography and Spatial Sciences, Data Cyberinfrastructure","10/01/2014","08/15/2019","Shaowen Wang","IL","University of Illinois at Urbana-Champaign","Standard Grant","Amy Walton","09/30/2020","$1,499,998.00","Katarzyna Keahey, Anand Padmanabhan","shaowen@illinois.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","CSE","1352, 7726","7433, 8048","$0.00","This project will develop a set of tools for spatial data synthesis through scalable data aggregation and integration based on cloud computing, CyberGIS, and other existing tools.  Many scientific problems require the aggregation and integration of large and varied spatial data from a multitude of sources, yet existing approaches and software cannot effectively synthesize the enormous amounts of spatial data that often are available.  This project will resolve problems associated with the use of massive spatial data, thus facilitating work dependent on this type of data for scientific problem solving, such as research on population dynamics and urban sustainability.  Learning materials derived from the research activities will be openly accessible through the CyberGIS Science Gateway.  Targeted massive open online course development will provide inexpensive and efficient ways to teaching students about the capabilities and underlying scientific principles of spatial data synthesis.  A summer school will be offered during the second half of the project to provide a more focused and in-depth training event.<br/><br/>This research project will create scalable capabilities for spatial data synthesis enabled by cloud computing and CyberGIS.  The project will begin by developing the capabilities for solving specific scientific problems and then move on to engage a broader community for validating and improving the core capabilities.  The research will incorporate two interrelated themes:  (1) measuring urban sustainability based on a number of social, environmental, and physical factors and processes; and (2) examining population dynamics by synthesizing multiple population data sources with social media data.  Spatial data synthesis capabilities that the project will provide include extracting metadata and dealing with problems of spatial references and units.  The project also will develop a fundamental capability to characterize uncertainty in data and its propagation."
"1724728","CIF21 DIBBs: EI: Creating a Digital Environment for Enabling Data-Driven Science (DEEDS)","OAC","Data Cyberinfrastructure","08/01/2017","10/01/2020","Ann Christine Catlin","IN","Purdue University","Standard Grant","Amy Walton","07/31/2021","$3,456,281.00","Connie Weaver, Joseph Francisco, Muhammad Alam, Maria Sepulveda, Kathleen Gallant","acc@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","CSE","7726","7433, 8048","$0.00","This project creates a platform that simplifies knowledge extraction from diverse scientific datasets, by integrating multimodal data, computing software, and interactive tools for search and exploration.  The effort provides a collaborative environment for sharing research data and computational and statistical algorithms.  During research investigations, the environment uploads and organizes data, executes and tracks computational jobs, and connects input and output to analysis results. When investigations are complete, the environment helps publish data, algorithms and investigative workflows for public access. The environment also simplifies the discovery, search, and exploration of published datasets - providing interactive tools for viewing and analyzing data. Four distinct use cases (chemistry, electrical engineering, nutrition science, and environmental science) provide a testbed for platform usability and functionality. The use cases produce important datasets that are intended for use by HHS, USDA, EPA, DOE, and other government agencies to support decision-making about policy and regulations.<br/><br/>The project builds upon a 2014 DIBBs pilot demonstration award (#1443017 - DataHub) which created a data management platform for the publishing and discovery of scientific research datasets. The team extends this platform to support the full research investigation process by 1) connecting data to computational and statistical modeling software, 2) tracking research workflows to link data, algorithms, and results, 3) automatically capturing metadata and classifying data by type, and 4) providing interfaces to define complex hierarchical, structured data and operate on the data using analytical toolkits. Published datasets are explored with interactive tools that interpret data types for advanced navigation, viewing, search, analysis, and visualization. Collaborations with research projects in chemistry, electrical engineering, nutrition science, and environmental science produce system requirements and guarantee that the general, discipline-neutral platform provides end-to-end support for their use cases. The project helps researchers curate their own findings, and also facilitates the sharing of data and findings for the purposes of preservation, replication, and extension."
"1640818","CIF21 DIBBS:  EI: VIFI:Virtual Information-Fabric Infrastructure (VIFI) for Data-Driven Decisions from Distributed Data","OAC","Data Cyberinfrastructure","10/01/2016","02/04/2020","Ashit Talukder","NC","University of North Carolina at Charlotte","Standard Grant","Alejandro Suarez","09/30/2022","$3,999,531.00","Stanislav Djorgovski, Mirsad Hadzikadic, Yong Tao, Ehab Al-Shaer","atalukde@uncc.edu","9201 UNIVERSITY CITY BLVD","CHARLOTTE","NC","282230001","7046871888","CSE","7726","7433, 8048","$0.00","Data discovery and data analytics often rely on the use of multiple data sources and data residing in distributed locations.  This project builds infrastructure that encourages data-driven discovery from distributed, fragmented datasets without requiring movement of massive amounts of data and without exposing sensitive raw datasets to end users.  The capability will be applied to a wide range of science topics: to the large sky surveys of astronomy, for which the collecting instruments are distributed nationally and internationally;  to classify Earth science satellite data; for the management of sickle-cell disease and antimicrobial resistance surveillance studies; and to integrate the highly distributed and fragmented data sources needed for multi-hazard mitigation and for sustainable and resilient human-building ecosystem research. The project outlines an ambitious and will enable interdisciplinary training in multiple universities and institutions, and contribute to the training of early career researchers<br/><br/>A Virtual Information-Fabric Infrastructure (VIFI) is created, allowing scientists to search, access, manipulate, and evaluate fragmented, distributed data in the information 'fabric' (the infrastructure to facilitate data sharing) without directly accessing or moving large amounts of data.  The system addresses the challenges of coordinating loosely federated infrastructure, distributed data management, security and privacy.  The architecture combines a set of loosely coupled components representing some proven capabilities with several emerging components. The VIFI infrastructure includes a novel orchestration layer for on-site analytics and hybrid-infrastructure (GPU, CPU) management, a dynamic secure container-based infrastructure which enables online adaptive analytics from unshareable data at distributed locations, and enhanced data and code management tools.  The layer also provides search, access and query based on improvements using persistent identifiers and automated semantic descriptions (or metadata) of raw data using semantic data mining techniques.  By integrating several NSF-funded components into a coherent whole, VIFI allows researchers to search, access, manipulate and evaluate data elements without requiring detailed familiarity with the data infrastructure itself.  The system contributes to and expands the sets of resources serving diverse communities, and is extensible to additional communities.  The project contains a substantial outreach effort, including training of early career scientists."
"2220826","CIF21 DIBBs: EI: Virtual Data Collaboratory: A Regional Cyberinfrastructure for Collaborative Data Intensive Science","OAC","Data Cyberinfrastructure","10/01/2021","03/31/2022","Ivan Rodero","UT","University of Utah","Standard Grant","Alejandro Suarez","09/30/2022","$1,540,483.00","","ivan.rodero@utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","CSE","7726","7433, 8048","$0.00","This project develops a virtual data collaboratory that can be accessed by researchers, educators, and entrepreneurs across institutional and geographic boundaries, fostering community engagement and accelerating interdisciplinary research.  A federated data system is created, using existing components and building upon existing cyberinfrastructure and resources in New Jersey and Pennsylvania.  Seven universities are directly involved (the three Rutgers University campuses, Pennsylvania State University, the University of Pennsylvania, the University of Pittsburgh, Drexel University, Temple University, and the City University of New York); indirectly, other regional schools served by the New Jersey and Pennsylvania high-speed networks also participate.  The system has applicability to a several science and engineering domains, such as protein-DNA interaction and smart cities, and is likely to be extensible to other domains.  The cyberinfrastructure is to be integrated into both graduate and undergraduate programs across several institutions.   <br/><br/>The end product is a fully-developed system for collaborative use by the research and education community.   A data management and sharing system is constructed, based largely on commercial off-the-shelf technology.  The storage system is based on the Hadoop Distributed File System (HDFS), a Java-based file system providing scalable and reliable data storage, designed to span large clusters of commodity servers.  The Fedora and VIVO object-based storage systems are used, enabling linked data approaches.  The system will be integrated with existing research data repositories, such as the Ocean Observatories Initiative and Protein Data Bank repositories.  Regional high-performance computing and network infrastructure is leveraged, including New Jersey's Regional Education and Research Network (NJEdge), Pennsylvania's Keystone Initiative for Network Based Education and Research (KINBER), the Extreme Science and Engineering Discovery Environment (XSEDE) computing capabilities, Open Science Grid, and other NSF Campus Cyberinfrastructure investments.  The project also develops a custom site federation and data services layer; the data services layer provides services for data linking, search, and sharing; coupling to computation, analytics, and visualization; mechanisms to attach unique Digital Object Identifiers (DOIs), archive data, and broadly publish to internal and wider audiences; and manage the long-term data lifecycle, ensuring immutable and authentic data and reproducible research."
"1443046","CIF21 DIBBs: STORM: Spatio-Temporal Online Reasoning and Management of Large Data","OAC","Physical & Dynamic Meteorology, Data Cyberinfrastructure, EarthCube","11/01/2014","08/10/2016","Feifei Li","UT","University of Utah","Standard Grant","Amy Walton","10/31/2019","$1,173,975.00","John Horel, Paul Rosen, Jeff Phillips","lifeifei@cs.utah.edu","201 PRESIDENTS CIR","SALT LAKE CITY","UT","841129049","8015816903","CSE","1525, 7726, 8074","4444, 7433, 8048, 9150, 9251","$0.00","A fundamental challenge for many research projects is the ability to handle large quantities of heterogeneous data. Data collected from different sources and time periods can be inconsistent, or stored in different formats and data management systems. Thus, a critical step in many projects is to develop a customized query and analytical engine to translate inputs.  But for each new dataset, or for each new query type or analytic task for an existing dataset, a new query interface or program must be developed, requiring significant investments of time and effort.  This project will develop an automatic engine for searching large, heterogeneous data collections for weather and meteorology, particularly from instruments in the western US, in a regional network called MesoWest. <br/><br/>This project develops an automatic query and analytical engine for large, heterogeneous spatial and temporal data. This capability allows users to automatically deploy a query and analytical engine instance over their large, heterogeneous data with spatial and temporal dimensions.  The system supports a simple search-box and map-like query interface that allows numerous powerful analytical queries.  Techniques to make these queries robust, relevant, and highly scalable will be developed.  The project also enables users to execute queries over multiple data sources simultaneously and seamlessly. The goal of the work is to dramatically simplify the management and analysis of large spatio-temporal data at different institutions, groups, and corporations."
"1724853","CIF21 DIBBs: EI: Integrated Platform for Applied Network Data Analysis (PANDA)","OAC","CYBERINFRASTRUCTURE, Data Cyberinfrastructure, Campus Cyberinfrastructure","09/01/2017","06/15/2022","Kimberly Claffy","CA","University of California-San Diego","Standard Grant","Kevin Thompson","08/31/2022","$4,080,000.00","Alistair King, Amogh Dhamdhere, Bradley Huffaker, Alberto Dainotti","kc@caida.org","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","CSE","7231, 7726, 8080","7433, 8048, 9251","$0.00","As the Internet, and society's dependence on it, have grown, the structure and dynamics of the network, and how it relates to the political economy in which it is embedded, are gathering increasing attention by researchers, operators and policy makers.  This project offers a new platform and supporting tools for collecting, analyzing, querying, and interpreting measurements of the Internet ecosystem.  It directly supports the NSF goal of providing robust, secure cyberinfrastructure to accelerate research, education, and new capabilities in data-intensive science and engineering.  Broader impacts of this project include increased public awareness of Internet structure, dynamics, performance, and evolution, which informs discussions of critical issues in current and future large-scale networking.<br/><br/>This Platform for Applied Network Data Analysis (PANDA) integrates existing research infrastructure measurement and analysis components previously developed by the Center for Applied Internet Data Analysis, and enables new scientific directions, experiments, and data products for a wide range of research activities.   The design of PANDA emphasizes efficient indexing and processing of terabyte archives, advanced visualization tools to show geographic and economic aspects of Internet structure, and detailed interpretation of displayed results.  The project actively engages collaborators from four targeted disciplines: networking, security, economics, and public policy.  Activities include workshops to establish and stimulate multi-disciplinary collaborations, development of online video tutorials targeting non-networking experts and classroom-focused materials, an annotated bibliography and discussion forum, and a strategic advisory board.<br/> <br/>This award is supported jointly by both the Data and Networking programs within the Office of Advanced Cyberinfrastructure."
"1443083","CIF21 DIBBs: Ubiquitous Access to Transient Data and Preliminary Results via the SeedMe Platform","OAC","Polar Cyberinfrastructure, CRCNS-Computation Neuroscience, Data Cyberinfrastructure","10/01/2014","09/08/2014","Amit Chourasia","CA","University of California-San Diego","Standard Grant","Amy Walton","09/30/2019","$1,329,379.00","Michael Norman","amit@sdsc.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","CSE","5407, 7327, 7726","5407, 7433, 7726, 8048, 8089, 8091","$0.00","Computational simulations have become an indispensible tool in a wide variety of science and engineering investigations.  Quick and effective assessments of the resulting data are necessary for efficient use of researcher time and computation resources, but this process is complicated when a large collaborating team is geographically dispersed and/or some team members do not have direct access to the computation resource and output data.  Current methods for sharing and assessing transient data and preliminary results are cumbersome and labor intensive; each research team must create their own scripts and ad hoc procedures to push data from system to system and user to user.  Better tools and cyberinfrastructure are needed to support preliminary results sharing for collaborating computational science teams. <br/><br/>This project develops web-based building blocks and cyberinfrastructure to enable easy sharing and streaming of transient data and preliminary results from computing resources to a variety of platforms, from mobile devices to workstations, making it possible to quickly and conveniently view and assess results and provide an essential missing component in High Performance Computing and cloud computing infrastructure."
"1443070","CIF21 DIBBs: User Driven Architecture for Data Discovery","OAC","Info Integration & Informatics, Data Cyberinfrastructure","09/01/2014","08/18/2014","Giridhar Manepalli","VA","Corporation for National Research Initiatives (NRI)","Standard Grant","Amy Walton","04/30/2018","$1,484,940.00","Laurence Lannom, Allison Powell","gmanepalli@cnri.reston.va.us","1895 PRESTON WHITE DR","RESTON","VA","201915469","7036208990","CSE","7364, 7726","7433, 8048, 8083","$0.00","The number, size, and availability of scientific datasets have grown enormously over the last few years.  As scientific activity becomes more data intensive and collaborative, a key challenge for cross-disciplinary research will be discovery of diverse data sets, managed within distributed repositories and registries.  Currently, discovery of information on the Internet is largely performed through automated approaches, characterized by web crawling and associated algorithms, or labor intensive indexing and categorization, such as the National Library of Medicine index for medical literature.  There are significant amounts of data housed in repositories where only researchers with expertise in the specific field know and access the data.<br/><br/>This project builds a user driven architecture for data discovery (UDADD), a capability that enhances discovery of scientific datasets by building a global index from diverse communities with minimal input.  In the UDADD approach user actions, such as dataset queries or downloads, drive the construction of a global index. These actions are recorded and gathered automatically, through cooperation with repository managers. Two software plugins are provided to help the repositories interact with the UDADD system. The architecture includes ranking techniques based on frequency and recency of use of the datasets. <br/><br/>The pilot architecture will be demonstrated and evaluated using cooperating repositories within the DataNet Federation Consortium.  Currently, six science and engineering communities participate in the consortium, including national scale projects in oceanography, social science, cognitive science, hydrology, engineering, and plant biology."
"1541318","CC*DNI DIBBs: Give Your Data the Edge: A Scalable Data Delivery Platform","OAC","Data Cyberinfrastructure","09/01/2015","11/21/2017","Larry Peterson","AZ","University of Arizona","Cooperative Agreement","Amy Walton","12/31/2017","$1,597,862.00","Nirav Merchant, Scott Baker, Hao Xu, Andrew Bavier","llp@cs.princeton.edu","888 N EUCLID AVE RM 510","TUCSON","AZ","857194824","5206266000","CSE","7726","7433, 8048","$0.00","Scientific collaboration is increasingly data driven. Large volumes of data are generated, aggregated, archived, and shared?often with collaborators (and their compute resources) spread across the globe - with subsequent analysis generating still more data to archive and distribute. Scientists either become experts at data transfer, storage, and management, or their ability to build on each other?s work suffers. This project addresses this challenge, with an emphasis on easing the burden on the user, building a solution that is sustainable over the long term, and delivering performance that scales in the number of collaborators.  <br/><br/>The project's technical approach is to deploy a general-purpose storage platform, called Syndicate, that harnesses a collection of available storage components to provide a global, scalable, and secure storage service. These include public and private cloud storage (for data durability), network caches and content distribution networks (for scalable read bandwidth), and local disks (for local reads/write performance). The project's goal is to make it possible for applications to access data independent of where it is stored, where Syndicate simultaneously: (1) minimizes the operational burden imposed on users, (2) maximizes the use of commodity infrastructure; and (3) maximizes aggregate I/O performance. At its core, Syndicate's value proposition is to fully decouple storage semantics from infrastructure. This lets users select infrastructure based on its cost/performance trade-off, while ensuring that their domain-specific storage requirements are met. And to demonstrate this value, the project is building a pilot deployment that spans edge resources on nine campuses, and operating the capability on behalf of a diverse set of application domains, ranging from biology to network analytics to personalized medicine to retail and consumer analysis."
"1640775","CIF21 DIBBs: PD: Accelerating Comparative Metagenomics through an Ocean Cloud Commons","OAC","ADVANCES IN BIO INFORMATICS, Data Cyberinfrastructure, EarthCube","01/01/2017","08/02/2019","B Hurwitz","AZ","University of Arizona","Standard Grant","Amy Walton","12/31/2019","$588,212.00","John Hartman","bhurwitz@email.arizona.edu","888 N EUCLID AVE RM 510","TUCSON","AZ","857194824","5206266000","CSE","1165, 7726, 8074","7433, 8048, 9102","$0.00","The Tara Oceans Expedition has provided the largest publicly available contiguous dataset available in genomics for any scientific project in the world.   Using the research schooner Tara and modern sequencing and state-of-the-art imaging technologies, a multinational team of scientists sampled microscopic plankton at hundreds of sites and depths in all the major oceanic regions.  The Tara Oceans Expedition data have been released, but it is a challenge for researchers to access, manipulate, and analyze such large-scale resources.  This project creates an Ocean Cloud Commons (OCC), a cloud-based resource and repository allowing researchers to query the Tara Oceans Expedition Data in the cloud; it also makes available comparative metagenomic tools through the Ocean Treasure Box (OTB).<br/><br/>The Ocean Cloud Commons and Ocean Treasure Box build upon established partnerships with organizations such as CyVerse Cyberinfrastructure, Agave Platform, OpenCloud, and computing facilities at the Texas Advanced Computing Center.  The Ocean Cloud Commons uses an algorithm based on MapReduce to create a comparative metagenomics data resource in a Hadoop big data framework.  The OCC can be widely accessed by researchers using tools developed in the Ocean Treasure Box and implemented as Apps in the CyVerse Cyberinfrastructure.  Specifically, OTB tools deploy and compute on OCC data in OpenCloud via the Agave Platform and Developer API from CyVerse.  Taken together, the OTB tools and OCC data resources enable researchers to address global-scale questions about the distribution of microbes across the sea that affect climate and ecosystem function.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and the NSF Directorate for Geosciences."
"1640813","CIF21 DIBBs: EI: mProv: Provence-Based Data Analytics Cyberinfrastructure for High-frequency Mobile Sensor Data","OAC","Information Technology Researc, CSR-Computer Systems Research, Networking Technology and Syst, Data Cyberinfrastructure, Smart and Connected Health","09/01/2016","09/12/2016","Santosh Kumar","TN","University of Memphis","Standard Grant","Alejandro Suarez","08/31/2022","$4,000,000.00","Mani Srivastava, Zachary Ives, Ida Sim","skumar4@memphis.edu","101 WILDER TOWER","MEMPHIS","TN","381523520","9016783251","CSE","1640, 7354, 7363, 7726, 8018","7364, 7433, 8048","$0.00","This project addresses a rapidly growing opportunity: the ability of the research community to use high-frequency mobile sensor data.  Mobile sensors (embedded in phones, vehicles, wearables, and the environment) continuously capture data in great detail, and have the potential to address problems in a range of scientific and engineering domains.  This effort focuses upon a specific case -- health data -- that builds upon several capabilities developed in National Institutes of Health (NIH) sponsored projects for assembling and analyzing health data collected through mobile sensors and apps.  Improvements to the usefulness of extremely noisy, distributed data can serve many communities, and the components are extensible outside the human health domain.  <br/><br/>Mobile sensors present a distinct set of data challenges: the data quantity and quality fluctuate, and uncertainty can be high.  Establishing provenance on such noisy data is a challenge, and there are limitations on access to data from human subjects.  This project addresses several of the distinctive challenges associated with mobile sensor data.   Variability is addressed by providing detailed annotation with metadata (such as provenance and quality), and by providing facilities for context-specific reasoning about the metadata.  The system captures provenance metadata along with data in a stream, and propagates this information alongside derived data from one stage to the next.  This creates cyberinfrastructure that makes it possible to 'replay' mobile device data with different configurations, to comparatively benchmark two algorithms or to diagnose erroneous output.  The project builds upon the capabilities and success of the NIH-funded Center of Excellence in Mobile Sensor Data to Knowledge (MD2K), which provides an open-source cyberinfrastructure enabling the collection, curation, analysis, visualization, and interpretation of high-frequency mobile sensor data.  Conducting research with mobile sensor data collected by others continues to be challenging; this project develops a companion open-source provenance cyberinfrastructure, facilitating the sharing of the mobile sensor data itself.  Results include metadata standards, interfaces, and runtime support for annotating data streams with the source (sensor, location, sampling rate, continuous or episodic), semantics of output (number, probability, class), provenance (features, rules for decision), and validation (specificity, sensitivity, benchmark used).  The infrastructure accommodates a wide variety of data types and enables data discovery, analytics, visualization, integration, and validation by third party researchers. The project improves the ability of the wider scientific and engineering community to use mobile sensing systems and metadata, and it also has immediate, tangible societal benefits in health and wellness.  <br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Computer & Information Science & Engineering (Division of Computer and Network Systems, and Division of Information and Intelligent Systems)."
"1640575","CIF21 DIBBs: EI: Continuous Capture of Metadata for Statistical Data","OAC","ADVANCES IN BIO INFORMATICS, Data Cyberinfrastructure","10/01/2016","07/18/2019","George Alter","MI","Regents of the University of Michigan - Ann Arbor","Standard Grant","Amy Walton","09/30/2021","$3,076,213.00","Jared Lyle","altergc@umich.edu","503 THOMPSON STREET","ANN ARBOR","MI","481091340","7347636438","CSE","1165, 7726","7433, 8048","$0.00","As the research community responds to increasing demands for public access to scientific data, the need for improvement in data documentation has become critical.  Accurate and complete metadata is essential for data sharing and for interoperability across different data types.  However, the process of describing and documenting scientific data has remained a tedious, manual process even when data collection is fully automated.  General purpose statistical packages (SPSS, SAS, Stata, R) are fundamental to research in the social and behavioral sciences, environmental sciences, biomedical research, and many other fields, but these packages lack tools for documenting how data are modified and new variables created.  By creating tools to capture data transformations from statistical analysis packages, this project creates efficiencies and reduces the costs of data collection, preparation, and re-use.  Two research communities with strong metadata standards and heavy reliance on statistical analysis software (social and behavioral sciences and earth observation sciences) are targeted, but the approach is generalizable to other scientific domains.<br/><br/>Automating documentation of data transformations involves three main steps. First, the most common data transformation operators are standardized and mapped to the Validation and Transformation Language (VTL), an emerging independent standard for describing operations on data in detail.  Second, software parses command scripts for the most widely used statistics packages and translates data transformation operations into VTL.  Third, software tools modify metadata files adhering to existing standards to reflect changes to the data.  This approach embeds detailed variable-level provenance information into standard metadata, and makes it available for data discovery services and automated data analysis tools.   <br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and the NSF Directorate for Social, Behavioral and Economic Sciences (Division of Social and Economic Sciences)."
"1443061","CIF21 DIBBs: Systematic Data-Driven Analysis and Tools for Spatiotemporal Solar Astronomy Data","OAC","OFFICE OF MULTIDISCIPLINARY AC, , Data Cyberinfrastructure, EarthCube","11/01/2014","08/14/2014","Rafal Angryk","GA","Georgia State University Research Foundation, Inc.","Standard Grant","Amy Walton","10/31/2019","$1,499,933.00","Petrus Martens, Katharine Reeves","angryk@cs.gsu.edu","58 EDGEWOOD AVE NE 3RD FL","ATLANTA","GA","303032921","4044133570","CSE","1253, 1798, 7726, 8074","7433, 7480, 8048","$0.00","The large quantities of data produced by modern solar telescopes provide a rich and rapidly growing opportunity for discovery.  These large data sets create an unprecedented ability to observe correlations between phenomena that have previously gone unexplored.   However, to harness the power of these large data sets, it is necessary to provide the solar physics and space weather communities with software tools that will rapidly and accurately catalog, explore, track and correlate solar phenomena.<br/><br/>This project develops tools for processing large volumes of spatio-temporal solar data.  Initially, the team enables tracking of all solar events previously identified by an international consortium (the Feature Finding Team of the Solar Dynamics Observatory) and reported to the Heliophysics Event Knowledgebase (HEK).  Next, the team develops systematic spatiotemporal characterizations of solar event types, and identifies spatiotemporal co-occurrence patterns.  Throughout the project, the team disseminates the generated data, discovered patterns, and developed software tools to the community. By adding an ability to track features previously identified by an international consortium, the project has potential to advance knowledge of solar phenomena, and the impact of such phenomena on space weather."
"1261715","CIF21 DIBBs: Long Term Access to Large Scientific Data Sets: The SkyServer and Beyond","OAC","Data Cyberinfrastructure","10/01/2013","07/12/2019","Alexander Szalay","MD","Johns Hopkins University","Cooperative Agreement","Amy Walton","03/31/2020","$10,449,659.00","Steven Salzberg, Charles Meneveau, Aniruddha Thakar, Randal Burns, Michael Rippin","aszalay1@jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","CSE","1798, 7726","7433, 8048, 8084","$0.00","The Project aims to create a sustainable collaborative ecosystem built around several large scientific data sets for the broader science community. Based upon the expertise developed for the Sloan Digital Sky Survey (SDSS) SkyServer and the associated projects the Project will formalize the main system components and reengineer them to be much more reusable. <br/><br/>The Project will take full ownership of the Sloan Digital Sky Survey archive and will provide a robust environment for its continued operations, using an economy of scale enabled by common, shared building blocks derived from the existing SDSS SkyServer framework, based upon a large, scalable database system.<br/><br/>Using these building blocks, the team will build and operate open data archives from large observations and numerical simulations, including computational fluid dynamics, ocean circulation and astrophysics, reaching PB scales. The Project will further extend the tools to life sciences, like large-scale, next-generation genome sequencing experiments, as well as high-throughput neuroscience imaging data. The resulting distributed, parallel database framework will be linked to small, user-created data sets that can be used also collaboratively, in conjunction with each other and the large data collections. <br/><br/>The Project will work with selected communities to help deploying and serving data using our building blocks, demonstrating portability, generality and economies of scale; will help and encourage other institutions and communities to use the tools, while seeking collaborations that result in disruptive changes, and will build tools that accelerate the timescale to deploy new services and applications and rapidly test new ideas.<br/><br/>The Project will enable individual users to bring their ""small data"" and analyze it collaboratively in the context of the large data. <br/>Our particular goals are:<br/><br/>   (i)   Take full ownership of the SDSS Archive (database and flat files) and ensure a scalable and robust environment for its continued operation;<br/><br/>   (ii)  Build upon our decade-long effort on SDSS and its ad-hoc spinoffs, through reengineering its components into portable and general building blocks;<br/><br/>   (iii) Systematically address curation issues arising from using a service-oriented architecture (SOA), and the resulting service life-cycle;<br/><br/>   (iv) Work with projects from additional scientific domains to help deploying and serving data using our building blocks, demonstrating portability, generality and economies of scale;<br/>  <br/>   (v) Develop scalable extensions to our database cluster in order to deal with large numerical simulations scaling up to petabytes, and turn them into open numerical laboratories;<br/><br/>   (vi) Use our CasJobs Collaborative Environment to address the problem of small but complex data in the ""Long Tail"" of science."
"1255793","CIF21: DIBBs: Building a Unified Infrastructure for Data Integration on Political Violence and Conflict","OAC","Data Cyberinfrastructure","03/01/2013","03/07/2013","Gary LaFree","MD","University of Maryland, College Park","Standard Grant","Robert Chadduck","05/31/2014","$117,176.00","Brandon Behlendorf","glafree@umd.edu","3112 LEE BLDG 7809 REGENTS DR","College Park","MD","207420001","3014056269","CSE","7726","7433, 8048","$0.00","Building a Unified Infrastructure for Data Integration on Political Violence and Conflict <br/><br/>This proposal s a conceptualization project whereby leaders of several major data collections, along with experts in insurgency, ethnic conflict, terrorism, computer science, and data management, will build consensus around a unified infrastructure for political violence data collection and integration. The project will create a scalable ontology focused on four domains relevant to all forms of political violence: conflicts, actors, geographies, and events. This ontological infrastructure will allow researchers and policy makers who study political violence, including its etiology and consequences, to access and integrate existing data from the major political violence data collections currently collected at academic institutions and non-governmental organizations around the world. This infrastructure will also facilitate the development of new non-linear and semantic analytical methods to decipher the complex dynamics of conflict and violence. Finally, this infrastructure will provide a platform for the next generation of data collection on violence and conflict by creating a flexible framework for new data collection projects that is both easily exchangeable and adheres to the consensus-based ontologies developed. The proposed project incorporates a two-day stakeholder workshop, a schematic design of the ontological infrastructure for political violence data collection, and a web-based community-moderated issue-tracking wiki to encourage participatory development and refinement of the ontologies. Additionally, the proposed project supports one of the core missions of NSF?s Big Data initiative, focusing on the development of a data infrastructure relevant to national security.  Intellectual Merit: Although scientists have made major advances in the empirical understanding of political violence in recent years, nonetheless further advances are being hindered by the fact that leading projects from around the world are largely autonomous and uncoordinated. This project will address this weakness by creating a scalable ontology focused on domains critical to political violence. The major goal of this enterprise is to design a strategy for integrating the world?s most important data bases on political violence within an expandable platform that will allow not only updating original data but the addition of new data and variables, including rapidly evolving data sets derived from the social media. The proposal has built in sufficient resources to host a two-day stakeholder conference, to prepare read-ahead materials for stakeholders before the conference, to design and staff a wiki for reaching out to the research community and for developing a final report that will serve as a springboard for a proposal to implement the ontology designed. By integrating the major data bases, providing an infrastructure for growth, and making the end product available to the world?s research community, the proposed activity could have a transformative impact on the science of political violence.  Broader Impacts: This ontological approach to political violence data collection will offer critical insights for data integration and for advancing the scientific study of violent conflict. Effective identification of ontologies across major political violence data collections will provide an essential roadmap for the integration of these data structures and the development of new applications and analysis for research on national security. Additionally, the workshop will serve to network senior and junior faculty alongside graduate students thereby developing a new generation of political violence experts. The translation of the workshop report into a community-moderated and web-based issue-tracking wiki will serve to expand participation to include other researchers who will be instrumental in defining and shaping a larger ontological structure for both existing and future data collection efforts."
"1640831","CIF21 DIBBs: EI: North East Storage Exchange","OAC","ADVANCES IN BIO INFORMATICS, XD-Extreme Digital, Data Cyberinfrastructure","11/01/2016","08/01/2016","James Cuff","MA","Harvard University","Standard Grant","Amy Walton","10/31/2017","$3,973,963.00","Ralph Zottola, John Goodhue, Saul Youssef, RAJIV SHRIDHAR","james_cuff@harvard.edu","1033 MASSACHUSETTS AVE 5TH FL","CAMBRIDGE","MA","021385369","6174955501","CSE","1165, 7476, 7726","7433, 8048, 8089, 8091","$0.00","Research progress is increasingly dependent upon the available capacity of storage to flexibly exploit large volumes of digital information.  The North East Storage Exchange (NESE) project creates a next-generation storage infrastructure specifically targeted at enabling new levels of collaborative research in projects regularly involving petabytes of information.  This storage exchange will integrate with a computational and network infrastructure that links Harvard University, Boston University, the Massachusetts Institute of Technology (MIT), Northeastern University and the University of Massachusetts system.  This project contributes to building a national data infrastructure to support advanced research in such priority topics as health care, epidemiology, physics, and earth science, among others.<br/><br/>NESE will provide a high capacity, highly networked, secure, cost effective, scalable, and accessible data store that lowers barriers to research, collaboration, and information sharing within and beyond the participating multi-university community. Some examples of NESE projects that will be early users of NESE include one of the four US Tier 2 centers that store and process ATLAS data from the Large Hadron Collider; the Center for Brain Science at Harvard University, which is generating 300 million micron-resolution images to map the billion neurons and synapses that make up a cubic millimeter of the human brain; and MIT collaborations with NASA and DARPA in next generation global ocean modeling and monitoring systems.  NESE addresses several critical infrastructural challenges: the creation of a sustainable multi-institutional resource; advancement of methods for data retention, management, and access to sensitive research data; implementation of controls that simplify protection of sensitive data; and building a sustainable, collaborative operating infrastructure to support future research.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and by NSF's Understanding the Brain and BRAIN initiative activities."
"1724821","CIF21 DIBBs: EI: SLATE and the Mobility of Capability","OAC","COMPUTATIONAL PHYSICS, Data Cyberinfrastructure","07/01/2017","07/31/2020","Robert Gardner","IL","University of Chicago","Continuing Grant","Alejandro Suarez","06/30/2023","$3,998,494.00","Shawn McKee, Joseph Breen III","rwg@hep.uchicago.edu","5801 S ELLIS AVE","CHICAGO","IL","606375418","7737028669","CSE","7244, 7726","7433, 7569, 8048, 8084","$0.00","Much of science today is propelled by multi-institutional research collaborations that require computing environments that connect instrumentation, data, and computational resources.  These resources are distributed among university research computing centers, national-scale high performance computing facilities, and commercial cloud service providers. The scale of the data and complexity of the science drive this diversity, and the need to aggregate resources from many sources into scalable computing systems.  The heterogeneity of resources causes scientists to spend more time on the technical aspects of computation and data management than on discoveries and knowledge creation, while computing support staff are required to invest more effort integrating domain specific software stacks with limited applicability beyond the community served.  Services Layer At The Edge (SLATE) provides technology that simplifies connecting university and laboratory data center capabilities to the national cyberinfrastructure ecosystem and thus expands the reach of domain-specific science gateways and multi-site research platforms.<br/><br/>SLATE implements 'cyberinfrastructure as code' by augmenting the canonical Science DMZ pattern with a generic, programmable, secure and trusted underlayment platform. This platform hosts advanced container-centric services needed for higher-level capabilities such as data transfer nodes, software and data caches, workflow services and science gateway components.  SLATE uses best-of-breed data center virtualization components, and where available, software defined networking, to enable distributed automation of deployment and service lifecycle management tasks by domain experts. As such it simplifies creation of scalable platforms that connect research teams, institutions and resources to accelerate science while reducing operational costs and development cycle times. Since SLATE needs only commodity components for its functional layers, it is used in building distributed systems across all data center types and scales thus enabling creation of ubiquitous, science-driven cyberinfrastructure.<br/> <br/>This award by the Office of Advanced Cyberinfrastructure is jointly supported by the Computational Physics within the NSF Directorate for Mathematical and Physical Sciences."
"1443069","CIF21 DIBBs:  An Infrastructure Supporting Collaborative Data Analytics Workflow Design and Management","OAC","Data Cyberinfrastructure, CDS&E","01/01/2015","09/08/2014","Jia Zhang","PA","Carnegie-Mellon University","Standard Grant","Amy Walton","12/31/2018","$999,900.00","Shiyong Lu","jiazhang@smu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","CSE","7726, 8084","1057, 7433, 8048, 8084, 9102, CVIS","$0.00","The need for collaborative data analysis increases significantly when confronted with the challenges of big data. Although workflow tools offer a formal way to define, automate, and repeat multi-step computational procedures, designing complex data process workflow requires collaboration from multiple people with complementary expertise.  Existing tools are not suitable to support collaborative design of comprehensive workflows.  To address such a challenge, this project aims to design and develop a software infrastructure with the capability of supporting collaborative data-oriented workflow composition and management, adding a key component to existing NSF cyberinfrastructure that will support big data collaboration through the Internet.  Reproducibility and scalability are two major targets.  The project extends an existing open-source workflow tool, VisTrails, by adding system-level facilities to support human interaction and cooperation that are essential for an effective and efficient scientific collaboration.<br/><br/>This project will produce five outcomes:<br/>1) A collaborative provenance data model equipped with a graph-level provenance querying formalism;<br/>2) A type-theoretic approach for addressing format transformations;<br/>3) Hypergraph theory-based algorithms for provenance management and mining;<br/>4) A software tool supporting (a)synchronous collaborative scientific workflow design, composition, reproduction, and visualization; and <br/>5) Principles, methodologies, experiences, and lessons that support the development of a generically applicable collaborative scientific workflow composition tool.<br/>The resulting tools will explore the potential for using scientific workflows to accelerate scientific discoveries that require a collaborative effort on big data analytics.  The design of the tools is targeted toward use cases in the civil engineering discipline, but has the potential to broadly impact other areas of science and engineering.  Partnership with VisTrails enables usage and evaluation of the techniques in the VisTrails end user community."
"1261721","CIF21 DIBBS: The Data Exacell","OAC","Information Technology Researc, Data Cyberinfrastructure, ","10/01/2013","05/09/2018","Nicholas Nystrom","PA","Carnegie-Mellon University","Cooperative Agreement","Amy Walton","09/30/2018","$8,914,035.00","James Taylor, Ralph Roskies, JRay Scott, Nicholas Nystrom, Jason Sommerfield","nystrom@psc.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","CSE","1640, 7726, NX12","7433, 8048, 8237","$0.00","The Pittsburgh Supercomputing Center (PSC) will carry out an  accelerated, development pilot project to create, deploy and test software building blocks and hardware implementing functionalities specifically designed to support data-analytic capabilities for data intensive scientific research. Building on the successful Data Supercell (DSC) technology which replaced a conventional tape-based archive with a disk-based system to economically provide the much lower latency and higher bandwidth data success necessary for data-intensive activities, PSC will implement and bring to production quality additional functionalities important to such work.  These include improved local performance, additional abilities for remote data access and storage, enhanced data integrity, data tagging and improved manageability.  PSC will work with partners in diverse fields of science, initially chosen from biology, astronomy and computer science, who will provide scientific and technology drivers and system validation.  The project will leverage current NSF/CI investments in data analytics systems at PSC.  Those investments include DSC, Blacklight (an SGI UV1000 with 2×16TB of hardware-enabled cache-coherent shared memory), and Sherlock (a YarcData ?Urika? graph-analytic appliance which also supports a globally accessible shared memory), both very capable for data analytic applications. Their tight coupling to the pilot storage system will allow synergistic development of analytical capabilities with development of increasingly sophisticated mechanisms for data handling. Working with the new, multi-petabyte data store, they will constitute a system specifically optimized for data intensive work as contrasted with conventional HPC systems. Blacklight will be upgraded with more powerful technology, specifically architected to satisfy the more demanding needs of data analytics in years 3,4. When successful, PSC will engage the NSF to consider larger-scale deployment aiming at exascale capacity."
"1640864","CIF21 DIBBs: EI: Vizier, Streamlined Data Curation","OAC","Data Cyberinfrastructure","01/01/2017","04/26/2017","Oliver Kennedy","NY","SUNY at Buffalo","Standard Grant","Amy Walton","06/30/2021","$2,749,699.00","Juliana Freire, Boris Glavic","okennedy@buffalo.edu","520 LEE ENTRANCE STE 211","AMHERST","NY","142282577","7166452634","CSE","7726","7433, 8048, 9251","$0.00","Big Data promises to have a positive impact on many aspects of our lives, but assembling the data to answer questions or derive predictive models can be challenging.  Data scientists must typically go through multiple rounds of curation, or 'wrangling,' where data are organized, refined, cleaned up, and merged together before they can be analyzed.  Curation is often slow and costly, but is essential for obtaining useful and trustworthy answers.  This project develops a software tool called Vizier that aims to streamline data curation and enable domain experts who do not have computer science expertise to curate their own data.  Easier curation magnifies the value of big data by enabling a wide range of users to improve data quality, and in doing so benefits numerous types of data-driven work in government, industry, and science.<br/><br/>Vizier features an intuitive interface combining elements of notebooks and spreadsheets, allowing analysts to quickly see, edit, and revise data.  This capability is complemented by a framework for automated data cleaning steps that are seamlessly integrated with manual curation operations.  The heart of Vizier is a system for managing uncertainty and provenance of curation workflows and data, enabling the user to keep track of higher-level curation operations as well as track the lineage of data. By transparently maintaining the history of all the user's actions and their effect on the curated data, Vizier enables regret-free exploration and curation where any changes to the data and their transitive effects can be undone. By learning from past curation histories, the system will also be able to provide users with context-dependent recommendations for additional curation actions.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Social, Behavioral and Economic Sciences (Division of Social and Economic Sciences)."
"1261727","CIF21 DIBBs: Integrating Geospatial Capabilities into HUBzero","OAC","Data Cyberinfrastructure","10/01/2013","08/30/2017","Xiaohui Carol Song","IN","Purdue University","Cooperative Agreement","Amy Walton","09/30/2019","$5,173,883.00","Larry Biehl, Venkatesh Merwade, Nelson Villoria","cxsong@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","CSE","7726","7433, 8048","$0.00","This project will develop geospatial data analysis building blocks as core part of the HUBzero Scientific Collaboration platform to enable researchers and educators to create and share geospatial data sets and modeling tools.  The project will build upon geospatial capabilities that have been developed by IT experts and validated by the science community and bring such capabilities to the masses, hence any domain scientist can develop and deploy geospatial applications with graphical user interfaces on the web.  The deliverables include (1) tools and web service interfaces of ""data space"" for managing and sharing data, including geospatial data, and (2) Extended RAPPTURE Toolkit APIs to support geospatial mapping, image processing, visualization, and access to shared data in the data space. The building blocks software developed in this project will be open source as part of the HUBzero open source releases."
"1443027","CIF21 DIBBs: Building a Modular Cyber-Platform for Systematic Collection, Curation, and Preservation of Large Engineering and Science Data - A Pilot Demonstration Project","OAC","CYBERINFRASTRUCTURE, Data Cyberinfrastructure","09/01/2014","09/11/2017","Santiago Pujol","IN","Purdue University","Standard Grant","Amy Walton","08/31/2017","$1,500,000.00","Michael McLennan, Ann Christine Catlin, Chungwook Sim, Lisa Zilinski","spujol@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","CSE","7231, 7726","7433, 8048","$0.00","This project focuses upon the preservation and re-use of scientific and engineering data.  A computational platform is being developed to allow researchers to organize, preserve, and share their data in more consistent and reliable ways, to facilitate broader use by the research community and society as a whole.  The team plans to create a Modular Cyber-Platform (MCP) that would be simple and reliable enough to minimize the costs associated with maintenance, yet flexible enough to facilitate use in a large number of domains or disciplines.  The modular cyber-platform would allow communities to readily publish systematically classified datasets, permit automatic long-term curation of data, and create a cyberinfrastructure for dataset dissemination, validation (crowd vetting) and collaboration.  While the products of this project would be relevant to a range of science and engineering communities, the emphasis of the project will initially be on data related to civil infrastructure (bridges, highways, buildings, pipelines, power distribution networks)."
"1443040","CIF21 DIBBS: Tripal Gateway, a Platform for Next-Generation Data Analysis and Sharing","OAC","ADVANCES IN BIO INFORMATICS, Data Cyberinfrastructure","01/01/2015","08/25/2014","Stephen Ficklin","WA","Washington State University","Standard Grant","Amy Walton","07/31/2018","$1,485,021.00","Jill Wegrzyn, FRANK FELTUS, Margaret Staton, Doreen Main","stephen.ficklin@wsu.edu","240 FRENCH ADMINISTRATION BLDG","PULLMAN","WA","991640001","5093359661","CSE","1165, 7726","7433, 8048","$0.00","Scientific community databases fulfill an important research need by offering curated information to audiences with shared basic and applied research goals. They serve as clearinghouses for community information and communication.  Researchers need easy-to-use analytical workflows in an easily accessible and familiar location, but the community database typically lacks the infrastructure to support these needs and more data exchange is needed between sites.  Additionally, the community database requires the ability to easily incorporate results from analytical workflows for public dissemination, and the capacity to transfer large datasets quickly between computational resources and the database.  Tripal, an open-source toolkit used for construction of online genomic and genetic databases, is uniquely positioned to provide solutions to these challenges as it has been adopted by multiple community databases and thus provides a common infrastructure.<br/><br/>This project creates Tripal Gateway: a set of modules (extensions) to be incorporated into Tripal to foster greater data dissemination, collaboration, and research.   The team develops three modules that integrate Tripal with Galaxy (a popular workflow system), interconnects Tripal sites for data sharing, and utilizes emerging technologies for faster data exchange:<br/> - Tripal Galaxy - a module integrating Galaxy workflows into a Tripal site, providing both next-generation analytical workflows and seamless transition of results into the community database.<br/> - Tripal Exchange - a module to provide capabilities for cross-site querying, enabling collation and viewing of data from multiple sites, and integration of data into workflows.<br/> - Tripal SDN - a module incorporating software defined networking (SDN) technology, providing mechanisms to improve speed of data exchange.<br/><br/>These new modules are developed, implemented, and tested in conjunction with six data sites (the Citrus Genome Database, Cool Season Food Legumes, CottonGen, the Genome Database for Rosaceae, Hardwood Genomics, and TreeGenes).  Integration of the Tripal Gateway is also anticipated for four additional databases (GrainGenes, KnowPulse, LegumeInfo, and PeanutBase).  After implementation, this effort will interlink and allow cross-querying across a major Arabidopsis resource, four legume genomics sites, the primary cotton community site, GrainGenes, and four different tree genomic sites covering fruit trees and forest trees.  Implementation of Tripal Gateway into the community databases servicing these extensive research communities will support basic and applied research that is both crop-specific and broadly useful across crop agriculture."
"1640829","CIF21 DIBBs: PD: - Metadata Toolkits for Building Multi-Faceted Data - Relationship Models","OAC","PLASMA PHYSICS, COMPUTATIONAL PHYSICS, Data Cyberinfrastructure, EarthCube","10/01/2016","08/03/2016","Martin Greenwald","MA","Massachusetts Institute of Technology","Standard Grant","Amy Walton","09/30/2020","$500,000.00","","g@psfc.mit.edu","77 MASSACHUSETTS AVE","CAMBRIDGE","MA","021394301","6172531000","CSE","1242, 7244, 7726, 8074","7433, 7569, 8048","$0.00","Scientific research is challenged by ever-larger, more complex data sets, stored in disparate form in complicated repositories, making it difficult to discover useful content.  One reason is the relative scarcity of 'navigational' metadata - metadata that explicitly reveals the multitude of relationships between data elements.  This project develops improved data management tools allowing data managers to create metadata schemas that reveal the multiple and complex relationships existing between data elements. The team develops these tools while collaborating directly with three different research communities:  plasma physics (with the MIT Plasma Science and Fusion Center), ocean monitoring and modeling (with the MIT Department of Earth Sciences) and uncertainty quantification (with the University of Texas Institute for Computational Engineering and Sciences). <br/><br/>The project provides tools that allow data managers to easily develop metadata schemas that represent and expose the multiple and complex relationships that exist between data elements and which are typically not well represented in data systems. Such data elements include data source, provenance, physical properties represented in the data, data versioning, annotation threads, data dictionaries, data catalogs and data shape (which typically determines which applications can consume or display the data), and larger organizational entities such as research campaigns, experimental proposals and research products (e.g., publications, presentations and public databases).  Schemas and data are manipulated through a Representational State Transfer - Application Programming Interface (RESTful API). Relationships among the data are represented as mathematical graph structures that are all built upon a common meta-schema. There is an emphasis on recording the full data lifecycle using a RESTful API and granular data object uniform resource identifier (URI) schema that facilitate instrumenting complex and varied workflows.  A modern web based exploration tool is built upon these technologies in the initial application areas of plasma physics, ocean monitoring and modeling, and uncertainty quantification.  By viewing meta-data and programs more generally as a collection of graphs whose nodes are the data files or records, the project creates a set of programs which can explore these graphs and make the system much more general and easily extensible.  Also, by allowing users to create data objects at any level of specificity, the graphs of which the data is a member can be used to label object groupings.  This ability to represent data relationships would be of use to a broad contingent of the scientific community and could be useful to the scientific enterprise in many domains.  <br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Geosciences, and the NSF Directorate for Mathematical & Physical Sciences (Division of Physics)."
"1854312","CIF21 DIBBs: PD: Cyberinfrastructure Tools for Precision Agriculture in the 21st Century","OAC","Hydrologic Sciences, Data Cyberinfrastructure","06/01/2018","05/22/2020","Michela Taufer","TN","University of Tennessee Knoxville","Standard Grant","Amy Walton","06/30/2021","$513,105.00","","taufer@utk.edu","1331 CIR PARK DR","Knoxville","TN","379163801","8659743466","CSE","1579, 7726","062Z, 077Z, 7433, 8048, 9150","$0.00","This interdisciplinary project applies computer science approaches and computational resources to large multidimensional environmental datasets, and synthesizes this information into finer resolution, spatially explicit products that can be systematically analyzed with other variables.  The main emphasis is ecoinformatics, a branch of informatics that analyzes ecological and environmental science variables such as information on landscapes, soils, climate, organisms, and ecosystems.  The project focuses on synthesis/computational approaches for producing high-resolution soil moisture datasets, and the pilot application is precision agriculture. The effort combines analytical geospatial approaches, machine learning methods, and high performance computing (HPC) techniques to build cyberinfrastructure tools that can transform how ecoinformatics data is analyzed.<br/><br/>The investigators build upon publicly available data collections (soil moisture datasets, soil properties datasets, and topography datasets) to develop: (1) tools based on machine-learning techniques to downscale coarse-grained data to fine-grained datasets of soil moisture information; (2) tools based on HPC techniques to estimate the degree of confidence and the probabilities associated with the temporal intervals within which soil-moisture-base changes, trends, and patterns occur; and (3) data- and user- interfaces integrating data preprocessing to deal with data heterogeneity and inaccuracy, containerized environments to assure portability, and modeling techniques to represent temporal and spatial patterns of soil moisture dynamics. The tools will inform precision agriculture through the generation and use of unique information on soil moisture for the coterminous United States.  Accessibility for field practitioners (e.g., local soil moisture information) is made possible through lightweight virtualization, mobile devices, and web applications.<br/> <br/>This award by the Office of Advanced Cyberinfrastructure is jointly supported by the Division of Earth Sciences within the NSF Directorate for Geosciences."
"1753840","CIF21 DIBBs: EI: North East Storage Exchange","OAC","ADVANCES IN BIO INFORMATICS, XD-Extreme Digital, Data Cyberinfrastructure","07/01/2017","10/10/2017","James Cuff","MA","Trustees of Boston University","Standard Grant","Alejandro Suarez","09/30/2022","$3,846,298.00","","james_cuff@harvard.edu","1 SILBER WAY","BOSTON","MA","022151703","6173534365","CSE","1165, 7476, 7726","7433, 8048, 8089, 8091","$0.00","Research progress is increasingly dependent upon the available capacity of storage to flexibly exploit large volumes of digital information.  The North East Storage Exchange (NESE) project creates a next-generation storage infrastructure specifically targeted at enabling new levels of collaborative research in projects regularly involving petabytes of information.  This storage exchange will integrate with a computational and network infrastructure that links Harvard University, Boston University, the Massachusetts Institute of Technology (MIT), Northeastern University and the University of Massachusetts system.  This project contributes to building a national data infrastructure to support advanced research in such priority topics as health care, epidemiology, physics, and earth science, among others.<br/><br/>NESE will provide a high capacity, highly networked, secure, cost effective, scalable, and accessible data store that lowers barriers to research, collaboration, and information sharing within and beyond the participating multi-university community. Some examples of NESE projects that will be early users of NESE include one of the four US Tier 2 centers that store and process ATLAS data from the Large Hadron Collider; the Center for Brain Science at Harvard University, which is generating 300 million micron-resolution images to map the billion neurons and synapses that make up a cubic millimeter of the human brain; and MIT collaborations with NASA and DARPA in next generation global ocean modeling and monitoring systems.  NESE addresses several critical infrastructural challenges: the creation of a sustainable multi-institutional resource; advancement of methods for data retention, management, and access to sensitive research data; implementation of controls that simplify protection of sensitive data; and building a sustainable, collaborative operating infrastructure to support future research.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Biological Sciences (Division of Biological Infrastructure), and by NSF's Understanding the Brain and BRAIN initiative activities."
"1640834","CIF21 DIBBs: EI: Virtual Data Collaboratory: A Regional Cyberinfrastructure for Collaborative Data Intensive Science","OAC","Data Cyberinfrastructure","09/01/2016","12/28/2020","Ivan Rodero","NJ","Rutgers University New Brunswick","Standard Grant","Amy Walton","03/31/2022","$4,000,000.00","Vasant Honavar, Jenni Evans, Grace Agnew, James von Oehsen","ivan.rodero@utah.edu","3 RUTGERS PLZA","NEW BRUNSWICK","NJ","089018559","8489320150","CSE","7726","7433, 8048","$0.00","This project develops a virtual data collaboratory that can be accessed by researchers, educators, and entrepreneurs across institutional and geographic boundaries, fostering community engagement and accelerating interdisciplinary research.  A federated data system is created, using existing components and building upon existing cyberinfrastructure and resources in New Jersey and Pennsylvania.  Seven universities are directly involved (the three Rutgers University campuses, Pennsylvania State University, the University of Pennsylvania, the University of Pittsburgh, Drexel University, Temple University, and the City University of New York); indirectly, other regional schools served by the New Jersey and Pennsylvania high-speed networks also participate.  The system has applicability to a several science and engineering domains, such as protein-DNA interaction and smart cities, and is likely to be extensible to other domains.  The cyberinfrastructure is to be integrated into both graduate and undergraduate programs across several institutions.   <br/><br/>The end product is a fully-developed system for collaborative use by the research and education community.   A data management and sharing system is constructed, based largely on commercial off-the-shelf technology.  The storage system is based on the Hadoop Distributed File System (HDFS), a Java-based file system providing scalable and reliable data storage, designed to span large clusters of commodity servers.  The Fedora and VIVO object-based storage systems are used, enabling linked data approaches.  The system will be integrated with existing research data repositories, such as the Ocean Observatories Initiative and Protein Data Bank repositories.  Regional high-performance computing and network infrastructure is leveraged, including New Jersey's Regional Education and Research Network (NJEdge), Pennsylvania's Keystone Initiative for Network Based Education and Research (KINBER), the Extreme Science and Engineering Discovery Environment (XSEDE) computing capabilities, Open Science Grid, and other NSF Campus Cyberinfrastructure investments.  The project also develops a custom site federation and data services layer; the data services layer provides services for data linking, search, and sharing; coupling to computation, analytics, and visualization; mechanisms to attach unique Digital Object Identifiers (DOIs), archive data, and broadly publish to internal and wider audiences; and manage the long-term data lifecycle, ensuring immutable and authentic data and reproducible research."
"1640867","CIF21 DIBBs: EI: Data Laboratory for Materials Engineering","OAC","DMR SHORT TERM SUPPORT, Data Cyberinfrastructure","09/01/2016","09/23/2016","Venugopal Govindaraju","NY","SUNY at Buffalo","Standard Grant","Alejandro Suarez","08/31/2022","$2,909,772.00","Srirangaraj Setlur, Krishna Rajan, Thomas Furlani","govind@buffalo.edu","520 LEE ENTRANCE STE 211","AMHERST","NY","142282577","7166452634","CSE","1712, 7726","026Z, 7433, 8048, 8400","$0.00","This project directly addresses the goals of the Materials Genome Initiative -- to accelerate the pace of discovery and deployment of advanced material systems.  To obtain insights for the discovery of new materials and to study existing materials, scientists and engineers rely heavily on an ever-growing number of materials research databases and scholarly research publications that date back many decades.  New materials innovation often takes years, sometimes decades, to develop a new material.  The project addresses the challenges through several steps, including automatic extraction of data from relevant electronic publications, storage of the data in formats that support comparison and analysis, development of advanced computational tools to improve the analysis, integration of the tools into a data laboratory to support the discovery of new trends and relationships among materials properties, and to predict new materials with desired properties.<br/><br/>The infrastructure building blocks developed under this project enable researchers to (i) use document processing technologies to process scientific publications and data from scientific databases in materials science to create a knowledge base; (ii) use machine learning technologies to learn from the data in this enhanced knowledge base to address a variety of use cases in materials science and engineering; and (iii) use innovative information retrieval and visualization tools for insightful analysis, facilitating faster discovery of new materials.  The tools will be hosted and disseminated through a web portal built on the HubZero platform, which will also provide users with the ability to query and visualize data, and run simulations and experiments. The data laboratory portal also provides the ability to run simulations and experiments on high-performance computing clusters using the building blocks.   The data laboratory provides a platform for materials informatics, enabling prediction of properties of metal alloys and interaction with the materials discovery and engineering user community.  While the primary target is the interdisciplinary field of materials research, the tools are designed to be domain agnostic as the core technologies can be applied to documents and databases across a broad swath of disciplines to enhance the pace of scientific discoveries.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Directorate for Mathematical & Physical Sciences (Division of Materials Research)."
"1443014","CIF21 DIBBs: An Integrated System for Public/Private Access to Large-Scale, Confidential Social Science Data","OAC","Data Cyberinfrastructure, Cybersecurity Innovation","01/01/2015","09/10/2014","Jerome Reiter","NC","Duke University","Standard Grant","Amy Walton","12/31/2018","$1,498,683.00","John de Figueiredo, Ashwin Machanavajjhala","jerry@stat.duke.edu","2200 W MAIN ST","DURHAM","NC","277054640","9196843030","CSE","7726, 8027","7433, 7434, 7726, 8027, 8048","$0.00","This research project will develop a pilot of an integrated system for disseminating large-scale data about people.  This project will address critical challenges that have inhibited the wide-spread dissemination of large-scale databases that can advance basic social, behavioral, and economic science research and that offer enormous potential benefits to society.  Among the challenges the dissemination of these data have posed are the unintended disclosures of data subjects' identities and sensitive attributes, thereby violating promises and sometimes laws designed to protect data subjects' privacy and confidentiality.  The products of this project will facilitate the development and dissemination of safe and useful large-scale datasets.  The project will result in extensible and open-source products that constitute a proof of concept and that will provide valuable information for future larger-scale implementations of the system.  The project therefore will lay the groundwork for a potential transformation in data dissemination, providing data stewards with the infrastructure they need to release data products that advance social science, policy making, and training.  The project also will provide education and training opportunities for a post-doctoral researcher as well as graduate and undergraduate students.<br/><br/>The investigators will create new methodology and broadly applicable tools for meeting data dissemination challenges.  From a technical perspective, they will advance methodology for generating synthetic datasets via nonparametric methods capable of handling highly dimensional data.  They will advance methodology for providing feedback on the quality of inferences from heavily redacted data, and they will develop methods for in depth assessment and characterization of disclosure risks inherent in releasing large-scale synthetic data with and without verification servers.  From an infrastructure perspective, the investigators will develop systems and architecture for integrating the three core tools (synthetic data, verification servers, and remote access) in ways that result in secure, scalable access to data.  The pilot system will be built with the goal of disseminating a version of a dataset on the work histories of federal government employees."
"1442997","CIF21 DIBBs: An Infrastructure for Computer Aided Discovery in Geoscience","OAC","AERONOMY, Data Cyberinfrastructure, EarthCube","11/01/2014","07/29/2019","Victor Pankratius","MA","Massachusetts Institute of Technology","Standard Grant","Amy Walton","10/31/2019","$1,424,765.00","Philip Erickson, Frank Lind","pankrat@mit.edu","77 MASSACHUSETTS AVE","CAMBRIDGE","MA","021394301","6172531000","CSE","1521, 7726, 8074","075Z, 7433, 8048","$0.00","Next-generation Geoscience needs to handle rapidly growing data volumes from ground-based and space-based sensor networks. As real-world phenomena are mapped to data, the scientific discovery process essentially becomes a search process across multidimensional data sets. The extraction of meaningful discoveries from this sea of data therefore requires highly efficient and scalable machine assistance to enhance human contextual understanding. This is necessary both for testing new hypotheses as well as for the detection of novel events and monitoring for natural hazards.<br/><br/>This project develops a computer-aided discovery approach that provides scientists with better support to answer questions such as: What inferences can be drawn from an identified feature?  What does a finding mean and how does it fit into the big theoretical picture? Does it contradict or confirm previously established models and findings? How can  concepts and ideas be tested effectively? To achieve this, scientists can programmatically express hypothesized Geoscience scenarios, constraints, and model variations. This approach helps delegate the automatic exploration of the combinatorial search space of possible explanations in parallel on a variety of data sets. Furthermore, programmable crawlers can scale the search and discovery of interesting phenomena on cloud-based infrastructures. The computer-aided discovery prototype is evaluated in case studies from Geospace science, including the exploration of structures in space and time using combined GPS, optics, and Geospace radar data."
"1640840","CIF21 DIBBs: PD: Ontology-Enabled Polymer Nanocomposite Open Community Data Resource","OAC","Mechanics of Materials and Str, DMR SHORT TERM SUPPORT, Data Cyberinfrastructure, CDS&E, DMREF","09/01/2016","06/27/2018","Deborah McGuinness","NY","Rensselaer Polytechnic Institute","Standard Grant","Amy Walton","08/31/2019","$520,890.00","Lynda Brinson, Wei Chen, Deborah McGuinness","dlm@cs.rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","1630, 1712, 7726, 8084, 8292","022E, 024E, 1765, 7433, 8021, 8048, 8396, 8399, 8400, 9102, 9251, 9263","$0.00","The project develops an open access data resource for the polymer nanocomposites community, facilitating faster nanocomposite design and insertion into advanced applications.  The capability would support three major types of users: researchers interested in comparing their results in detail to other work; researchers exploring, discovering, and quantifying fundamental scientific principles that govern processing-structure-property (p-s-p) relationships; and materials designers interested in using nanocomposites for advanced applications.  The resource would accelerate the comparison, exploration, and design of polymer nancomposite materials, for applications ranging from energy to healthcare.<br/><br/>The goal is to create an open access, easy to use, persistent, flexible data resource for the polymer nanocomposites community that is scalable and will enable improved understanding of p-s-p relationships and design of commercially relevant polymer nanocomposites.  The resource builds upon earlier work using the Material Data Curator System (MDCS) at the National Institute of Standards and Technology (NIST), and a prototype (NanoMine) developed through the NSF Division of Materials Research.  A robust ontology will be integrated with an expanded version of the NanoMine prototype to create an open linked data community resource to support organization, integration, mining, and analysis services. Improved data analytics tools are integrated into NanoMine for quantitative image analysis, microstructure reconstruction, knowledge discovery, and materials design recommendation.  A set of standards provide quality metrics for the data; these metrics will be integrated into the ontology and used to validate data at the time of data ingest. The project also leverages open source visualization tools and provides semantically enhanced browsing and visualization capabilities to aid users in discovery of new relationships. <br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Engineering Directorate (Division of Civil, Mechanical & Manufacturing Innovation), and the NSF Directorate for Mathematical & Physical Sciences (Division of Materials Research)."
"1541215","CC*DNI DIBBs: Data Analysis and Management Building Blocks for Multi-Campus Cyberinfrastructure through Cloud Federation","OAC","Data Cyberinfrastructure","10/01/2015","03/25/2020","David Lifka","NY","Cornell University","Cooperative Agreement","Amy Walton","09/30/2021","$8,229,079.00","Richard Wolski, Thomas Furlani","lifka@cac.cornell.edu","341 PINE TREE RD","ITHACA","NY","148502820","6072555014","CSE","7726","062Z, 7433, 8048, 9251","$0.00","The ability to aggregate, share, and analyze important large data sets while optimizing time-to-science is essential to support multi-disciplinary and multi-institutional data-driven discovery. This project is deploying a federated cloud computing system in New York State and California comprised of data infrastructure building blocks designed to support scientists requiring flexible workflows and analysis tools for large-scale data sets. Data challenges from seven different communities-earth and atmospheric sciences, finance, chemistry, astronomy, civil engineering, genomics, and food science-are being addressed using a rich set of open source software, optimized frameworks, and cloud usage modalities. The federated cloud is operating at Cornell University (project lead) and at partner sites at the University at Buffalo and the University of California, Santa Barbara. The project team is supporting multi-disciplinary research groups with over forty global collaborators and documenting science use cases. The broader goal of this project is to develop a federated cloud model that encourages and rewards institutions for sharing large-scale data analysis resources that can be expanded internally with common, incremental building blocks and externally through meaningful collaborations with other institutions, public clouds, and NSF cloud resources.<br/><br/>Project documentation and webinars feature best practices and include how to create Virtual Machine instances, run at federated sites, burst to Amazon Web Services, and access, move, and store large-scale data. A new tool for cloud metrics is being built into Open XDMoD (XD Net Metrics on Demand) that features QBETS (Queue Bounds Estimation from Time Series) statistics to enable users to make online forecasts of future performance and allocation level availability as well as to predict when to burst from federation resources. A new allocations and accounting model allows institutional administrators to track utilization across federated sites and use this data as an exchange mechanism. These tools provide a better understanding of how the sharing of data infrastructure building block capacity across institutional boundaries can create wider science and engineering collaborations and increase data sharing in a scalable and sustainable way."
"1443068","CIF21 DIBBs: Building a Scalable Infrastructure for Data-Driven Discovery and Innovation in Education","OAC","STEM + Computing (STEM+C) Part, Project & Program Evaluation, REAL, Data Cyberinfrastructure","01/01/2015","06/02/2020","Ken Koedinger","PA","Carnegie-Mellon University","Standard Grant","Amy Walton","12/31/2020","$5,736,819.00","John Stamper, Carolyn Rose","Koedinger@cmu.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","CSE","005Y, 7261, 7625, 7726","7433, 7726, 8048, 9251","$0.00","This project is creating a community software infrastructure, called LearnSphere, that supports sharing, analysis, and collaboration across the wide variety of educational data.  LearnSphere supports researchers as they improve their understanding of human learning.  It also helps course developers and instructors improve teaching and learning through data-driven course redesign.  The goal is to transform learning science and engineering through a large, distributed data infrastructure, and develop the capacity for course developers, instructors, and learning engineers to make use of it.<br/><br/>LearnSphere maintains a central store of metadata about what datasets exist, but also has distributed features allowing contributors control over access to their own data. It provides a hub to link many communities of educational researchers, provides a repository for researchers to store their data, and provides an open analytic method library and workflow-authoring environment for researchers to build models and run them across datasets.<br/><br/>The research team has extensive experience not only in using educational data mining to make discoveries and improve student outcomes, but also in the creation of educational data infrastructures. They have developed the DataShop infrastructure, which is currently the largest open repository of educational technology data including over 550 datasets. A newer data infrastructure, MOOCdb, is being developed to store and analyze Massively Open Online Course (MOOC) data. The Open Learning Initiative has produced data stored in DataShop for many years and is expanding into the MOOC space. Dialogue-based tutoring systems and student affect sensors are producing new kinds of data that are being added to LearnSphere. The researchers are further improving data collection infrastructure in MOOCs especially by adding platform components for massive multi-factor online experiments. The project is also creating new methods for data integration, discourse data storage and analytics, and new algorithms for automated discovery, as well as new learning science discoveries that result from these algorithms. <br/><br/>By integrating these building blocks in LearnSphere, the project will facilitate cross-modality and cross-domain educational data analysis that is not possible today."
"1443085","C1F21 DIBBS: Porting Practical Natural Language Processing (NLP) and Machine Learning (ML) Semantics from Biomedicine to the Earth, Ice and Life Sciences","OAC","ADVANCES IN BIO INFORMATICS, Polar Cyberinfrastructure, Data Cyberinfrastructure, EarthCube","11/01/2014","07/17/2015","Christopher Jenkins","CO","University of Colorado at Boulder","Standard Grant","Amy Walton","10/31/2018","$1,497,785.00","Martha Palmer, James Martin, Ruth Duerr","chris.jenkins@colorado.edu","3100 MARINE ST STE 481 572 UCB","BOULDER","CO","803090001","3034926221","CSE","1165, 5407, 7726, 8074","7433, 8048","$0.00","Semantics is the study of word-based information. The sciences are filled with word-based descriptive data: field observations, materials and habitat identifications, parameter names and units, events and processes. Semantics are also important in medicine, where the human body and illnesses have to be described.  To enhance interoperability among these word-based (semantic) systems, and to more readily explore the rapidly growing quantities of semantic data, there has been a movement towards organizing word-based data in ways that allow machine-assisted, automated analysis.  Biomedicine has made great progress in organizing and using semantic information because of substantial funding investments. This project builds upon extensive investments in the biomedical field, providing an opportunity to rapidly develop the organization of semantic concepts for other domain sciences. <br/><br/>A toolkit developed by the Center for Computational Language and Education Research (CLEAR TK) will be used to build semantic resources (taxonomies, ontologies, and semantic networks) for three science domains (geology, cryology, and biology).  CLEAR TK is a state-of-the-art natural language processing (NLP) and machine learning (ML) system that also has essential tools for machine-assisted annotation, validation, document tagging, and event extraction.  The CLEAR TK system has been used operationally for biomedical semantic applications, including in high-profile hospitals.  In this project, developments are focused upon the science fields of geology, ice and snow, and biology.  In these fields, accurate extraction of semantic information from the word-based data is required so users can quickly find the data they really need. This project provides a valuable opportunity to expand and evaluate semantic capabilities in conjunction with several scientific domain experts."
"1640899","CIF21 DIBBS: EI: The Local Spectroscopy Data Infrastructure (LSDI)","OAC","DMR SHORT TERM SUPPORT, PROJECTS, Data Cyberinfrastructure, CDS&E","10/01/2016","07/27/2016","Kristin Persson","CA","University of California-Berkeley","Standard Grant","Alejandro Suarez","09/30/2022","$3,940,400.00","Mark Asta, Sophia Hayes, Shyue Ping Ong","kristinpersson@berkeley.edu","1608 4TH ST STE 201","BERKELEY","CA","947101749","5106433891","CSE","1712, 1978, 7726, 8084","7237, 7433, 7569, 8048, 8400, 9102, 9263","$0.00","Traditional empirical and 'one-at-a-time' materials testing is unlikely to meet the innovation needs in chemical and materials research, to enable emerging industries to address challenges in energy, national security, healthcare, and other areas in a timely manner.  Historically, novel materials exploration has been slow and expensive, taking on average 18 years from concept to commercialization.  This project has identified a major scientific challenge - characterization of materials and chemical systems via spectroscopy - that can greatly enhance and expand materials research through accumulation, organization, and automation of both experimental and computational resources and data.  Currently, a large amount of time is invested in the interpretation and understanding of spectroscopic data, since no resource for efficiently accomplishing these tasks is available. This project allows materials researchers and chemists working in the spectroscopic field to access a searchable database of existing parameters and spectra for comparative, automated identification, and to address the full range of data elements -- production, curation, analysis, dissemination and sharing.  The resulting data resource contributes to the cyberinfrastructure of the broader materials, chemistry, and engineering community, and has the potential to catalyze the discovery of new materials and the innovative use of materials and chemical systems in science and industry. <br/><br/>The goal of the Local Spectroscopy Data Infrastructure (LSDI) project is to establish the first computational local atomic environment spectroscopy database, based on well-benchmarked computational spectra, to enable a publicly available, online resource for rapid material characterization, to accelerate materials development and optimization. Through novel technological advancements involving nanoscale engineering of defects, interfaces and surfaces, it has become increasingly important to determine the local atomic environments in materials. Spectroscopic techniques - including X-Ray Absorption Near Edge Spectroscopy (XANES), Extended X-Ray Absorption Fine Structure (EXAFS), Electron Energy Loss Spectroscopy (EELS), and Nuclear Magnetic Resonance (NMR) - have become essential characterization tools in elucidating atomic-scale chemical structure, electronic properties, and quantum phenomena in materials. There is a growing need for a general-use resource to help make spectral assignments for all researchers, including non- specialists, by capitalizing on recent advances in computational methods to populate an interactive database consisting of solid-state X-ray absorption and NMR spectra and associated parameters. This project includes: (i) creation of robust, benchmarked workflows for first-principles calculation of XAS/NMR spectra; (ii) data generation, curation and storage; (iii) development of automated spectral analysis algorithms; (iv) dissemination through the Materials Project; and (v) dynamic interaction with the community through the new Materials Data Cloud (MDCloud) environment. The data infrastructure developed by this project will allow a researcher who has recorded an experimental spectrum, such as by NMR, XANES or XAFS, of a solid-state material - even one with a disordered or non-crystalline structure - to access through the internet a searchable database of existing parameters and spectra for comparative, automated identification, along with a computational resource for simulating the spectra associated with various structural and chemical hypotheses.  The LSDI contributes to the cyberinfrastructure of the materials, chemistry, and engineering communities, and supports advances in the fundamental understanding of spectroscopic methods, materials and chemical systems. The system catalyzes the discovery of new materials, and supports innovative use of materials and chemical systems in science and industry, consistent with the goals of the Materials Genome Initiative.<br/><br/>This award by the Advanced Cyberinfrastructure Division is jointly supported by the NSF Engineering Directorate (Division of Civil, Mechanical & Manufacturing Innovation) and the NSF Directorate for Mathematical & Physical Sciences (Division of Chemistry and Division of Materials Research)."
"1541349","CC*DNI DIBBs: The Pacific Research Platform","OAC","CYBERINFRASTRUCTURE, Data Cyberinfrastructure","10/01/2015","01/12/2022","Larry Smarr","CA","University of California-San Diego","Cooperative Agreement","Alejandro Suarez","09/30/2022","$8,197,182.00","Frank Wuerthwein, Camille Crittenden, Thomas DeFanti, Philip Papadopoulos","lsmarr@ucsd.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","CSE","7231, 7726","7433, 8048, 9251","$0.00","Research in data-intensive fields is increasingly multi-investigator and multi-institutional, depending on ever more rapid access to ultra-large heterogeneous and widely distributed datasets. The Pacific Research Platform (PRP) is a multi-institutional extensible deployment that establishes a science-driven high-capacity data-centric 'freeway system.' The PRP spans all 10 campuses of the University of California, as well as the major California private research universities, four supercomputer centers, and several universities outside California. Fifteen multi-campus data-intensive application teams act as drivers of the PRP, providing feedback to the technical design staff over the five years of the project. These application areas include particle physics, astronomy/astrophysics, earth sciences, biomedicine, and scalable multimedia, providing models for many other applications.<br/> <br/>The PRP builds on prior NSF and Department of Energy (DOE) investments. The basic model adopted by the PRP is 'The Science DMZ,' being prototyped by the DOE ESnet. (A Science DMZ is defined as 'a portion of the network, built at or near the campus local network perimeter that is designed such that the equipment, configuration, and security policies are optimized for high-performance scientific applications rather than for general-purpose business systems'). In the last three years, NSF has funded over 100 U.S. campuses through Campus Cyberinfrastructure - Network Infrastructure and Engineering (CC-NIE) grants to aggressively upgrade their network capacity for greatly enhanced science data access, creating Science DMZs within each campus.  The PRP partnership extends the NSF-funded campus Science DMZs to a regional model that allows high-speed data-intensive networking, facilitating researchers moving data between their laboratories and their collaborators' sites, supercomputer centers or data repositories, and enabling that data to traverse multiple heterogeneous networks without performance degradation over campus, regional, national, and international distances. The PRP's data sharing architecture, with end-to-end 10-40-100Gb/s connections, provides long-distance virtual co-location of data with computing resources, with enhanced security options."
"1724898","CIF21 DIBBs: PD: OneDataShare: A Universal Data Sharing Building Block for Data-Intensive Applications","OAC","Data Cyberinfrastructure","09/01/2017","09/15/2022","Tevfik Kosar","NY","SUNY at Buffalo","Standard Grant","Alejandro Suarez","08/31/2022","$616,469.00","","tkosar@buffalo.edu","520 LEE ENTRANCE STE 211","AMHERST","NY","142282577","7166452634","CSE","7726","068P, 7433, 8048, 9251, 9290","$0.00","Applications in scientific, industrial, and personal spaces now generate more data than ever before. As data become more abundant and data resources become more heterogeneous, the accessing, sharing and disseminating of data sets becomes a bigger challenge.  Existing technologies for transferring and sharing data suffer from serious shortcomings, including low transfer performance, inflexibility, restricted protocol support, and poor scalability.  This project develops a universal data sharing building block for data-intensive applications, dubbed OneDataShare, with three major goals: (1) optimization of end-to-end data transfers and reduction of the time to delivery of the data; (2) interoperation across heterogeneous and incompatible data resources; and (3) predicting the data delivery time and decreasing the uncertainty in real-time decision-making processes.<br/><br/>OneDataShare deliverables include: (1) design and implementation of novel algorithms for application-layer optimization of the data transfer protocol parameters to achieve optimal end-to-end data transfer throughput; (2) development of a universal interface specification for heterogeneous data storage endpoints and a framework for on-the-fly data transfer protocol translation; (3) instrumentation of end-to-end data transfer time prediction capability, and feeding it into real-time scheduling and decision-making processes for advanced provisioning, high-level planning, and co-scheduling of resources; (4) deployment of these capabilities as stand-alone OneDataShare cloud-hosted services to end users; and (5) integration of these capabilities with widely used data scheduling and workflow management tools, and validation in specific applications.  OneDataShare services and tools are developed at the application level, and they do not require any changes to the existing infrastructure, nor to the low-level networking stack, although they increase the end-to-end performance of the data movement tasks substantially.  These efficient and high-performance data transfer techniques will help the scientific community, industry, and end-users to save significant time and effort in transferring and sharing data."
"1541335","CC*DNI DIBBs: Multi-Institutional Open Storage Research InfraStructure (MI-OSiRIS)","OAC","Data Cyberinfrastructure","09/01/2015","06/06/2019","Shawn McKee","MI","Regents of the University of Michigan - Ann Arbor","Cooperative Agreement","Amy Walton","08/31/2021","$4,958,411.00","Douglas Swany, Kenneth Merz, Patrick Gossman","smckee@umich.edu","503 THOMPSON STREET","ANN ARBOR","MI","481091340","7347636438","CSE","7726","062Z, 7433, 8048, 9251","$0.00","Every field of science generates and utilizes data in various forms: programs, instrument outputs, papers, notes, applications, simulations, video and audio recordings, etc. The continuing and evolving challenge for scientists is how to store, access, transform, manage and curate the variety of data required to effectively conduct their research, and transparently share it with other researchers across campus or at other institutions. The MI-OSiRIS project is addressing that challenge by combining an object-based software-defined storage technology with a monitored, managed network infrastructure to give scientists a distributed storage system which allows them to directly access their data from resources at any of the participating institutions.   Furthermore, MI-OSiRIS utilizes each institution's existing authentication infrastructure to allow scientists to provide controlled access to their data across all participating institutions.  By documenting and publishing designs, code, and operational experiences, the MI-OSiRIS project serves as a replicable model for supporting data-intensive, multi-institutional science collaborations.<br/><br/>MI-OSiRIS implements a Ceph-based petabyte-scale distributed data system by deploying object storage servers at each participating institution, connecting them via a managed high speed network, and distributing data based on the specific requirements of each science research domain. Ceph, an open source storage platform, supports multiple data access methods (traditional file, native object, and block), and allows configuration of access, replication, distribution, and integrity on a per-research-domain basis. MI-OSiRIS is built on low-cost, commodity hardware and can deliver gigabytes per second of I/O bandwidth per node. The system monitors and manages the network paths between its partner institutions, science users and Ceph storage components by strategically deploying perfSONAR instances which have been augmented with a network discovery, monitoring, and management platform (Network Management Abstraction Layer).  Globus Online servers provide access to data from outside MI-OSiRIS.  In addition, MI-OSiRIS leverages Ceph's software defined storage aspects to automate some data-lifecycle management tasks."
"1724843","CIF21 DIBBs: PD: Cyberinfrastructure Tools for Precision Agriculture in the 21st Century","OAC","Hydrologic Sciences, Data Cyberinfrastructure","07/01/2017","05/09/2017","Michela Taufer","DE","University of Delaware","Standard Grant","Amy Walton","10/31/2018","$499,999.00","Rodrigo Vargas","taufer@utk.edu","220 HULLIHEN HALL","NEWARK","DE","197160099","3028312136","CSE","1579, 7726","7433, 8048, 9150","$0.00","This interdisciplinary project applies computer science approaches and computational resources to large multidimensional environmental datasets, and synthesizes this information into finer resolution, spatially explicit products that can be systematically analyzed with other variables.  The main emphasis is ecoinformatics, a branch of informatics that analyzes ecological and environmental science variables such as information on landscapes, soils, climate, organisms, and ecosystems.  The project focuses on synthesis/computational approaches for producing high-resolution soil moisture datasets, and the pilot application is precision agriculture. The effort combines analytical geospatial approaches, machine learning methods, and high performance computing (HPC) techniques to build cyberinfrastructure tools that can transform how ecoinformatics data is analyzed.<br/><br/>The investigators build upon publicly available data collections (soil moisture datasets, soil properties datasets, and topography datasets) to develop: (1) tools based on machine-learning techniques to downscale coarse-grained data to fine-grained datasets of soil moisture information; (2) tools based on HPC techniques to estimate the degree of confidence and the probabilities associated with the temporal intervals within which soil-moisture-base changes, trends, and patterns occur; and (3) data- and user- interfaces integrating data preprocessing to deal with data heterogeneity and inaccuracy, containerized environments to assure portability, and modeling techniques to represent temporal and spatial patterns of soil moisture dynamics. The tools will inform precision agriculture through the generation and use of unique information on soil moisture for the coterminous United States.  Accessibility for field practitioners (e.g., local soil moisture information) is made possible through lightweight virtualization, mobile devices, and web applications.<br/> <br/>This award by the Office of Advanced Cyberinfrastructure is jointly supported by the Division of Earth Sciences within the NSF Directorate for Geosciences."
"1724845","CIF21 DIBBs: PD: Building High-Availability Data Capabilities in Data-Centric Cyberinfrastructure","OAC","Data Cyberinfrastructure","08/01/2017","02/28/2020","Haiying (Helen) Shen","VA","University of Virginia Main Campus","Standard Grant","Amy Walton","07/31/2020","$531,994.00","","hs6ms@virginia.edu","1001 N EMMET ST","CHARLOTTESVILLE","VA","229034833","4349244270","CSE","7726","7433, 8048, 9251","$0.00","This project supports data-related analysis in a wide range of science and engineering applications. It will contribute to the development of scalable data-centric cyberinfrastructure capabilities, to accelerate interdisciplinary and collaborative research.  The exascale file system will serve as catalyst for research in data storage architectures, and will enable new data-focused services and capabilities that advance scientific discoveries, collaborations, and innovations.  The project addresses a major data challenge common to a range of communities such as social science, economics, and bioengineering, and will provide thorough training and collaborative research opportunities for project participants.<br/> <br/>Both high performance computing (HPC) clusters and Hadoop clusters use file systems. A Hadoop cluster uses the Hadoop Distributed File System (HDFS) that resides on compute nodes, while an HPC cluster usually uses a remote storage system. Despite years of efforts on research and application development on HPC and Hadoop clusters, the file systems in both types of clusters still face a formidable challenge, that of achieving exascale computing capabilities. The centralized data indexing in HDFS and HPC storage architectures cannot provide high scalability and reliability, and both HDFS and HPC storage architectures have shortcomings such as single point of failure and insufficiently efficient data access. This project builds scalable high-availability data capabilities in data-centric cyberinfrastructure to overcome the shortcomings and create a highly scalable file system with new techniques for distributed load balancing, data replication and consistency maintenance."
"2006409","Organizing CSSI PI Meeting - Towards a National Cyberinfrastructure Ecosystem","OAC","Software Institutes","04/01/2020","05/22/2020","Haiying (Helen) Shen","VA","University of Virginia Main Campus","Standard Grant","Amy Walton","03/31/2021","$65,480.00","Upulee Kanewala, Sandra Gesing, Xiaohui Carol Song, Ritu Ritu","hs6ms@virginia.edu","1001 N EMMET ST","CHARLOTTESVILLE","VA","229034833","4349244270","CSE","8004","026Z, 7556, 8004","$0.00","This project will host a 2-day workshop in Seattle, WA, which will bring together the community of Cyberinfrastructure for Sustained Scientific Innovation (CSSI) awardees (with the goal of involving at least one principal investigator (PI) from each Elements, Frameworks, Institute Conceptualizations, and Scientific Software Innovation Institutes project, many of which are collaborative awards) from approximately 250 awards. This will be the first CSSI PI meeting. In addition, PIs from the prior connected solicitations (such as Software Infrastructure for Sustained Innovation (SI2) and Data Infrastructure Building Blocks (DIBBS)) will be invited, as well as PIs on NSF awards in which CSSI seed investments were made (Venture funded PIs as well as CSSI Early Concept Grants for Exploratory Research (EAGER) awardees). In addition, the proximity to Society for Industrial and Applied Mathematics (SIAM) Conference on Parallel Processing for Scientific Computing (PP20) will encourage participation by non-PI community to further inform the academic community of CSSI goals and projects. Goals of this workshop include: (1) Serve as a focused forum for PIs to share technical information with each other, community, and NSF Program Officers; (2) Explore innovative topics emerging within software and data infrastructure communities; (3) Discuss emerging best practices across the supported software and data infrastructure projects; (4) Stimulate thinking on new ways of achieving software and data sustainability; (5) Gather the shared experiences in an online web portal. The workshop is expected to host close to 250 CSSI and other awardees, other speakers and panelists. <br/><br/>The proposed workshop will support the exchange of ideas among the current cyberinfrastructure development projects. It will provide guidance on issues related to the development of robust software and data artifacts and to the problem of their sustainability. Involvement of program officers across NSF is expected to help the interdisciplinary CSSI awardees understand the relevance and impact of cyberinfrastructure throughout the NSF. The participation of these awardees, program officers, and other researchers in a common forum will help ensure that the cyberinfrastructure developed as part of CSSI projects will be relevant and broadly applicable to most science and engineering domains. The results of this workshop thus have the potential to guide cyberinfrastructure development and cyberinfrastructure driven research for both the participating projects and for the wider cyberinfrastructure development community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1440753","SI2-SSE: Adding Research Accounts to the ASSISTments' Platform: Helping Researchers Do Randomized Controlled Studies with Thousands of Students","OAC","Project & Program Evaluation, Software Institutes","09/01/2014","09/06/2016","Neil Heffernan","MA","Worcester Polytechnic Institute","Standard Grant","Rajiv Ramnath","08/31/2017","$486,209.00","Joseph Williams","nth@wpi.edu","100 INSTITUTE RD","WORCESTER","MA","016092247","5088315000","CSE","7261, 8004","7433, 8005, 9177, SMET","$0.00","ASSISTments is a free, university-based platform created to perform controlled experiments  with the potential to help increase the quality, speed, and reliability of results related to K12 education. ASSISTments' mission is ""to improve education through scientific research while not compromising student learning time."" Each day, teachers assign problems to thousands of students (currently 50,000 students) in ASSISTments. These problem sets often contain controlled experiments. ASSISTments has used this platform to do controlled experiments that have resulted in 17 peer-reviewed publications. For a typical education researcher, developing relationships with schools is costly. ASSISTments has built relationships with teachers and researchers to run experiments to improve education without disrupting classrooms. This project will add researcher accounts to ASSISTments to better facilitate the research process. Researchers will create their own experiments, get approval from WPI for release to teachers, and get anonymized data. ASSISTments will reach out to its community of teachers who trust ASSISTments, to invite them to run the study in their classrooms.   The intellectual merit of this work will be the contribution of the studies that this system would support. ASSISTments' ten-year goal is to have a community of hundreds of scientists that use this tool to do their studies. <br/><br/>Psychologists tend to study human learning in lab studies; researchers in education and learning sciences point out that it's not clear if those studies generalize to K12. These communities need to work together, but are lacking common ground.  Thousands of researchers in psychology, mathematics education, and learning sciences care about using science to better understand human learning. Some researchers study how to help students with motivational messages, spaced retesting, or comparing feedback. Many researchers have used thousands of psychology undergraduates as subjects, but want their ideas tested and validated in authentic K12 settings. Everyone understands physicists need a shared scientific instrument to do their work, but so do educational psychologists.  The broader impact of this work will be as a demonstration, showing how a tool could be built that helps many researchers conduct controlled experiments.  This will include showing how the project can increase the efficiency of the scientists? work."
"1636805","BD Spokes: PLANNING: MIDWEST: Big Data Innovations for Bridge Health","OAC","BD Spokes -Big Data Regional I","09/01/2016","08/23/2016","Robin Gandhi","NE","University of Nebraska at Omaha","Standard Grant","Beth Plale","08/31/2018","$99,959.00","Daniel Linzell, Deepak Khazanchi, Chungwook Sim, Brian Ricks","rgandhi@unomaha.edu","6001 DODGE ST EAB 209","OMAHA","NE","681822000","4025542286","CSE","024Y","027Z, 7433, 8083, 9150","$0.00","Bridges across the U.S. continue to deteriorate at an alarming rate and the American Society of Civil Engineers estimate a cost of over $76 billion to improve the country's functionally obsolete or structurally deficient bridges. This indicates a significant demand for innovative bridge health monitoring solutions that can strategically guide management, maintenance and replacement programs without risking public safety. Unfortunately, the need to improve how our bridges are managed and repaired or replaced faces similar issues and demands as the rest of the U.S. transportation network: continuously shrinking resources and governing bodies who do not have the necessary insights from bridge health data to find a workable solution. <br/><br/>To discuss how to address these critical problems, researchers, practitioners, and individuals representing public and private sectors (transportation infrastructure and built environment owners, operators, designers and maintainers) convened with Big Data technology and analytics experts participated at the inaugural BRIDGE-ing Big Data Workshop hosted by the University of Nebraska in October 2015. During this workshop, it became clear that Big Data technology could assist with providing a timely solution. It also was apparent that past efforts focusing on utilizing bridge health monitoring and big data techniques as part of the management and maintenance/replacement processes are fragmented, and resulting datasets are not deemed trustworthy and are under-utilized. This project will (1) catalog datasets including sources, copyrights, license, collection procedures, and expected access controls from private sector, academia, and government agencies, (2) obtain commitments from stakeholders and host collaboration workshops with small working groups to discuss, import/export, and share bridge structural health monitoring data, and (3) solicit proposals from businesses/researchers to develop innovative applications that integrate disparate and voluminous data sources. It is anticipated that this project's findings will benefit the Midwest Big Data Hub transportation spoke and potentially inform similar activities for highways, buildings, power distribution networks and other civil infrastructure entities. Findings from this project will be promoted to national and international technical organizations, to directly impact workforce development, education and research programs. Combined, this project will make a direct impact on our country's ability to efficiently maintain the health and safety of its bridges."
"1758395","Preparing a Community of Outstanding STEM Teachers for Rural and Urban Northeast Texas","DUE","Robert Noyce Scholarship Pgm","07/01/2018","08/25/2021","William Newton","TX","Texas A&M University-Commerce","Continuing Grant","Bonnie Green","06/30/2023","$1,199,157.00","Robynne Lock, Rebecca Dibbs, Melanie Fields, Johanna Delgado-Acevedo","William.Newton@tamuc.edu","2600 W NEAL ST","COMMERCE","TX","754284311","9038865964","EDU","1795","9178","$0.00","This Track 1 Robert Noyce Teacher Scholarship Program will recruit and prepare thirty-two students over five years to become secondary physics, chemistry, biology, and mathematics teachers in high-needs school districts in Northeast Texas. Counties in this region suffer from a shortage of secondary STEM educators. Compounding this problem are high turnover rates that are at least partially caused by the isolation that STEM teachers in this region often experience. This project will address these problems through three primary efforts. (i) Potential Noyce Scholars will be recruited with activities that present teaching as an attractive, first-choice career option and by providing students teaching experiences early in their academic careers. (ii) Noyce Scholars will be prepared through teaching tracks that combine their major courses with teacher certification courses and a dedicated class in each major which covers discipline-specific pedagogy, education research, and culturally-responsive teaching. (iii) Noyce Teachers will be supported as they work in local high-needs schools by individual mentor teachers and a mutually supportive community of Noyce Teachers, Noyce Scholars, learning assistants, in-service teachers, and participating faculty. The community will meet regularly and will foster collaboration and communication between rural and urban districts.<br/><br/>Based at Texas A&M University-Commerce (TAMUC), this project will be a collaboration between TAMUC, the local rural school districts of Commerce, Caddo Mills, and Royse City, and Region 1 Educational Service Center which serves the Dallas-Fort Worth metroplex and the rural counties to the east. Over the course of the project, thirty-two STEM teachers in four cohorts of eight will be prepared to meet the needs of both rural and urban high-needs schools in Northeast Texas. Towards this end the project team will follow a three-step process. First, it will raise awareness of the program and its benefits through a broad advertising campaign. Second, it will recruit twenty-four freshmen and sophomore students/year into an expanded learning assistant (LA) program in introductory physics, chemistry, biology, and math classes. Third, the team will recruit Noyce Scholars from the LA pool and community college transfer students. Noyce Scholars will have two mentors, an in-service teacher and a member of the project team. The impact of the LA and Noyce programs on the teaching practices of new teachers and the impact of the LA program and the Noyce program on discipline-specific identity, teacher identity, and career interests will all be measured. Details about the implementation of the project, materials created through the activities of the community of practice, and research results will be reported in peer-review STEM education journals, at local and national conferences, and on the project website.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2037661","COLLABORATIVE RESEARCH: EAGER: Towards Building a CyberInfrastructure for Facilitating the Assessment, Dissemination, Discovery, & Reuse of Software and Data Products","OAC","Software Institutes","09/01/2020","07/22/2020","Ritu Ritu","TX","University of Texas at San Antonio","Standard Grant","Ashok Srinivasan","02/28/2023","$175,000.00","","ritu@wayne.edu","1 UTSA CIRCLE","SAN ANTONIO","TX","782491644","2104584340","CSE","8004","077Z, 7916, 8004","$0.00","Over the last several years, the projects funded through the various NSF programs, such as the Cyberinfrastructure for Sustained Scientific Innovation (CSSI), Data Infrastructure Building Blocks (DIBBs), and Software Infrastructure for Sustained Innovation (SI2) programs, have resulted in innovative software and data products with broad societal impacts. Collecting the information on the short-term and long-term impact of these products on their intended user communities in terms of quantifiable metrics can be important for future funding decisions, and hence is in national interest. However, collecting such information can be a challenging task given the diversity of the NSF-funded products, their usage environments, and their target audiences. Additionally, when a product is composed of (or integrated with) other products, it can be difficult to capture the provenance trail of all the embedded products, which impacts the process of gathering the metrics necessary in evaluating their success. Moreover, the knowledge of the entire technology stack used in a product can enable other developers or adopters of that product in analyzing the code reuse and integration cost. When analyzing the feasibility of integrating software products, or interoperating with them, or extending them, it is also important to check the compatibility of their licenses and software stacks so that one can determine if the products can interoperate legally and seamlessly, and if the derived products can be disseminated as intended. It can be time-consuming to carefully review and understand the impact of the licenses of the base products on any derived product, or to check if one product can co-exist or interoperate with another product. Hence, having a central and a publicly accessible infrastructure for (1) tracking the metrics of the NSF-funded products, (2) checking their license and software stack compatibility, and (3) discovering the software stack and its evolution, can be useful for quantifying the societal impacts of the NSF-funded products and in promoting their dissemination.<br/> <br/>The overarching goal of this project is to develop a software infrastructure for facilitating the assessment, discovery, dissemination, and reuse of publicly accessible software and data products. As a preliminary step towards meeting this goal, this project has initiated research and development activities for prototyping: (1) iTracker: the software infrastructure for tracking the user-defined metrics of products released and deployed on different platforms & computing environments, (2) CompChecker: a license and software-stack compatibility checker for advising the users on the feasibility of integrating or interoperating with existing products, and (3) Discovery Catalog: a prototype of a catalog of NSF-funded products which can display the most recent information captured by iTracker for each product of interest and integrate CompChecker as a feature. The project demonstrates the use of block-chain for securely storing an immutable copy of the metadata related to the cataloged products and this metadata can in turn be useful for tracking the evolution of the products during their life cycle. The project demonstrates the infrastructure required for identifying and promoting the relevant metrics for evaluating different categories of products. The project has the potential of encouraging the developer community to adopt best practices for product dissemination and will likely foster cross-disciplinary collaborations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1930025","Assessment and Evaluations of NSF OAC-Funded Program Impact on the Scientific Community","OAC","CYBERINFRASTRUCTURE, Software Institutes","09/01/2019","01/24/2020","Changwon Suh","MD","Nexight Group LLC","Standard Grant","Alexis Lewis","06/30/2020","$52,458.00","","csuh@nexightgroup.com","1100 WAYNE AVE","SILVER SPRING","MD","209105642","2406677636","CSE","7231, 8004","7231","$0.00","Cyberinfrastructure (CI) is essential to the advancement and transformation of science and engineering. Over the last decade, the CI community has focused on developing secure, advanced, scalable, and global CI resources, tools, and services, creating an interoperable and collaborative CI ecosystem. In order to move forward strategically, it is critical to understand the impact that CI programs have had on the scientific research community. This award supports an effort to develop an understanding of this impact, by working with the Cyberinfrastructure community to understand and enhance the impact of programs such as NSF's Cyberinfrastructure for Sustained Scientific Innovation (CSSI) program and its predecessors. To this end, the PIs will gather relevant information, conduct a targeted survey, and prepare a report describing findings and mapping out the future directions of CI research.<br/><br/>This work will provide new understanding of the impact of recent Data and Software Programs, through a systematic cross-cutting survey-based assessment. The assessment will seek to evaluate the impact of the activities funded under the Data Infrastructure Building Blocks (DIBBs), Software Infrastructure for Sustained Innovation (SI2), and Cyberinfrastructure for Sustained Scientific Innovation (CSSI) programs. The approach is to (1) determine the scope of the activity and establish a framework for design of the survey (2) design and administer the survey and (3) analyze the results and synthesize the findings into a report. The outcomes will benefit the scientific research community broadly, by providing insights into the most effective methods of research support in Cyberinfrastrucutre, and broadening the impact of advanced Cyberinfrastructure research on the science and engineering domains.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"2037656","COLLABORATIVE RESEARCH: EAGER: Towards Building a CyberInfrastructure for Facilitating the Assessment, Dissemination, Discovery, & Reuse of Software and Data Products","OAC","Software Institutes","09/01/2020","07/22/2020","Subhashini Sivagnanam","CA","University of California-San Diego","Standard Grant","Ashok Srinivasan","08/31/2023","$124,585.00","","sivagnan@sdsc.edu","9500 GILMAN DRIVE","LA JOLLA","CA","920930021","8585344896","CSE","8004","077Z, 7916, 8004","$0.00","Over the last several years, the projects funded through the various NSF programs, such as the Cyberinfrastructure for Sustained Scientific Innovation (CSSI), Data Infrastructure Building Blocks (DIBBs), and Software Infrastructure for Sustained Innovation (SI2) programs, have resulted in innovative software and data products with broad societal impacts. Collecting the information on the short-term and long-term impact of these products on their intended user communities in terms of quantifiable metrics can be important for future funding decisions, and hence is in national interest. However, collecting such information can be a challenging task given the diversity of the NSF-funded products, their usage environments, and their target audiences. Additionally, when a product is composed of (or integrated with) other products, it can be difficult to capture the provenance trail of all the embedded products, which impacts the process of gathering the metrics necessary in evaluating their success. Moreover, the knowledge of the entire technology stack used in a product can enable other developers or adopters of that product in analyzing the code reuse and integration cost. When analyzing the feasibility of integrating software products, or interoperating with them, or extending them, it is also important to check the compatibility of their licenses and software stacks so that one can determine if the products can interoperate legally and seamlessly, and if the derived products can be disseminated as intended. It can be time-consuming to carefully review and understand the impact of the licenses of the base products on any derived product, or to check if one product can co-exist or interoperate with another product. Hence, having a central and a publicly accessible infrastructure for (1) tracking the metrics of the NSF-funded products, (2) checking their license and software stack compatibility, and (3) discovering the software stack and its evolution, can be useful for quantifying the societal impacts of the NSF-funded products and in promoting their dissemination.<br/> <br/>The overarching goal of this project is to develop a software infrastructure for facilitating the assessment, discovery, dissemination, and reuse of publicly accessible software and data products. As a preliminary step towards meeting this goal, this project has initiated research and development activities for prototyping: (1) iTracker: the software infrastructure for tracking the user-defined metrics of products released and deployed on different platforms & computing environments, (2) CompChecker: a license and software-stack compatibility checker for advising the users on the feasibility of integrating or interoperating with existing products, and (3) Discovery Catalog: a prototype of a catalog of NSF-funded products which can display the most recent information captured by iTracker for each product of interest and integrate CompChecker as a feature. The project demonstrates the use of block-chain for securely storing an immutable copy of the metadata related to the cataloged products and this metadata can in turn be useful for tracking the evolution of the products during their life cycle. The project demonstrates the infrastructure required for identifying and promoting the relevant metrics for evaluating different categories of products. The project has the potential of encouraging the developer community to adopt best practices for product dissemination and will likely foster cross-disciplinary collaborations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1244820","Interdisciplinary Scientific Data Management","OAC","International Research Collab, DATA INTEROPERABILITY NETWORKS, Data Cyberinfrastructure","10/01/2012","04/22/2013","Alexander Szalay","MD","Johns Hopkins University","Standard Grant","Robert Chadduck","09/30/2016","$1,051,100.00","Charles Meneveau, Katalin Szlavecz, Randal Burns, Andreas Terzis","aszalay1@jhu.edu","3400 N CHARLES ST","BALTIMORE","MD","212182608","4439971898","CSE","7298, 7701, 7726","1066, 5916, 5935, 5979, 7701","$0.00","Scientists are increasingly limited by their ability to analyze the large amounts of complex data available. These data sets are generated not only by instruments but also computational experiments; the sizes of the largest numerical simulations are on par with data collected by instruments, crossing the petabyte threshold this year. The importance of large synthetic data sets is increasingly important, as scientists compare their experiments to reference simulations. All disciplines need a new ?instrument for data? that can deal not only with large data sets but the cross product of large and diverse data sets. <br/><br/>While the largest data sets have captured most of the public attention, they only represent the tip of the iceberg. What is often missed is that scientific data sets have a power law distribution. At one end are the very large data collections compiled by hundreds of scientists collaborating over multiple years.  These projects typically have coherent data management plans and organization to ensure that the data products are accessible to a wide community. Nevertheless, the long-term curation of the data is still an unsolved problem. <br/><br/>At the other end of the distribution, in the ""long tail"", are the very large numbers of small data sets, such as the images, spreadsheets and tables collected in laboratories and field studies. While the individual files are small, their numbers add up; in fact, there is as much data aggregated in these small items as in the biggest collections. On the other hand, these data sets are often not as well documented as their bigger counterparts. For most scientists there is little reward in becoming a data management expert and devoting the time required to documenting the data for later reuse. In fact, the process of manually cleaning data sets has been called the strip mining of big data: an ugly and resource intensive effort that leaves big scars.<br/><br/>Scientists at the Johns Hopkins University have built innovative frameworks to publish scientific data across a wide range of disciplines, from astronomy to turbulence, and environmental science. These projects already share some common components for data management. This project will connect more of the existing independent components into a coherent one, explore how to scale the data services to deal with the ""long tail"" of the data distribution, and demonstrate the overlap in the basic data management tasks across disciplines. The project has four parts: (i) continue and enhance the efforts on the Sloan Digital Sky Survey, (ii) turn large numerical simulations into easy-to-use numerical laboratories, (iii) enhance an existing end-to-end system for environmental sensors and integrate it with other field data, (iv) enhance and generalize a set of core collaborative tools, and apply these to help with the challenge of the ""long tail"" of scientific data.<br/> <br/>The projects involve the Sloan Digital Sky Survey (SDSS) -- the world's most used astronomy facility -- and its CASJOBs/MyDB collaborative environment  The framework will be extended to other areas of science, like in-situ environmental monitoring and field biology. This will be demonstrated by integrating data in soil ecology from the Baltimore Ecosystem Study project with data collected automatically, via a wireless sensor network. The project will also test, how a simple, ""DropBox""-like interface (i.e., online storage and sharing) can be used to overcome some of the barriers that prevent scientists from publishing much of their value-added data. Finally, the project will explore how smaller and larger numerical simulations can be placed into interactive, publicly accessible numerical laboratories, using data sets currently from turbulence and astronomy.  <br/><br/>The funds will support people: a combination of data scientists, database administrators, postdoctoral fellows, students and programmers working together to ""connect the dots"" and bring additional data sets on line. The project will enhance the public interfaces of several publicly available data sets, prototype an easy-to-use environment to upload small user data into a collaborative environment, and create a framework for a new citizen-science project in environmental science."
"0940841","DataNet Full Proposal: DataNet Federation Consortium","OAC","CESER-Cyberinfrastructure for, Data Cyberinfrastructure","09/01/2011","06/22/2016","Reagan Moore","NC","University of North Carolina at Chapel Hill","Cooperative Agreement","Amy Walton","08/31/2017","$8,300,992.00","Nirav Merchant, John Orcutt, William Regli, Arcot Rajasekar, Jonathan Goodall","rwmoore@renci.org","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","CSE","7684, 7726","7726, 9251","$0.00","Major science and engineering initiatives are dependent upon massive data collections that comprise observational data, experimental data, simulation data, and engineering data.  To support science and engineering collaborations, a policy driven national data management infrastructure will be implemented. The implementation prototype will address both the life cycle of science and engineering data and the sustainability of data collections and repositories over time, across changes in technology and changes in usage. The motivation for building the national infrastructure comes from the data management requirements of the NSF Ocean Observatories Initiative (real-time data streams, simulation output, video), the NSF Consortium of Universities for Advancement of Hydrologic Science (point data), engineering projects in education and CAD/CAM/CAE archives, the iPlant collaborative (genome databases), the Odum social science institute (statistics), and the NSF Science of Learning Centers (EEG / MRI sensor data, video).<br/><br/>The approach is based on a bottom-up federation of existing data management systems through use of the integrated Rule-Oriented Data System (iRODS).  Each of the referenced national initiatives has implemented a core data management system based upon the iRODS data grid technology.  Through federation, the independent systems can be assembled into a national data infrastructure that integrates collections across project-specific technology (such as real-time sensor data acquisition systems), institutional repositories, regional data grids, federal repositories, and international data grids.  The resulting infrastructure will enable collaborative research among researchers in academic institutions and federal agencies, and across national boundaries.<br/><br/>Evolution of the policies (computer actionable rules) and procedures (computer executable workflows) that govern each stage of the data life cycle will be supported.  Specific policies and procedures will be implemented for each domain to support their community standards for managing data in their local data grid.  The project will develop the interoperability mechanisms required to share data between the domains, develop sets of policies and procedures to govern the data life cycle stages, and develop policies and procedures that enable re-use of collections.  The national data management infrastructure will demonstrate enforcement of data management policies that comply with NSF Data management and preservation requirements."
"1659293","CC*Integration: BRACELET:  Robust Cloudlet Infrastructure for Scientific Instruments' Lifetime Connectivity","OAC","CISE Research Resources","04/15/2017","04/10/2017","Klara Nahrstedt","IL","University of Illinois at Urbana-Champaign","Standard Grant","Deepankar Medhi","03/31/2021","$500,000.00","Roy Campbell, Paul Braun, John Dallesasse, Tracy Smith","klara@cs.uiuc.edu","506 S WRIGHT ST","URBANA","IL","618013620","2173332187","CSE","2890","","$0.00","Universities typically have many scientific instruments in interdisciplinary<br/>research laboratories to conduct high-quality research in science and engineering.<br/>Yet many of these older operating instruments are prematurely disconnected from campus networks<br/>because they cannot operate at the speed of a modern computing devices, or use legacy operating system software<br/>that is not updated with the latest security patches, creating potential vulnerabilities.<br/><br/>This project will develop a robust cloudlet-based infrastructure, called BRACELET. <br/>BRACELET is an integrated three-tier infrastructure that integrates the<br/>existing campus network, cloud, and security infrastructures with the NSF DIBBs program supported 4CeeD<br/>data file upload service. Each cloudlet will be placed alongside potentially vulnerable instruments to shape traffic<br/>and protect against external threats. The cloudlet will play a crucial role in keeping the instrument connected throughout its<br/>lifetime, continuously providing otherwise missing or new performance and security features for the<br/>instrument. BRACELET will extend the capabilities and useful lifetime of scientific instruments, helping to accelerate<br/>scientific innovation and discovery."
"0848296","NARA Transcontinental Persistent Archive Prototype","OAC","CESER-Cyberinfrastructure for, Data Cyberinfrastructure, , , , , ","09/15/2008","11/19/2012","Reagan Moore","NC","University of North Carolina at Chapel Hill","Continuing Grant","Robert Chadduck","12/31/2013","$2,881,183.00","Richard Marciano, Stanley Ahalt, Arcot Rajasekar","rwmoore@renci.org","104 AIRPORT DR STE 2200","CHAPEL HILL","NC","275995023","9199663411","CSE","7684, 7726, H369, I265, J289, K132, L179","7684, 9139, 9216, HPCC","$0.00","NARA Transcontinental Persistent Archive Prototype<br/>PI: Reagan W. Moore, University of North Carolina at Chapel Hill<br/><br/>Traditional preservation environments support fundamental preservation activities such as appraisal, accession, arrangement, description, preservation, and access. Digital preservation environments also support information about individual records, management of data encoding formats, migration to new forms of technology, management of massive archives, and validation of trustworthiness assessment criteria. We propose the development of a reference implementation for digital preservation environments based on data grid technology.  A reference implementation defines the assessment criteria, the management policies, and the preservation procedures needed for long-term preservation. <br/> <br/>The reference implementation will demonstrate the basic mechanisms needed to support long-term preservation of digital records.  Based on ten years of experience with applying distributed data management systems to preservation projects, the components of a reference implementation are well understood.  The components include mechanisms to automate the management of the preservation environment, automate the validation of assessment criteria for trustworthiness, authenticity, integrity, and chain of custody, and support the incorporation of new technology through extensible policies, extensible procedures, and extensible sets of system information.  The goal is to minimize the labor required to manage the massive US record collections (measured in petabytes of data and billions of files), while preserving the essential properties of the records.<br/><br/>The system will be used to inform the National Archives and Records Administration on the approaches that result in viable preservation environments, and to demonstrate to the archival community an approach that successfully manages technology evolution.<br/><br/>"
"2314202","COLLABORATIVE RESEARCH: EAGER: Towards Building a CyberInfrastructure for Facilitating the Assessment, Dissemination, Discovery, & Reuse of Software and Data Products","OAC","Software Institutes","01/01/2023","01/12/2023","Ritu Ritu","MI","Wayne State University","Standard Grant","Ashok Srinivasan","10/31/2023","$48,623.00","","ritu@wayne.edu","5057 WOODWARD STE 13001","DETROIT","MI","482024050","3135772424","CSE","8004","077Z, 7916, 8004","$0.00","Over the last several years, the projects funded through the various NSF programs, such as the Cyberinfrastructure for Sustained Scientific Innovation (CSSI), Data Infrastructure Building Blocks (DIBBs), and Software Infrastructure for Sustained Innovation (SI2) programs, have resulted in innovative software and data products with broad societal impacts. Collecting the information on the short-term and long-term impact of these products on their intended user communities in terms of quantifiable metrics can be important for future funding decisions, and hence is in national interest. However, collecting such information can be a challenging task given the diversity of the NSF-funded products, their usage environments, and their target audiences. Additionally, when a product is composed of (or integrated with) other products, it can be difficult to capture the provenance trail of all the embedded products, which impacts the process of gathering the metrics necessary in evaluating their success. Moreover, the knowledge of the entire technology stack used in a product can enable other developers or adopters of that product in analyzing the code reuse and integration cost. When analyzing the feasibility of integrating software products, or interoperating with them, or extending them, it is also important to check the compatibility of their licenses and software stacks so that one can determine if the products can interoperate legally and seamlessly, and if the derived products can be disseminated as intended. It can be time-consuming to carefully review and understand the impact of the licenses of the base products on any derived product, or to check if one product can co-exist or interoperate with another product. Hence, having a central and a publicly accessible infrastructure for (1) tracking the metrics of the NSF-funded products, (2) checking their license and software stack compatibility, and (3) discovering the software stack and its evolution, can be useful for quantifying the societal impacts of the NSF-funded products and in promoting their dissemination.<br/> <br/>The overarching goal of this project is to develop a software infrastructure for facilitating the assessment, discovery, dissemination, and reuse of publicly accessible software and data products. As a preliminary step towards meeting this goal, this project has initiated research and development activities for prototyping: (1) iTracker: the software infrastructure for tracking the user-defined metrics of products released and deployed on different platforms & computing environments, (2) CompChecker: a license and software-stack compatibility checker for advising the users on the feasibility of integrating or interoperating with existing products, and (3) Discovery Catalog: a prototype of a catalog of NSF-funded products which can display the most recent information captured by iTracker for each product of interest and integrate CompChecker as a feature. The project demonstrates the use of block-chain for securely storing an immutable copy of the metadata related to the cataloged products and this metadata can in turn be useful for tracking the evolution of the products during their life cycle. The project demonstrates the infrastructure required for identifying and promoting the relevant metrics for evaluating different categories of products. The project has the potential of encouraging the developer community to adopt best practices for product dissemination and will likely foster cross-disciplinary collaborations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1334929","Collaborative Research: Engineering Polymer Nanodielectric Systems Using a Descriptor-Based Design Methodology","CMMI","DEMS-Design Eng Material Syst","09/01/2013","04/17/2015","Wei Chen","IL","Northwestern University","Standard Grant","kara peters","08/31/2017","$490,675.00","Lynda Brinson","weichen@northwestern.edu","633 CLARK STREET","EVANSTON","IL","602080001","3125037955","ENG","8086","024E, 067E, 073E, 116E, 1633, 1984, 9102, 9178, 9231, 9251","$0.00","The objective of this collaborative research project is to develop a microstructure-mediated design methodology that provides a seamless integration of design optimization, predictive materials modeling, processing and surface engineering, to enable accelerated discovery and development of new materials.  Through the synergy of experts in engineering design, mechanics, and materials science, a descriptor-based computational microstructure design framework and a combined theoretical, computational, and experimental approach to design new microstructural systems with tailored system properties.  Using emerging nanodielectric polymer systems as a testbed, final proof of concept will reside in design of filler morphology, interphase properties, and chemistry combinations for achieving specific mechanical and dielectric properties for a wide range of engineering applications. The computational microstructure design framework will create a shift from discovery-based materials development to systematic and computer-assisted materials design. This research will also make significant strides in predicting interphase behavior based on interaction of material constituents. <br/><br/>The results of this research could have important societal impact through innovations of new nanodielectric polymers used in electrical transmission and storage systems across a wide range of industries such as utility, energy, consumer electronics, and manufacturing.  Since this research provides a general methodology for designing microstructural material systems, the techniques will transcend to broader applications and benefit a wide range of domestic and military applications.  To disseminate the results to a broader community, a workshop on ""Design of Emerging Microstructural Material Systems"" will be organized.  Research will be integrated with education and students will have the opportunity to participate in interdisciplinary materials system design projects that offer innovation and leadership experiences."
"1314631","SBE TTP: Medium: Securing Cyber Space: Understanding the Cyber Attackers and Attacks via Social Media Analytics","SES","Secure &Trustworthy Cyberspace","09/01/2013","03/04/2016","Daniel Zeng","AZ","University of Arizona","Standard Grant","Sara Kiesler","08/31/2018","$1,301,944.00","Ronald Breiger, Salim Hariri, Thomas Holt","zeng@email.arizona.edu","888 N EUCLID AVE RM 510","TUCSON","AZ","857194824","5206266000","SBE","8060","0000, 7434, 7924, 9178, 9179, 9251, OTHR, SMET","$0.00","As society becomes more dependent on cyber infrastructure, the security of networks and information technologies has become a growing concern. Individuals, businesses, and governmental organizations are now common victims of cyber-attacks that seek to steal private data, gain remote control over remote systems, and cause harm to networks and systems through other malicious means. Additionally, critical infrastructures such as smart power grids and communication networks are facing an increasing number of cyber-based threats. As a result, many researchers and security practitioners have begun to investigate cyber attacker communities in order to learn more about cyber attacker behaviors, emerging threats, and the cybercriminal supply chain. Unfortunately, there is a lack of established science for cyber security research. The lack of literature is problematic for researchers wanting to learn more so that they may contribute to and advance the current state of cyber security research. For example, many cyber attacker communities take careful measures to hide themselves by employing anti-crawling measures. This would be a challenge for many researchers and security practitioners. Furthermore, some may find cyber attacker community discussion difficult to interpret due to cyber attacker jargon, advanced security concepts, or foreign contents belonging to cyber attacker groups spanning across different countries or regions.<br/><br/>For these reasons, research studying hacker communities is greatly needed, as well as research that advances others? capacity to understand and investigate contents from such communities. Specifically, the development of automated tools and analyses increases the potential for more cyber security research. Web mining and machine learning technologies can be used in tandem with social science methodologies to help answer many questions related to hacker behaviors and culture, illegal markets and covert networks, cybercriminal supply chain, malware analysis, emerging security threats, and other matters. There are many opportunities for extending current cyber security research by combining hacker community data with social science methodologies, computational techniques, and security analysis. <br/>   <br/>In this research, important questions about hacker behaviors, markets, community structure, community contents, artifacts, and cultural differences are explored. Automated techniques to collect and analyze data from forums, Internet Relay Chat, and honeypots will be developed. The development of such tools will help further proactive approaches for preventing cyber-based threats, rather than taking the traditional approach of reacting when something ""bad"" happens.  Better understanding of hacker communities across multiple geopolitical regions will support a better understanding of cybercriminal behavior, and improved and safer practices for security researchers and practitioners.<br/><br/>The proposed integrated computational framework and the resulting algorithms and software will also allow social science researchers and security practitioners to closely examine how cyber attacker groups form, develop, and spread their ideas; identify important and influential cyber criminals in the online world; and develop the means to recognize online hacker identities through their communication and interaction styles. Knowing more about cyber criminals, hackers, and their illegal black markets can help policy makers and security professionals make better decisions about how to prevent or respond to attacks. <br/><br/>The proposed work also contributes to the educational and professional development of the student research associates who contribute to it.  They will learn sound research methods, and how to write about and present their work for scientific and other professional audiences."
"1245936","CC-NIE Integration:  Clemson-NextNet","OAC","Information Technology Researc, Campus Cyberinfrastructure","11/01/2012","09/17/2012","Kuang-Ching Wang","SC","Clemson University","Standard Grant","Kevin Thompson","10/31/2015","$990,898.00","James Bottum","kwang@clemson.edu","230 Kappa Street","CLEMSON","SC","296340001","8646562424","CSE","1640, 8080","1640, 9150","$0.00","Clemson Next-Net models a next-generation evolutionary campus network and services for productive and innovative research and education. The project builds upon existing work to expand Clemson's networking capabilities, enable Software Defined Networking (SDN) in at least 20 buildings on campus, and integrate high-speed campus research and education locations into the campus and national OpenFlow based infrastructure. The completed network extension will support significant new scientific research and education opportunities for multiple departments, colleges, and research groups across Clemson that require access to remote instruments and/or transfer large datasets. The project also facilitates future advances in Clemson?s networking infrastructure and its ability to connect to the national infrastructure.<br/><br/>The project provides a template for other universities who are planning similar campus network transformations and are working directly with Clemson on cross-campus projects in and beyond this project. Outreach, education, and training activities are also engaging faculty, students, and IT staff on campus and across campuses to leverage the created SDN network environment for their research, education, and operational needs. Such a quantum change in their perception of the networking and computing mechanism will provide users the basis and incentive to create new use cases with the technology."
"1443062","Beyond Data Discovery: Shared Services for Community Metadata Improvement","OAC","Data Cyberinfrastructure, EarthCube","05/01/2015","04/27/2015","Ray Habermann","IL","The HDF Group","Standard Grant","Amy Walton","04/30/2019","$1,498,604.00","Matthew Jones","ted@metadatagamechangers.com","410 E UNIVERSITY AVE STE 200","CHAMPAIGN","IL","618203871","2175316100","CSE","7726, 8074","7433, 8048","$0.00","Science data and results must be well documented in order to be reproducible and re-usable.  Metadata -- ancillary contextual information such as science objectives, data provenance, and uncertainty estimates at each step -- is a fundamental part of the research documentation, reuse, and collaboration process.<br/><br/>This project develops flexible tools for evaluating metadata, using consistent measurement systems that encourage community engagement, integrate guidance for improvement, and are a critical element in cross-community metadata improvement efforts.  Provision of these new metadata and data evaluation services across communities will improve the ability to integrate and reuse trustworthy data for crosscutting synthesis and analysis across science communities.  The focus on use metadata rather than discovery metadata is a significant shift in focus.  Use metadata is a fundamental building block needed to allow effective scientific analysis workflows.  The team builds a significant collaboration with several interdisciplinary partner organizations that provide guidance to this project."
"1639529","INFEWS/T1: Mesoscale Data Fusion to Map and Model the U.S. Food, Energy, and Water (FEW) System","OAC","Track 1 INFEWS, Hydrologic Sciences, Data Cyberinfrastructure","09/01/2016","08/10/2020","Benjamin Ruddell","AZ","Northern Arizona University","Standard Grant","Alejandro Suarez","08/31/2022","$3,463,681.00","Kevin Gurney, Shade Shutters, Michael Hanemann, John Sabo","benjamin.ruddell@nau.edu","601 S KNOLES DR","Flagstaff","AZ","860117034","9285230886","CSE","020Y, 1579, 7726","004Z, 043Z, 7433, 8048","$0.00","The Food, Energy, and Water (FEW) system is complex, vulnerable to societal and environmental changes, yet critical for national well-being. This project's major contribution is to create and exploit the first detailed mapping of the Food, Energy, and Water System of the United States. Using this capability will improve understanding of how local Food, Energy, and Water policy decisions and technologies cause ripple effects throughout the system (for example, how electricity usage in an American city affects rivers hundreds of miles away).  Policies and technologies often pose trade-offs between Food, Energy, and Water systems, and this project is measuring those trade-offs so costs and benefits may be understood and balanced in future decisions.  By studying how past events like droughts, storms, wars, or economic crises have affected the nation's Food, Energy, and Water System, this project is developing the capacity to anticipate the impacts of future events.  <br/><br/>The project provides an empirical basis for advances in theory and scientific modeling of the complete food-energy-water (FEW) system of the United States.   The system is primarily composed of mesoscale phenomena in which regional trade, river basins and aquifers, irrigation districts, crop belts, states, tribes, counties and cities, power grids, climate gradients, and seasonal timescales interact in a dynamic, inter-connected coupled natural-human system. To advance understanding of these interactions, a reliable and complete empirical description of the FEW system is needed. This requires a dataset containing consumption, production, and bilateral trade data for the United States, with sub-county resolution.  A retrospective version of this dataset (containing data from the mid-20th century to the present), will serve as a model network for the FEW system's emergent performance metrics, sustainability metrics, and supply-chain teleconnections, along with observed historical dynamics of system response, vulnerability, and resilience to stresses and shocks. A wide range of diverse and disparate (but mostly pre-existing) economic, climate, and environmental data will be assembled to create the first comprehensive empirical map of the U.S. Food, Energy, and Water system (the FEWSion v1.0-US database).  This capability will then be used to achieve four high-value science and modeling objectives: (1) quantify the multiple-objective trade-offs between performance and sustainability metrics, (2) analyze historical sensitivity, vulnerability, resilience, and evolution of the FEW network with attribution to observed stresses and shocks, (3) establish the role of cities within the FEW system, and (4) provide a standards-based benchmarking assessment capability that can be used by other projects awarded under Track 1 (FEW System Modeling) and Track 3 (Research to Enable Innovative System Solutions) of this INFEWS solicitation.  A public online educational tool uses this information to visualize how individual and local decisions create environmental footprints, and how those decisions create impacts throughout the food, energy, and water system."
"1931348","CSSI Elements: DataSwarm: A User-Level Framework for Data Intensive Scientific Applications","OAC","Data Cyberinfrastructure, Software Institutes","09/01/2019","04/07/2022","Douglas Thain","IN","University of Notre Dame","Standard Grant","Varun Chandola","08/31/2023","$578,994.00","","dthain@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","CSE","7726, 8004","077Z, 7923, 8048, 9251","$0.00","This project creates a capability that will support the construction of large, data intensive scientific applications that must run on top of national cyberinfrastructure, such as large campus clusters, NSF extreme-scale computing facilities, the Open Science Grid, and commercial clouds.  The new capability (DataSwarm) brings data requirements and software dependencies to the target cyberinfrastructure systems, and deploys them as and when required, rather than having these requirements pre-installed on the target systems.  The motivation comes from applications in high energy physics, molecular dynamics, and quantum chemistry.<br/><br/>The main motivation of the work is the challenge of scalable computing frameworks.  Based on a prior development by the Principal Investigator (Work Queue), the current project provides technical innovation in three areas: <br/>(1) Molecular Task Composition.  Molecular task composition is used as an abstraction for the precise construction of tasks that require a custom software environment, large data input, and a scratch data area to capture the outputs. By expressing these aspects explicitly instead of implicitly, the project improves the storage efficiency of large numbers of tasks. <br/>(2) In-Situ Data Management.  In-situ storage management is performed to offset the increased storage consumption likely to occur under molecular task composition, avoiding unpredictable failures of tasks due to storage exhaustion. <br/>(3) Precision Provenance.  Precision provenance of both data objects and task components enables the efficient re-use of resources across multiple runs, as well as precise incremental changes to complex workflows.<br/>For this project, the three key elements addressed are the software environment, input data, and a scratch data area. These elements are usually independently managed; here, they are bound together to form temporary ""molecules"" for task execution.  The three applications included in this project represent three typical types of complex data and complex software dependencies. They include custom late-stage data analysis codes in high energy physics, complex multidimensional optimization, and ensemble molecular dynamics, respectively.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1661523","Research Data Management Implementations: Impact on Science","OAC","Data Cyberinfrastructure","05/01/2017","04/25/2017","Hakizumwami B. Runesha","IL","University of Chicago","Standard Grant","Amy Walton","04/30/2018","$69,859.00","","runesha@uchicago.edu","5801 S ELLIS AVE","CHICAGO","IL","606375418","7737028669","CSE","7726","7556, 8048","$0.00","The pace and scale of modern research requires researchers to navigate a large number of complex data management activities to collect, organize, analyze, share, store, and preserve their data, while also working to make their data more open, discoverable, and reproducible. <br/><br/>These data management activities are critical for modern research and collaborative science initiatives and maximize the utility of government funded research. Unfortunately, researchers often lack the time, resources, and expertise to perfectly execute all of these activities. While requirements for data management have been in place for six years, many researchers are still not entirely clear on what a good implementation strategy should look like or what their specific responsibilities are with respect to data management. There are few good Research Data Implementations (RDMI) exemplars and a lack of common standards and practices. Data remains difficult to manage and reproduce throughout its lifecycle, and solutions are still carried out and implemented in a piecemeal fashion.<br/><br/>In March of 2013, an NSF-funded workshop on RDMI brought together 109 data management experts, with an additional 73 experts attending online, to discuss RDMI implementations as they relate to domain specific workflows and deployments. These discussions were very helpful to the scientific community. There is a broad community of researchers that would benefit from RDMI, but RDMI availability is currently limited to institutions and domains with the resources and specialized personnel to develop them. After 4 years, the scientific community would greatly benefit from an opportunity to come together again to reflect on what has been accomplished to date related to Data Management, share achievements and assess gaps and opportunities for further contributions, and contribute with suggestions for a future roadmap. We propose to organize a second RDMI workshop to be held in 2017. This new workshop will focus on:(a)the impact that RDMI have on science, (b) developing RDMI in partnership with research communities, and (c) increasing access to RDMI for the broader research community. Workshop organizers will invite submission of position and experience papers and encourage dialogue on these focus areas through talks, panel discussions, and breakout sessions. Individual case studies will be discussed and workshop participants, through breakout sessions, will offer feedback and suggestions that will aid in refining future RDMI implementations."
"1549081","SBIR Phase I:  Wearable device and methods for sleep assessment and management in the home environment","TI","SBIR Phase I","01/01/2016","06/22/2016","Madhvi Upender","MD","Awarables, Inc.","Standard Grant","Jesus Soriano Molla","12/31/2016","$179,928.00","","madhvi@awarables.com","300 WEST PRATT ST STE 200","BALTIMORE","MD","212016512","2026743911","TIP","5371","163E, 5371, 8018, 8032, 8042, 8048","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is to bring to market a platform for monitoring and management of sleep disorders that is cost effective, easy to use for multiple nights in the home environment and delivers clinically valid and actionable results. The many consumer devices that claim to provide sleep quality data are not clinically relevant or accurate and are not accepted by healthcare providers. On the other hand, the clinical state-of-the-art is a single night, expensive, highly obtrusive and uncomfortable procedure at a sleep laboratory that only works for detection of moderate/severe sleep apnea. Awarables is dedicated to providing devices and technologies that can be validated by institutions specializing in sleep medicine and approved by the FDA. Starting with the pediatric population, including children with ADHD and Autism, we are bringing the ability to monitor and improve sleep, an integral part of every person's overall health and well-being, in populations suffering from insomnia (30M+), apnea (18M+), and other sleep disorders that require longer term home monitoring. As we progress through a landscape at the intersection of consumer applications and mobile healthcare, Awarables will challenge the existence of archaic sleep laboratories.<br/><br/>The proposed project addresses the research and development challenge of monitoring sleep quantity and quality i.e. sleep stages and other clinical metrics, and detecting critical sleep events such as apnea events per hour, snoring, and posture for multiple nights in the home environment. This entails miniature hardware of the size of a quarter instead of machinery-sized single-night sleep laboratory equipment, while providing the clinically validated analytics provided in the sleep laboratory. A comprehensive system comprising hardware, analytics, mobile user app, and clinician report will be developed leveraging a multi-disciplinary team of hardware and software engineering, and medical researchers and sleep clinicians. The detection of apnea events using a multi-sensor, multi-method approach is also proposed on re-engineered Awarables' hardware housing EKG/heart-rate and acoustic signals. The methods to be used include sensor fusion and intelligent classification algorithms, such as neural networks, that leverage both time and frequency domain features. The absence of such a product in the industry indicates the inability of existing competing IP to solve the problem at robust product level. The apnea detection and improved patent-pending sleep staging enhancements in this project will also be statistically validated on data from public clinical trial databases."
"1548605","SBIR Phase I:  Personalized Wearable Device that Learns, Adapts to Users, and Provides Enhanced Metrics and Assessments","TI","SBIR Phase I","01/01/2016","12/08/2015","Adam Tilton","IL","Rithmio, Inc.","Standard Grant","Jesus Soriano Molla","06/30/2016","$150,000.00","","adam.tilton@rithmio.com","350 N Orleans Street","Chicago","IL","606541975","3174329750","TIP","5371","5371, 8018, 8032, 8048","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project lies in addressing a long-standing roadblock to widespread consumer adoption of wearable tech devices for Smart Health use-cases.  The primary barrier is that the current devices are woefully inaccurate when it comes to converting body-worn sensor data into activity/gesture data. A second barrier is that without reliable gesture data, there is no mechanism for providing meaningful feedback to users.  To address these barriers, we propose an innovative approach to gesture/activity recognition from body-worn sensor data. The software can rapidly learn and adapt to user's motion idiosyncrasies, in a computationally lightweight but powerful system. The commercialization plan is to license the software to equipment manufacturers for them to embed it in their motion sensing products.  Products and use-cases that have been impossible to analyze previously can now have tracking enabled, thus driving value for the end-user and expanding economic opportunities for the manufacturers.  The proposed software will empower individuals to manage their fitness and rehabilitation regimens; sports trainers and physicians will have unprecedented tools for monitoring outpatient treatment; and the field will have troves of behavior data to mine for research implications and additional societal outcomes.  <br/><br/>The proposed project will lead to software that can be integrated with wearable tech devices, either embedded into silicon or as a stand-alone mobile app.  The software will be capable of 1) accurately recognizing multiple activities/gestures despite individual variances and other noise factors, 2) providing reliable and valid attributes (metrics) of those activities, specifically range of motion, path efficiency, and power, and 3) providing meaningful data for user feedback and research purposes. Despite the plethora of related devices and technologies now available, current technology is lacking as to the number of gestures identified, accuracy of identification, support for on-device learning, and the ability to provide valid and reliable gesture metrics.  The proposed technology will address current limitations in and market demand for functionality, accuracy, and robustness.  The overall technical question is whether the software can be developed to adequately compensate for sensor drift and for other types of uncertainties in motion data, at the level of complexity posed by increasingly sophisticated physical behaviors and output (metric) requirements.  The anticipated technical results include novel algorithms, fundamental performance bounds, software prototypes, and testing and validation studies. Phase I demonstrations, if successful, will lead to full-scale software development of these and additional functions."
"1548528","SBIR Phase I:  Real-time Continuous Sensor-based Objective Scoring and Reporting of Acute Pain","TI","SBIR Phase I","01/01/2016","12/10/2015","Alireza Akhbardeh","CA","ROPAmedics, LLC","Standard Grant","Jesus Soriano Molla","06/30/2016","$150,000.00","","alireza.akhbardeh@gmail.com","811 Rhode Island St","San Francisco","CA","941072610","4157570928","TIP","5371","5371, 8018, 8032, 8048","$0.00","The broader impact/commercial potential of this Small Business Innovation Research (SBIR) Phase I project is the development of a non-invasive device to objectively measure acute pain. This pain measurement sensor will monitor patients? pain continuously and in real-time thus replacing or complementing the subjective pain measurement and scoring that is practiced today. When patients are able to communicate, pain levels are subjectively reported by the patients. When patients are unable to effectively communicate, pain levels are subjectively measured by a clinician using proxies such as vital signs and facial expressions.  Such non-responsive patients include individuals in the acute care units, pediatrics, or patients suffering from neurological disorders such as stroke and dementia. Up to 10 million patients are admitted to acute care every year with an average length of stay (LOS) over 10 days.  Improved pain monitoring could reduce LOS and decrease complications associated with over medication. A decrease in LOS of just 0.25 days could save over $5 billion/year. In addition, inefficient pain management is recognized as one of the major reasons patients become addicted to opiates. Opioid abuse in the US costs over $55.7 billion.  An estimated market/revenue opportunity for this device is $450 million with limited adoption.<br/><br/>The proposed project entails the development of the real-time acute pain scoring and reporting software platform. It will provide development of a platform to enable real-time pain scoring and reporting, a major effort to prove that the technology can be deployed in clinical settings where a physician can make good use of pain level diagnosis and apply a therapy plan. Feasibility of the platform has been indicated by studies aimed to prove the link between pain-evoked cortical activity of the brain and corresponding hemodynamic responses. In this project, the bio-signals extraction, signal conditioning, and real-time pain scoring algorithms will be developed utilizing real-time objective pain assessment in addition to developing a usability mobile app. In addition, we will perform validation studies of the developed platform. Successful development of the proposed platform will contribute to improving patient?s pain management significantly by lowering costs related to pain management and length of stay. The goal of phase II of the project is to miniaturize the system and enhance the user interface, an essential step towards commercialization."
"1349002","RCN: Building the Research Data Alliance Community through US and International Engagement (RDA 2)","OAC","Information Technology Researc, CYBERINFRASTRUCTURE, Data Cyberinfrastructure","10/01/2013","07/17/2018","Francine Berman","NY","Rensselaer Polytechnic Institute","Continuing Grant","Amy Walton","09/30/2021","$6,022,637.00","Inna Kouper, Beth Plale, Mark Parsons, Kathleen Fontaine, Laurence Lannom","bermaf@rpi.edu","110 8TH ST","Troy","NY","121803522","5182766000","CSE","1640, 7231, 7726","7433, 8048","$0.00","Data-driven innovation requires a foundation of infrastructure to support the sharing, access, use, re-use, analysis, and stewardship of digital data. Data infrastructure includes cyber-infrastructure tools for data discovery and analysis (and their underlying technical structures and components -- persistent digital identifiers, shared metadata frameworks, etc.), and social infrastructure in the form of community policy and organizational practice (harmonization of standards, approaches for data access and preservation, etc.). To address the growing global need for data infrastructure, the Research Data Alliance (RDA) was planned and launched in FY13 as an international community-driven organization. RDA's mission is to build the social, organizational, and technical infrastructure needed to reduce barriers to data sharing and exchange, and to accelerate data-driven innovation world-wide. In the wake of precipitous growth, RDA is now working to develop a stable support model for at least a five-year period. The RDA 2 project provides support for U.S. participation and leadership within the RDA, as well as strategic expansion of the U.S. community within RDA (RDA/U.S.). RDA 2 integrates a) strategic efforts and pilots to expand, diversify, and strengthen the RDA/U.S. community, and b) support for U.S. contributions to RDA operations and leadership, including U.S. participation in, and hosting of, RDA Plenaries. RDA/U.S. will be led by a Steering Committee consisting of Fran Berman, RPI (Chair), Beth Plale, IU, (Vice Chair, Technical Programs), Larry Lannom, CNRI, (Vice Chair, Outreach and Development) and Mark Parsons, RPI (Managing Director).<br/><br/>The RDA 2 project builds RDA through increasing U.S. engagement and leadership. RDA 2 builds RDA/U.S. through pilots in three strategic areas: Community Engagement and Outreach, Student and Early Career Engagement, and Adoption and Impact Amplification. The pilots are designed to expand and diversify RDA/U.S. data community, increase the impact of RDA deliverables in the U.S., and enhance the benefit of RDA for U.S. institutions, communities, businesses, and individuals. A strong RDA/U.S. can be a vehicle for accelerating U.S. innovation, and positioning the U.S. community for greater competitiveness and leadership. RDA/U.S. can contribute to the data infrastructure needed to make new U.S. policy approaches and initiatives work, and serve as a means of capitalizing"
"1430508","DataONE (Data Observation Network for Earth)","OAC","Data Cyberinfrastructure","10/01/2014","03/01/2018","William Michener","NM","University of New Mexico","Cooperative Agreement","Amy Walton","03/31/2020","$15,000,000.00","Matthew Jones, David Vieglais, Suzanne Allard, Patricia Cruse, Amber Budden","wmichene@unm.edu","1700 LOMAS BLVD NE STE 2200","ALBUQUERQUE","NM","871063837","5052774186","CSE","7726","7433, 7726, 8048, 9150","$0.00","DataONE will create new cyberinfrastructure (CI) that will resolve many of the key challenges that hinder the realization of more global, open, and reproducible science. We will do so through four interrelated CI activities that are supported by the DataONE team of developers and the CI Working Group. <br/>First, we will significantly expand the volume and diversity of data available to researchers through the DataONE Federation of repositories (i.e., Member Nodes) for large-scale scientific innovation and discovery. DataONE will create lightweight and easily deployed ""Slender Node"" software and develop DataONE compatibility for common repository software systems (e.g. DSpace and others) that are already deployed in hundreds of high-value repositories worldwide. <br/>Second, we will incorporate innovative and high-value features into the DataONE CI.  These new features include: 1) measurement search to leverage semantic technologies and enable highly precise data discovery and recall of data needed by researchers; 2) tracking the data through creation, all transformations, and analyses (provenance) to enable more reproducible science by storing and indexing provenance trace information that can be used to both reproduce scientific data processing and analysis steps and to discover specific data sources by examining the documented workflows; and 3) data extraction, sub-setting and processing services to enable researchers at any location to more easily participate in  ?big data? initiatives (e.g. working with data from large environmental observatories and participating in broad-scale synthesis and modeling endeavors). These three new sets of features will dramatically improve data discovery; further support reproducible and open science; and enable scientists from any institution, independent of networking capacity, to extract subsets of large data sets held in DataONE-affiliated repositories for processing and interpretation. <br/>Third, we will maintain and improve core CI software and services (e.g., Coordinating and Member Node software stacks and key components of the Investigator Toolkit) so that the user experience continues to improve, new services can be easily added over time, and the CI can be readily upgraded as operating system and other supporting software systems continue to evolve.   <br/>Fourth, we will increase the number of Member Nodes (size of the Federation) while maintaining cybersecurity and trust. Both of these activities respond to the need for DataONE network continuity and reliability that are critical to maintaining community trust and enabling researchers to achieve their science objectives. <br/>Four working groups that are each comprised of a small number of experts from computer and information sciences, domain sciences, and cyber-enabled learning will guide and contribute to DataONE CI development and usability, sustainability, and education and outreach. The CI Working Group will coordinate core CI research and development, including the addition of new services such as provenance tracking and semantically enabled measurement search. The Usability and Assessment Working Group will help DataONE understand community needs and expectations, and constantly improve the CI via feedback from usability analysis.  The Community Engagement and Outreach Working Group will ensure that community needs are met and that education activities and materials achieve optimal impact. The Sustainability and Governance Working Group will empower the community to drive the organization?s governance structure and sustainability strategies, ensuring that DataONE can sustain services and evolve to meet the needs of researchers, libraries, sponsors, and other stakeholders for decades to come.<br/>In addition to developing robust and powerful infrastructure, DataONE aims to change the scientific culture by promoting good data stewardship practices.  Our specific goals are to: 1) build a community of stakeholders through active engagement with data repositories and the broad community of scientists; and 2) educate scientists about good data life cycle practices through effective education, outreach and training activities and experiences.  Community engagement in the biweekly Member Node Forum and the annual meeting of the DataONE Users Group will support expansion of the data content and services provided to and needed by the research community. A new DataONE webinar series and education resources (e.g., best practices and software tools, learning modules) will enable researchers to better steward their data and take advantage of the myriad services and tools available through DataONE. The DataONE Summer Internship Program will actively involve students in CI development and related DataONE activities such as creating and providing web-based educational resources.<br/>"
"1835877","Collaborative Research: CSSI: Framework: Data: Clowder Open Source Customizable Research Data Management, Plus-Plus","OAC","Data Cyberinfrastructure","09/01/2018","03/10/2022","Barbara Minsker","TX","Southern Methodist University","Standard Grant","Alejandro Suarez","08/31/2023","$620,151.00","Kenneth Berry, Jessie Zarazaga","minsker@smu.edu","6425 BOAZ LANE","DALLAS","TX","75205","2147684708","CSE","7726","062Z, 077Z, 7218, 7925, 8048, 9251","$0.00","Preserving, sharing, navigating, and reusing large and diverse collections of data is now essential to scientific discoveries in areas such as phenomics, materials science, geoscience, and urban science. These data navigation needs are also important when addressing the growing number of research areas where data and tools must span multiple domains. To support these needs effectively, new methods are required that simplify and reduce the amount of effort needed by researchers to find and utilize data, support community accepted data practices, and bring together the breadth of standards, tools, and resources utilized by a community. Clowder, an active curation based data management system, addresses these needs and challenges by distributing much of the data curation overhead throughout the lifecycle of the data, augmenting this with social curation and automated analysis tools, and providing extensible community-dependent means of viewing and navigating data. As an open source framework, built to be extensible at every level, Clowder is capable of interacting with and utilizing a variety of community tools while also supporting different data governance and ownership requirements.<br/><br/>The project enhances Clowder's core systems for the benefit of a larger group of users. It increases the level of interoperability with community resources, hardens the core software, and distributes core software development, while continuing to expand usage.  Governance mechanisms and a business model are established to make Clowder sustainable, creating an appropriate governance structure to ensure that the software continues to be available, supportable, and usable.  The effort engages a number of stakeholders, taking data from diverse but converging scientific domains already using the Clowder framework, to address broad interoperability and cross domain data sharing. The overall effort will transition the grassroots Clowder user community and Clowder's other stakeholders (such as current and potential developers) into a larger organized community, with a sustainable software resource supporting convergent research data needs.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1247316","Data and Software Preservation for Open Science (DASPOS)","PHY","HEP-High Energy Physics, OFFICE OF MULTIDISCIPLINARY AC, CYBERINFRASTRUCTURE, COMPUTATIONAL PHYSICS, PHYSICS AT THE INFO FRONTIER, Data Cyberinfrastructure","09/15/2012","09/15/2016","Michael Hildreth","IN","University of Notre Dame","Standard Grant","Bogdan Mihaila","08/31/2017","$2,065,046.00","Robert Gardner, Douglas Thain, Mark Neubauer, Jaroslaw Nabrzyski","hildreth.2@nd.edu","940 Grace Hall","NOTRE DAME","IN","465565708","5746317432","MPS","1221, 1253, 7231, 7244, 7553, 7726","7433, 7569, 8048, 8084","$0.00","Scientific data is being collected at a higher rate than ever.  A striking example is in elementary particle physics (EPP) experiments, where collaborations of thousands of scientists collect huge amounts of data at the Large Hadron Collider (LHC), but other disciplines have and are continuing to observe similar growth. <br/><br/>The complexity and time frame of these experiments is such that the full scientific potential can only be realized when the data remains accessible and analyzable through extended periods. <br/><br/>The possibility of successfully meeting this goal for the necessary long term data preservation requires a novel approach that will make the data and necessary software management more solid and survivable. The long term data preservation will become an even more critical issue as present experimental efforts evolve and the Big Data paradigm develops. The initial efforts of the US community to analyze the large volume of LHC data is being satisfied by the Open Science Grid project, designed to facilitate such large and distributed experiments. DASPOS provides an opportunity to continue to study today's analysis over the long term. <br/><br/>The DASPOS project incorporates the present state-of-the-art knowledge in working with data in EPP. This project aims to provide a generic technological framework where the basic difficulties are identified and solved with the aim of advancing these goals simultaneously for several disciplines, which should facilitate the emergence of commonalities and standards.<br/><br/>The milestones and the work plan are well structured and adapted to present knowledge. Intense communications via workshops is planned and is a natural path for the goal of inclusion of the various disciplines. The intention to document these workshops is a valuable component of this project, as are concrete goals such as prototypes and software challenges.<br/><br/>The DASPOS project is not only sound but also timely. The recent dynamics in data preservation and large data management is now reaching several countries and funding agencies. In fact, several projects at national levels are now installed, including for instance, the PREDON project, financed by CNRS-France in 2012 to prepare a multidisciplinary novel approach to big data management. <br/><br/>Other similar initiatives are under study in Germany and Italy. It is no question that synergies will emerge at an international scale, and is also clear that DASPOS will play a pioneering and leading role in this context. <br/><br/>In conclusion, the impact and merit of the DASPOS proposal is innovative and potentially transformational. This can be an historical opportunity to make a significant advance in the scientific data management in the context of the ""Big Data"" challenge."
"1227110","Network for Computational Nanotechnology Cyber Platform","EEC","EWFD-Eng Workforce Development, ERC-Eng Research Centers, NANOSCALE: SCIENCE & ENGIN CTR, Special Projects - CCF, CYBERINFRASTRUCTURE, NanoSim-Nanosim Groups-Network, ENG NNI Special Studies, Data Cyberinfrastructure, Software Institutes","12/01/2012","08/17/2022","Gerhard Klimeck","IN","Purdue University","Cooperative Agreement","Mehdi Ferdowsi","11/30/2023","$30,792,392.00","Krishna Madhavan, Michael McLennan, Alejandro Strachan, Lynn Zentner, Michael Zentner","gekco@purdue.edu","2550 NORTHWESTERN AVE STE 1900","WEST LAFAYETTE","IN","479061332","7654941055","ENG","1360, 1480, 1675, 2878, 7231, 7604, 7681, 7726, 8004","026Z, 113E, 116E, 124E, 131E, 7219, 7433, 7680, 8004, 8048, 8211, 9178, 9251","$0.00","Network for Computational Nanotechnology (NCN) was founded in 2002 to advance nanoscience toward nanotechnology via online simulations on nanoHUB.org. Not only has nanoHUB become the first broadly successful, scientific end-to-end cloud computing environment, but it also has evolved well beyond online simulation. Annually, nanoHUB provides a library of 3,000 learning resources to 195,000 users worldwide. Its 232 simulation tools, free from the limitations of running software locally, are used in the cloud by over 10,800 annually. Its impact is demonstrated by 720+ citations to nanoHUB in the scientific literature with over 4,807 secondary citations, yielding an h-index of 31, and by a median time from publication of a research simulation program to classroom use of less than 6 months. Cumulatively, over 14,000 students in over 760 formal classes in over 100 institutions have used nanoHUB simulations. <br/><br/>Despite a decade of transformational success for a broad nanotechnology research and education community, significant gaps remain as work is still performed by isolated individuals and small groups. This fragmentation by specialty hinders tool and data sharing across knowledge domains. Nano areas such as bio, photonics, and materials are only beginning to use nanoHUB while manufacturing, informatics, environmental-health-and-safety are to date not even represented on nanoHUB. The NCN Cyber Platform proposes to address these gaps through efforts in three strategic goals to: 1) accelerate research by transforming nanoscience to nanotechnology through the integration of simulation with experimentation; 2) inspire and educate the next-generation nanoscience and nanotechnology workforce; and 3) grow the nanoHUB society that uses and shares nanoHUB content. Five cross-cutting thrust areas focus on the cyberinfrastructure (CI) and social dynamics of the nanoHUB virtual society: CI innovation; content stewardship and node engagement; education research and precollege/college and lifelong learning; outreach, diversity, and marketing; and CI operations. The 10-year NCN nanoHUB Cyber Platform vision is that nanoHUB will be the online nano society that researchers, practitioners, educators and students depend on day-to-day while simultaneously immersed in professional practice and computational resources for a multidisciplinary culture of innovation grounded in cloud services-enabled workflows.<br/><br/>Intellectual Merit: The NCN nanoHUB strategic plan will answer two fundamental challenges to the next-generation nanoHUB experience: 1) development of technologies that enable simple management and publication of scientific data (experimental and simulation) without additional complex steps: and 2) the establishment of a value system that fosters publication of data, tools, and lectures similar to today's rewards for journal publications. CI innovation, developed through the leading HUBzero platform as well as in cooperation with other CI efforts, will enable new connection points for research, education, and commercialization, expanded platform tool features to help users exchange and publish data; combined data and tools for verification, validation, and engineering activities; and increase immersive and pervasive features. Through partnerships with professional societies and commercial publishers, nanoHUB will change how researchers publish their simulation results through novel interactive journals that reflect a user's workflow, link directly back to their data, and make the work reproducible. This value system will drive new content toward nanoHUB, obviating the need for content generation to be monetarily supported by NCN. Through partnerships with the three new NCN content nodes and other NSF-funded nano efforts, NCN will continue to foster content creation to demonstrate value to the authors and will prototype, test, and host the proposed new technologies for broad usage.<br/><br/>Broader Impacts: NCN has developed processes that enabled researchers to rapidly deploy their research codes and innovative tutorials and classes on nanoHUB. To date, these processes harvested research and educational results from 890 contributors world-wide. Expansion into new areas of nano research and education, including pre-college education, represent a huge growth potential for nanoHUB that goes beyond simulation to embracing data management, search, and exploration. Focus on diversity will continue to be an integral part of NCN's outreach program, in particular through focused workshops and new initiatives such as EPICS High. The NCN-pioneered HUBzero already powers 40 HUBs at 12 institutions, serving a broad range of science and engineering disciplines and commercialization. Through impact assessment and continual contributions to HUBzero software stack releases, nanoHUB will continue to drive impact beyond its nano society into other disciplines and institutions."
"1649820","Smart Food Policy for Small Scale Farmers: Understanding the Critical Factors of Food Traceability","OAC","Data Cyberinfrastructure","08/15/2016","08/16/2016","Jose Ramon Gil-Garcia","NY","SUNY at Albany","Standard Grant","Amy Walton","07/31/2018","$45,566.00","Gary Kleppel","jgil-garcia@ctg.albany.edu","1400 WASHINGTON AVE","ALBANY","NY","122220100","5184374974","CSE","7726","7916, 8048","$0.00","Food safety and procurement policies that focus on local producers can prevent foodborne illness outbreaks and are an important component of a healthy food environment. Food safety policies such as the New York (NY) Food Metric require some traceability, meaning the revealing of information and processes of the origin, location, and life history of a product across the supply-chain. However, the costs of participating in a traceability cyber infrastructure could potentially nullify the economic benefits of food safety policy implementation for small farms. Data and technology requirements and capabilities have the potential to marginalize small farms who have restricted capability, time, and resources to collect, record, and share data. In partnership with Professor Gary Kleppel and the Kleppel Lab for Agricultural Ecology and Sustainable Food Production in the Department of Biology at the University at Albany (UAlbany), the Center for Technology in Government, UAlbany proposes to build preliminary data and technology architectures to support the development of the necessary cyber-infrastructure for a whole-chain traceability system that fits with the data capabilities of small farms. <br/><br/>The focus of this research is to design data and technology architectures that fit with the capabilities of small farms. Data collection will include a series of in-depth interviews with selected small farmers and government officials in NY?s Capital District and representatives of UAlbany, which will serve as the institutional buyer. The research team will use qualitative analysis of the interview data to identify the critical factors needed to design appropriate technology and data architectures for small farms. In addition, the results will be used to document the policy, organizational, governance, and technical components needed to enable whole-chain traceability from small farms to institutional buyers."
"1639753","Earthcube Building Blocks: Collaborative Proposal: Polar Data Insights and Search Analytics for the Deep and Scientific Web","ICER","Polar Cyberinfrastructure, EarthCube","09/01/2016","09/16/2016","Chris Mattmann","CA","University of Southern California","Standard Grant","Eva Zanzerkia","08/31/2019","$514,999.00","","mattmann@usc.edu","University Park","Los Angeles","CA","900890001","2137407762","GEO","5407, 8074","7433, 8048","$0.00","This project develops an NSF EarthCube Building Block focused on Polar Data Science. The system will build upon work in Information Retrieval and Data Science and upon existing investment from NSF Polar, EarthCube, and from DARPA and NASA in this area. The system will collect, analyze, and make interactive the wealth of textual and scientific Polar data collected to date across the Deep web of scientific information -- scientific journals, multimedia information, scientific data, web pages, etc. The system builds upon fundamental research in text analysis, search, and visualization. Its primary goal is to unlock unstructured scientific data from 90+ data formats and to scale to 10s-100s of millions of records using the NSF XSEDE supercomputing resources. The system will perform information retrieval and machine learning on data crawled from the Polar Deep and Scientific web. Crawling will be informed by science questions crowdsourced through the EarthCube and Polar communities. The project is a collaboration with NSIDC, Ronin Institute, and the broader community including the newly funded Arctic Data Center led by NCEAS, to build our proposed system.<br/><br/>The result of periodic and regular crawling will be a Crawl Data Repository (CDR) of raw textual data e.g., web pages containing richly curated dataset abstract descriptions, news stories tied to datasets, ASCII note files and dataset descriptions, and other textual data available on or pointed to by Polar repositories as well as scientific data (HDF, Grib, NetCDF, Matlab, etc.). The CDR will be made available for historical and future analysis by the broader EarthCube and Polar communities. In addition, an extraction pipeline will generate an Extraction Data Repository (EDR) of machine learning features not previously present (geospatial, temporal, people, places, scientific publications and topics, etc.) that will be the basis of interactive, visual analytics over the Polar data resources. Information collected will assist in answering scientific questions such as these derived from the President?s National Strategy for the Arctic Region. To date, the team has also crowd sourced 30+ questions from the Polar community represented on CRYOLIST https://goo.gl/4dDyIS and will continue to solicit this feedback and use the information collected to aid science as prioritized by the community. They will also engage the community to assist in validating our system. This is not a predictive tool per-se ? though it can help to enable such predictions. Its focus is on building an operational and core capability for textual scientific data analysis, both retrospective, and prospective."
"1203876","Collaborative research: Spatial and temporal variability of surface albedo and light absorbing chemical species in Greenland.","OPP","ARC Rsch Support & Logistics, ANS-Arctic Natural Sciences","09/01/2012","03/14/2014","Jack Dibb","NH","University of New Hampshire","Standard Grant","William J. Wiseman, Jr.","08/31/2016","$368,208.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205, 5280","1079, 9150","$0.00","The collaborative team will take advantage of the currently funded Greenland Inland Traverse (GrIT) traveling between Thule and Summit Greenland to access a spatially diverse area of the GIS in order to better understand albedo variability and the snow properties that influence albedo. The GrIT route offers a unique opportunity to study a wide range of snow accumulation zones (i.e. the ablation zone, soaked snow zone, the percolation zone and the dry snow zone) across Greenland, which are expected to have a broad range of albedo values as well as significant variability in snow physical properties and concentrations of light absorbing compounds (i.e. dust, elemental carbon, and brown carbon). The project's field component will take place over two seasons during the spring of 2013 and 2014. The approach will include stopping along the traverse to collect coincident daily measurements of snow spectral albedo, snow physical properties (i.e. specific surface area, density), surface snow light absorption properties (i.e. wavelength dependent absorption of water soluble compounds and particulates), and the concentrations of trace elements, organic, and elemental carbon. Additionally, the temporal evolution of spectral albedo will be monitored continuously during the sunlit months using autonomous stations deployed along the traverse route to track seasonal variations of snow albedo and to help attribute these variations to the physical and chemical composition of the snow.  The results of this project will yield a unique data set characterizing the temporal and spatial variability of surface albedo as well as the physical and chemical properties of Greenland snow, which are broadly useful to both modeling, ice mass balance, and remote sensing communities. Conference presentations, rapid publication of results, and most importantly close collaboration with modelers, (i.e. through work with the CESM PCWG) will ensure that this knowledge used to improve process parameterizations in predictive global climate models.  The team will also build on international collaborations begun in the Dartmouth IGERT program, including a week-long ambassadorship to Nuuk by co-PI Polashenski including lectures at the college and Katuuaq cultural center.  Graduate, undergraduate, and high school student training will also be included in the project."
"9714982","Stratospheric Transport and Stratospheric/Tropospheric      Exchange: Insights and Constraints from Be-10, Be-7 and     Their Ratio","AGS","Atmospheric Chemistry, LARGE-SCALE DYNAMIC METEOROLOG","04/01/1998","04/15/1998","Jack Dibb","NH","University of New Hampshire","Standard Grant","Sumant Nigam","03/31/2001","$149,945.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524, 1527","0000, 4444, OTHR","$0.00","    9714982  Dibb     Cosmogenic isotopes represent a largely untapped source of information on transport within the stratosphere and exchange between the stratosphere and troposphere.  The Be-10 and Be-7 (beryllium) pair of isotopes is particularly useful as tracers because their sources are known, they are basically non-reactive, and their greatly different half-lives makes their ratio a useful clock over time scales of months to several years.     The principal investigator and researchers at the Lawrence Livermore National Laboratory (LLNL) have compiled the small set of data that exist on these isotopes and their ratio.  They will increase the data base by nearly an order of magnitude by measuring and analyzing samples taken during several recent airborne sampling campaigns.  Latitudinally, the samples range from more than 70(N to 70(S, from both the lower stratosphere and the upper troposphere.  In addition, during the campaigns measurements were obtained of a variety of other tracers such as ozone, carbon monoxide, carbon dioxide, methane and water vapor.  These data will be compared with the beryllium isotopes results data.  Dr. Dibb also will work with LLNL scientists who plan to simulate the transport and exchange processes of the stratosphere.  The observational data will serve as constraints for model simulations of transports in these regions."
"1042410","Collaborative Research: Science Coordination Office for Summit Station and the Greenland Traverse","OPP","ARC Rsch Support & Logistics","09/01/2011","08/29/2011","Jack Dibb","NH","University of New Hampshire","Standard Grant","Jennifer Mercer","08/31/2016","$410,400.00","Zoe Courville","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205","1079","$0.00","The Science Coordination Office (SCO) serves the scientific community, NSF/OPP, and the arctic logistics contractor by coordinating input and providing an organized mechanism for OPP to consult with regarding decisions at Summit Station. SCO makes recommendations to CPS about ways to accommodate or mitigate conflicting requests from different science teams, as well as suggesting ways investigators might accomplish science objectives with smaller logistical impacts. SCO advocates on behalf of the community, suggesting science-based priorities for capital investments by OPP at Summit that will maintain and enhance the value of the site for research while striving to keep the station financially sustainable. This proposal includes two new members to SCO in order to represent the broader research community and diversify generations of researchers. This proposal adds functionality to the existing SCO. SCO will discuss research projects on the Greenland Inland Traverse and future research sites on the Greenland Ice Sheet hosting investigations similar to work done at Summit Station. Activities that expand communication in this proposal include significant updates to the current GEOSummit webpage such as incorporation of a virtual tour, Summit bibliography, and Summit GIS. SCO will create a Summit Listserv and host communication events such as a town hall style meeting at the Fall AGU meeting, increased effort at informal direct contact, and semi-annual teleconferences involving the scientific community. The SCO role in long-range and annual planning is to focus on the economic and environmental sustainability of the station in parallel with the preservation of core station scientific activities. These objectives are captured in a developing Long-range Plan for Summit Station."
"9725252","Air-Snow Exchange of Reactive Nitrogen Oxides at Summit,    Greenland (Collaborative Research with UC Irvine, Michigan  Technological University and Purdue University)","OPP","Atmospheric Chemistry, ARCSS-Arctic System Science","02/01/1998","04/20/2000","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Michael T. Ledbetter","01/31/2001","$245,773.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524, 5219","4444, 5219, EGCH","$0.00","  ABSTRACT    OPP-9725252   OPP-9725463  DIBB, JACK   HONRATH, RICHARD  UNIVERSITY OF NH   MI TECHNOLOGICAL UNIVERSITY    OPP-9727093   OPP-9727418  BLAKE, DONALD  SHEPSON, PAUL  UNIVERSITY CA-IRVINE PURDUE UNIVERSITY    The project will determine the atmospheric concentration of nitrogen compounds in the atmosphere by conducting a field experiment at a field camp at the summit of the Greenland ice sheet.  The concentration of nitrogen compounds in the atmosphere will be compared to their concentration in freshly deposited snow so that the record of atmospheric chemistry that is retained in the permanent ice record at the site may be interpreted for changes in the chemistry of the troposphere that have occurred since human activities began to affect the atmosphere.  That record will lead to important conclusions about the human impacts of global change on the atmosphere and will allow an examination of the natural cycles of atmospheric chemistry over the past 100,000 years."
"9221836","Gamma Ray Detector for Snow Deposition Studies: Development and Testing","OPP","ANT Ocean & Atmos Sciences, ANS-Arctic Natural Sciences","08/15/1993","08/10/1993","Jack Dibb","NH","University of New Hampshire","Standard Grant","Bernhard Lettau","01/31/1996","$57,588.00","E. Chupp, Philip Dunphy","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","O/D","5113, 5280","","$0.00","9221836  Dibb  This two objectives of this project are to develop a rugged,  portable gamma ray detector system that can be used to make rapid  in situ measurements of Cesium-137 in snow and ice, and to test the  system in Antarctica in conjunction with other ice coring and snow  sampling programs to verify and calibrate the in situ measurements.   These measurements will provide an accurate means of determining  the snow accumulation rate, a critical component of glaciological  mass balance studies.    The identification of horizon markers of known absolute age is  basic to such studies.  On the century time scale, the deposition  of Cesium-137 has produced horizons at the time of the initiation  of atmospheric thermonuclear testing in 1953, at the time of  maximum testing in 1963, and the Chernobyl accident in 1986.   Cesium-137 has a half life of 30.2 years.    This gamma ray detection technique is expected to locate horizons  quickly and unambiguously in the field, and can be used both in  polar ice sheets, and in high altitude temperate zone snow fields.  ***"
"1456249","RAPID:  Measurements of Coarse Aerosol During WINTER","AGS","Atmospheric Chemistry","08/01/2014","08/01/2014","Jack Dibb","NH","University of New Hampshire","Standard Grant","Sylvia Edgerton","07/31/2016","$163,339.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524","7914, 9150, OTHR","$0.00","Measurements and chemical analysis of super-micron (greater than 1 micrometer) sized particles in the atmosphere are being made as part of the aircraft-based Wintertime Investigation of Transport, Emissions, and Reactivity (WINTER) field campaign, scheduled to take place during January and February 2015. An important goal of the WINTER campaign is to characterize the multiphase chemical processing and transport of air emissions over the Northeast and Mid-Atlantic US during wintertime. These data, when combined with the measurements being made by other campaign investigators, are expected to provide unique insight into the chemical processes that occur in the atmosphere during the winter months This research is relevant to the development and optimization of models used for predicting air quality and climate change.<br/><br/>Chemical analysis of the aerosol samples will provide data on the concentrations of soluble ions (chloride, nitrate, sulfate, oxalate, sodium, ammonium, potassium, magnesium and calcium) in the atmosphere. The abundance and distribution of aerosol chloride can play a critical role in the production of nitryl chloride (ClNO2) and influence regional atmospheric photochemistry. Supermicron sea salt and dust particles can serve as strong sinks for gas phase nitric and sulfuric acids and influence the chemical cycling of nitrogen and sulfur oxides, possibly competing with processes leading to new particle formation. The combined results from the WINTER campaign will lead to a more comprehensive understanding of the year-round fate of anthropogenic pollutant emissions in the atmosphere."
"1917598","Collaborative Research: Improving Research Coordination for Summit Station and the Dry-Snow Zone of Greenland","OPP","ARC Rsch Support & Logistics","08/01/2019","07/12/2019","Jack Dibb","NH","University of New Hampshire","Standard Grant","Renee Crain","07/31/2022","$173,209.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205","1079, 9150","$0.00","Summit Station (72N, 38W, 3250 m.a.s.l.) hosts the Greenland Environmental Observatory, a cooperation between the National Science Foundation and the National Oceanic and Atmospheric Administration with permission from the Danish Commission for Scientific Research in Greenland to provide long-term environmental measurements. Summit is the only year-round, high-elevation, free-tropospheric, inland environmental observatory in the Arctic, and fills a unique niche in the international scientific community's global observing system. The Summit Station Science Coordination Office is an advisory body that serves the scientific community, the National Science Foundation's Arctic Research Support and Logistics Program and the Arctic Research Support & Logistics Services contractor by making recommendations about ways to accommodate or mitigate conflicting requests from different science teams working at Summit and suggesting ways that projects might reduce their logistical footprint. The Science Coordination Office also suggests science-based priorities for capital investments by the National Science Foundation at Summit. The Science Coordination Office strives to develop a true community of Summit users through open communication and by encouraging shared use of resources and key data sets. It also endeavors to focus the Summit community on the transformative questions identified by the participants at the Summit Station Science Summit in March 2017 and encourages the community to synthesize available data to identify innovative approaches to address these knowledge gaps.<br/>     <br/>The Science Coordination Office advances discovery and understanding of processes acting across the interior of the Greenland Ice Sheet while promoting teaching, training, and learning. New features of the GEO Summit website, aimed specifically at new Principal Investigators, will provide rich web content for interested students and the general public.  Over the next three years opportunities to interface with the new Greenland Climate Research Centre in Nuuk and add website content tailored to Greenlandic students and researchers will be actively pursued. The ability to quickly link to content about Summit Station will enable outreach programs by Summit researchers to increase their impact. Much effort in this project will be placed towards encouraging broad dissemination of results to enhance scientific and technical understanding. This will be accomplished by continuing to provide a clearinghouse for accessing Summit data, an extensive Summit bibliography, and a detailed list of planning activities to avoid duplicate collection of data at Summit. The Science Coordination Office will also provide greater visibility to the broader community by chairing sessions at international meetings and hosting data workshops that focus on Greenland.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"1637006","Collaborative Research: Science coordination office for Summit Station/ISI Observatory and the Greenland Traverse","OPP","ARC Rsch Support & Logistics","12/15/2016","01/16/2018","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Jennifer Mercer","11/30/2018","$115,171.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205","1079","$0.00","The Division of Polar Programs has been funding substantial scientific activities at Summit Station, Greenland (72°N 38°W, 3250 meters above sea level), for over twenty years. Summit Station hosts the Greenland Environmental Observatory (GEOSummit), a cooperation between the National Science Foundation (NSF) and the National Oceanographic and Atmospheric Administration with permission from the Danish Commission for Scientific Research in Greenland to provide long-term environmental measurements. Summit is the only high-elevation, free-tropospheric, inland environmental observatory in the Arctic which is manned throughout the year. Summit therefore fills a unique niche in the international scientific community?s global measurement capability. The Science Coordination Office (SCO) for Summit Station and the Greenland Ice Sheet serves in an advisory capacity to NSF?s Arctic Research Support and Logistics Program.  SCO?s primary role is to present the needs and desires of the science community working on the Greenland Ice Sheet in discussions and decision making processes involving NSF, its primary logistics support contractor, and other stakeholders.  The SCO also works with NSF, NSF?s contractor, and science teams to work out equitable and efficient use of resources, and strives to ensure that the wide range of science and support activities impact the pristine character of Summit as lightly as possible.  SCO shares in the long-range goal of redeveloping Summit infrastructure in ways that will reduce long-term operation and maintenance costs, and reduce the emissions of pollutants by facilities on the station and the aircraft and traverse vehicles that visit.  The SCO also helps coordinate visits to Summit for educational groups at all levels, from high school to post-graduate. <br/><br/>The SCO will work closely with NSF and all relevant stakeholders in the design of a revitalized Summit Station where reducing operational and maintenance effort (and costs) will preserve the site for future science by reducing emissions. Additional scientific communities, including astronomy and astrophysics, have recently expressed interest in using Summit Station as an Arctic base for new observations.  SCO will actively participate in discussions with all interested parties to develop a site plan to accommodate an influx of additional research activities while maintaining long-standing focus on climate-relevant research which requires clean air and snow conditions.  SCO?s website is a keystone of communication to the science community, with several new features added over the past few years, including; a Google Earth based GIS recording activity in the region over the past 9 years, a virtual tour using Streetview images, a new Working at Summit section that targets new investigators, a comprehensive bibliography of published work near Summit, and a quarterly Newsletter).  SCO will conduct a comprehensive overhaul of the web site to improve navigation, and will continue to add new features."
"1022996","Collaborative Research: Direct radiative forcing over central Greenland; Assessment of the coupled effect of light absorbing aerosols and snow albedo variability","OPP","ARCSS-Arctic System Science","09/15/2010","09/14/2010","Jack Dibb","NH","University of New Hampshire","Standard Grant","Neil R. Swanberg","08/31/2013","$190,000.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5219","1079, 9150","$0.00","The PIs will make key measurements needed to accurately estimate the direct radiative forcing by aerosols over the central Greenland ice sheet. Sampling will take place over a field season that will occur from the spring through fall of 2011.  It will include real-time measurements of aerosol physical and optical properties (size distribution, multi-wavelength scattering, &#963;sp, and backscattering, &#963;bsp, coefficients as well as the multi-wavelength absorption coefficient, &#963;ap) needed to estimate the aerosol single scattering albedo, &#969;, and asymmetry parameter, g. Additional measurements of the wavelength-dependent optical depth, &#964;&#955;, as well as the spectral surface reflectance, Rs will also be made. These data will serve as input to a radiative transfer model that will be used to estimate the direct aerosol radiative forcing at the surface and top of the atmosphere over Greenland. Sources and source regions of the direct radiative forcing will be determined by the chemical composition of the aerosols sampled.  It is hypothesized that dust, biomass burning and fossil fuel combustion aerosols often exert a positive direct radiative forcing many times greater than that of anthropogenic greenhouse gases.  Additional characterization of snow albedo, which varies occurs on timescales of hours to days, will be made to determine whether it, too, exerts a significant influence on the direct aerosol forcing over Summit. Surface snow grain properties and surface snow chemistry will be determined at high temporal frequency to explore the link between the variability in these properties and the surface albedo."
"9907469","Investigation of Photochemical Transformation within Snow and their Effect on Snow and Atmospheric Composition","OPP","ARCSS-Arctic System Science, ANS-Arctic Natural Sciences","09/01/1999","09/10/2001","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Jane V. Dionne","08/31/2002","$180,080.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197    OPP-9907469  OPP-9907330<br/>HONRATH, RICHARD   DIBB, JACK  ALBERT, MARY<br/>MICH. TECH. UNIVERSITY   UNIVERSITY NH CRREL<br/><br/>OPP-9907376    OPP-9907623  OPP-9907434<br/>SHEPSON, PAUL   BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY   UC-IRVINE  UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow.  The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow.  The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past.  The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities.  The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere.<br/><br/>"
"9813312","Seasonal Differences in Air-Snow Chemical Relationships at Summit, Greenland","OPP","ARC Rsch Support & Logistics, ARCSS-Arctic System Science, TEACHER ENHANCEMENT PROGRAM","12/15/1998","07/26/2000","Jack Dibb","NH","University of New Hampshire","Standard Grant","Neil R. Swanberg","11/30/2002","$422,345.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205, 5219, 7300","0000, 1079, 5219, 9177, EGCH, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY           KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462   OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"0309564","Collaborative Research: Factors Controlling Chemical Weathering in Regions of Very High Physical Weathering Rates","EAR","Hydrologic Sciences","08/15/2003","08/16/2003","Jack Dibb","NH","University of New Hampshire","Standard Grant","L. Douglas James","07/31/2005","$84,826.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1579","9189, EGCH","$0.00","0309564<br/>Dibb<br/>Over the past decade, a debate has taken place concerning the ultimate controls on chemical weathering at Earth's surface. Some have argued that the rate of physical weathering, not climate, is the major control on chemical weathering. Physical weathering is highest in areas of rapid tectonic uplift. Rapidly uplifting tectonic regimes with high frequency rainfall events are the dominant feature of many high-standing oceanic islands in the SW Pacific/Australasian region. High-standing islands (HSIs) there produce at least 33% of the sediment entering the marine environment annually. Because of this, HSIs have some of the highest physical weathering rates known on Earth. Research in our previous grant (EAR 0096285) determined chemical weathering rates in some New Zealand watersheds. Comparison of newly determined chemical weathering rates to the previously determined physical weathering rates showed that, although the ratio of chemical to physical weathering is low, the absolute rates of chemical weathering are some of the highest ever observed. Preliminary observations from Taiwan indicate that chemical weathering rates there are also very high. The current project is a return to New Zealand and Taiwan to collect water, suspended sediment and soil and sediment samples in order to conduct the following work: 1. Use a suite of radionuclides (7Be, 137Cs, 210Pb) to determine residence times of sediments in the soils and floodplains of two previously investigated watersheds in New Zealand; 2. Use a full suite of major, minor and trace element analyses to evaluate the physical and chemical weathering rates in New Zealand and Taiwan watersheds whose primary lithology is volcanic rocks; 3. Use data from activities 1 and 2 and the results of our previous research to develop a quantitative framework to evaluate the relationship between physical and chemical weathering rates, especially in these regions of very high physical weathering. <br/>At the locations where we collect soil and streambed sediment profiles for 7Be, 137Cs and 210Pb, we shall collect additional samples for future analysis of uranium and thorium series nuclides. These samples will be archived until time and funds permit, we shall analyze these samples using the ICP-MS at OSU's MARC analytical center. The data will be used for calculation of watershed residence times. We plan these additional activities in response to the reviewer comment that the original choice of nuclides had half-lives too short to be useful in calculating the likely watershed residence times. Using the uranium and thorium data, we can use the approaches of Plater et al. (1994), Vigier et al. (2001), Moreira-Nordemann (1980) and Marques et al. (2003) to calculate erosion rates and timescales, and watershed residence times.<br/>Broader impacts of the work will include training provided to graduate students and the building of international partnerships with New Zealand and Taiwanese scientists. The PIs plan to establish a website where all the data from the proposed research and from EAR 0096285 will be placed so that it will be accessible by the broad scientific community. This research has important societal relevance in contributing  to the overall understanding of CO2 concentration in the atmosphere. Because the chemical weathering of silicate minerals on the surface of Earth is thought to be the major control on the atmospheric CO2 concentration, this research has important implications for understanding the mechanisms of greenhouse gas regulation.<br/>"
"0221109","Collaborative Research:  Impact of Snow Photochemistry on Atmospheric Radical Concentrations at Summit, Greenland","OPP","ARC Rsch Support & Logistics, ANS-Arctic Natural Sciences","09/01/2002","06/23/2004","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Jane V. Dionne","08/31/2006","$214,480.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205, 5280","0000, 1079, OTHR","$0.00","<br/>Dibb<br/>0221109<br/><br/>In the past few years there has been an explosion of scientific interest in the chemical processing occurring in sunlit snow. Rather than simply acting as a passive sink for the products of tropospheric reactions, the snowpack has been shown to be one of the most photochemically active, and strongly oxidizing, regions of the entire troposphere. The group of investigators assembled for this proposal has played a central role in this revolution in our thinking about the role of the snowpack in atmospheric chemistry. One key finding has been that photolysis of snow chromophores initiates the release of a number of important trace gases. Initial modeling suggests that photolysis of a number of these gases (HCHO, HOOH, CH3CHO and HONO) results in an enormous production of HOx  (i.e., OH and HO2), which in turn causes a large enhancement of these radicals in the snowpack and in the air just above the snow. Because oxidation by OH is the main sink for many tropospheric gases, including some of those important for climate change and stratospheric O3 depletion, this enhancement in HOx might significantly perturb tropospheric chemistry. Snowpack chemistry likely also modifies the chemical records of atmospheric composition ultimately preserved in glacial ice. While recent work has shown that photochemical and physical processes in the snowpack can impact the chemistry and composition of both the atmosphere and snowpack, these processes are, in general, poorly understood. This is especially true for the processes that produce and consume OH and HO2. The research will elucidate the processes that produce and consume OH and HO2  radicals within and above sunlit snow over a wide range of environmental conditions, thereby improving our understanding of fast photochemistry within this unique environment."
"9015954","U.S.-France Collaborative Research:  Air-Snow Transfer      Function in Greenland","OISE","FRANCE","04/15/1991","04/09/1991","Jean-Luc Jaffrezo","PA","Carnegie-Mellon University","Standard Grant","Rose Gombay","09/30/1993","$7,050.00","Jack Dibb, Cliff Davidson","","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","O/D","5918","5113","$0.00","                                                                                This award will support collaborative research between US and                   French scientists on the topic of the air-snow transfer                         function in Greenland.  The participants are: Drs. Jean-                        Luc Jaffrezo, Cliff Davidson and Jack Dibb, Carnegie Mellon                     University, and Dr. Michel Legrand, Laboratoire de Glaciologie                  et Geophysique de l'Environment, St. Martin d'Here, France.                                                                                                     The US (GISP II) and European (GRIP) deep drilling projects                     involve acquisition of two deep cores to bedrock from the                       Summit region of Greenland over the next two years.  The                        cores will provide a detailed record of about 200,000 years,                    yielding information on the earth's geologic history, climate                   change and variations in the chemical composition of                            atmospheric constituents.  One important component of the                       GISP II and GRIP projects is a program in atmospheric                           sciences, which is designed to help relate the ice core data                    to atmospheric conditions in previous times.  There are three                   objectives to this program:  1) Source regions and atmospheric                  pathways for the chemical constituents reaching the Summit                      will be identified; 2) Incorporation of these species into                      precipitation at the Summit will be investigated, in order to                   determine the mechanisms and rates of deposition during                         snowstorms; and 3) Changes in the chemical composition of the                   icesheet will be quantified.  These objectives will be                          achieved by a multicomponent program that incorporates field                    work, laboratory analyses, and computer modelling. This award                   will support collaboration between US and French researchers                    for the purpose of carrying out laboratory work, data                           interpretation and joint publications related to the above                      projects.  This effort will benefit from the complementary                      expertise of the US and French teams in the geochemistry of                     gases and aerosols, of tracers of natural and anthropogenic                     emissions and of transport and deposition mechanisms.  The                      results of this research are expected to improve greatly the                    ability of the scientific community to retrieve information                     from deep ice."
"0806075","Collaborative Research: Cool Robot to support Greenland science campaigns","OPP","ARC Rsch Support & Logistics, ARCTIC RESEARCH AND EDUCATION, CYBERINFRASTRUCTURE & SENSORS","10/01/2010","09/14/2012","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Peter West","09/30/2014","$145,103.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205, 5208, 5225","1079, 9150","$0.00","The proposed project will refine the Cool Robot, an autonomous solar-powered mobile robot, and demonstrate its potential to conduct significant scientific observations in Greenland over vast distances. Two field deployments, a week-long circuit around Summit Camp in year two and a 1,500-km traverse from Summit to NEEM and back in year three, will collect data on snow-surface characteristics and elevations as ground truth for satellite data and air samples to assess spatial and temporal variations in atmospheric chemistry near the snow surface. Ground-based data collection is crucial to furthering our understanding of glaciology and environmental sciences in Greenland. This collaborative project among Dartmouth College, UNH and CRREL builds on a successful Small Grant for Exploratory Research, a student-based pilot study that designed, fabricated, and field-tested the simple four-wheel drive, solar-powered Cool Robot. This project will provide critical performance data on robot mobility, power systems, navigation and communications over a vast polar snowfield and thus forge a path to expand the use of mobile robots to support science and logistics operations in the Greenland. Potential uses of the Cool Robot are traverses to collect glaciological data, snow characterization to study climate change, biological sampling, atmospheric and snow chemistry and photochemistry surveys, micrometeorite sampling and site inspections for meteorite fields, crevasse detection in advance of manned traverses, airfield geophysical surveys, and routine snow-road surveys. Arrays of mobile robots would allow scientific instruments to be dynamically positioned based on preliminary data or to respond to specific events. Array-based campaigns could include study of the polar atmosphere, magnetosphere, troposphere, and sub-glacial geology using a diverse set of instruments: magnetometers, GPS receivers, snow property measurement, and ground penetrating radar. The project supports instrument development and deployment, increased logistics capability and reduced costs using the Cool Robot, and is an opportunity to train students in engineering and arctic research. View the Cool Robots website http://engineering.dartmouth.edu/crobots/."
"9727418","Air-Snow Exchange of Reactive Nitrogen Oxides at            Summit, Greenland","OPP","ARC Rsch Support & Logistics, ARCSS-Arctic System Science","02/01/1998","05/15/2000","Paul Shepson","IN","Purdue Research Foundation","Continuing Grant","Michael T. Ledbetter","01/31/2002","$286,358.00","","paul.shepson@stonybrook.edu","1281 WIN HENTSCHEL BLVD","WEST LAFAYETTE","IN","479064182","3174946200","GEO","5205, 5219","1079, 5219, EGCH","$0.00","  ABSTRACT    OPP-9725252   OPP-9725463  DIBB, JACK   HONRATH, RICHARD  UNIVERSITY OF NH   MI TECHNOLOGICAL UNIVERSITY    OPP-9727093   OPP-9727418  BLAKE, DONALD  SHEPSON, PAUL  UNIVERSITY CA-IRVINE PURDUE UNIVERSITY    The project will determine the atmospheric concentration of nitrogen compounds in the atmosphere by conducting a field experiment at a field camp at the summit of the Greenland ice sheet.  The concentration of nitrogen compounds in the atmosphere will be compared to their concentration in freshly deposited snow so that the record of atmospheric chemistry that is retained in the permanent ice record at the site may be interpreted for changes in the chemistry of the troposphere that have occurred since human activities began to affect the atmosphere.  That record will lead to important conclusions about the human impacts of global change on the atmosphere and will allow an examination of the natural cycles of atmospheric chemistry over the past 100,000 years."
"9423490","Characterization of the Atmospheric Concentration           and Air-Snow Exchange of Soluble Gaseous Acids at           Summit, Greenland","OPP","ARCSS-Arctic System Science, ANS-Arctic Natural Sciences","04/15/1995","04/09/1996","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Michael T. Ledbetter","09/30/1997","$203,897.00","Robert Talbot","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5219, 5280","0000, 5219, EGCH, OTHR","$0.00","  This award is for support for a two year program to study the origin of nitrate in the atmosphere and surface snow at Summit, Greenland.  Preliminary results from unfunded pilot studies suggest that nitric acid (HNO3) is not the only, and may not even be the major nitrogen species contributing to nitrate (NO3-) in summer-time snow at Summit.  Peroxy acetyl nitrate and one or more alkyl nitrate species seem to be the most likely candidates, and they may also be contributing to the elevated concentrations of organic acids observed just above the snow surface at Summit.  Gradient measurements of soluble acidic gases will be made with 2 mist chamber samplers at different heights in the 1995 and 1996 seasons at Summit.  These measurements will be complemented with intensive experiments comparing mist chamber samples to nylon filter samples and the use of nylon filters on the mist chamber inlet, to quantify soluble nitrogen species besides nitric acid.  The primary goal of this study will be to enable improved interpretation of the nitrate records in polar ice, but additional insights into reactive nitrogen chemistry over snow covered surfaces are also anticipated."
"9908431","Airborne Measurements of Acidic Trace Gases and Aerosol Associated 210Pb, 7Be, and 10Be for the NSF/NCAR Tropospheric Ozone Production about the Spring Equinox (TOPSE) Experiment","OPP","Atmospheric Chemistry","09/01/1999","09/01/1999","Robert Talbot","NH","University of New Hampshire","Standard Grant","Jane V. Dionne","08/31/2002","$400,000.00","Jack Dibb","rtalbot@uh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524","0000, 1079, 1560, OTHR","$0.00","The proposed investigation will provide measurements of selected acidic gases and aerosol species aboard the NSF/NCAR C-130 research aircraft for the TOPSE airborne experiment.  TOPSE is the Tropospheric Ozone Production about the Spring Equinox experiment, which is a multi-investigator program designed to study the production and transport of ozone and other contaminant compounds over the mid-latitude to polar Northern Hemisphere during the transition from winter to spring conditions.  The principal focus of this investigation is on HNO3, with additional measurements of SO2, HCOOH, CH3COOH, and the naturally occurring radionuclides 210Pb, 7Be, and 10Be.  These measurements will address issues involving the sources, partitioning, and cycling of reactive nitrogen, the photochemistry of organic compounds in the polar springtime, and the origin of air masses encountered during the study."
"9910337","Science Coordination Office for Summit, Greeland Environmental Observatory (Cooperative Research with the University of Arizona)","OPP","ARC Rsch Support & Logistics","05/01/2000","05/18/2004","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Simon Stephenson","04/30/2005","$181,527.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205","0000, OTHR","$0.00","ABSTRACT<br/><br/>Summit Greenland is a site of expanding scientific interest by both U.S. and European scientists.  Current U.S. projects are evaluating ice-core characteristics related to environmental change, are investigating upper and middle atmosphere phenomena as a basis for understanding the global system, are evaluating atmospheric conditions in the troposphere and in the boundary layer contacting the Greenland permanent ice sheet, and are establishing the radiation, energy, and water balances which occur on the ice-pack.  To better coordinate the disparate communities using this environmental observatory, a Science Coordination Office will be established.   Its goals are to: 1) coordinate measurements between investigators and the sharing of facilities and personnel on-site, 2) provide scientific requirements to NSF, it's support contractor and European partners as the facility is developed, 3) stimulate sharing of data among science projects.<br/>"
"9731098","Collaborative Research:  Measurement of Aerosol Chemical and Radiative Properties in Nepal","AGS","Atmospheric Chemistry","10/01/1998","09/23/1998","Jack Dibb","NH","University of New Hampshire","Standard Grant","Anne-Marie Schmoltner","04/30/2001","$174,002.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524","1309, EGCH","$0.00","This project supports an aerosol sampling program that will be carried out in collaboration between the University of New Hampshire, the University of Colorado/CIRES, and the Nepalese Department of Hydrology and Meteorology (DHM). The concentrations of soluble ionic species, organic carbon and elemental carbon in aerosol will be determined on a continuous basis (at a nominal 2-day resolution) at these stations for approximately two years. This filter sampling will be complemented by continuous multi-wavelength aerosol optical depth measurements at each station. One station will be situated near Kathmandu, and the other at an altitude of 4100 m. The primary objective is to determine the modifications in the aerosol content of air masses as they traverse Nepal from south to north and encounter the Himalayan Massif. The alternating influence of summer monsoon air from the Bay of Bengal and wintertime westerlies are expected to cause large seasonal variations in the concentration and composition of aerosols. Optical depth measurements will provide information on the relationships between surface-level air masses and the aerosol burden in the overlying column. Little is currently known about the atmospheric chemistry over much of central Asia due to a lack of systematic sampling in this broad region. The central Asian monsoon circulation is the primary source of water for densely populated regions of Asia, and is also a major component of the global climate system. Model predictions suggest that anthropogenic modifications of atmospheric composition could greatly modify regional climate, including the strength of the summer monsoon and therefore the amount of much needed precipitation."
"9223988","Impact of Aging and Spatial Heterogeneity of Snow on the    Preservation of Atmospheric Signals in the Snowpack at      Summit, Greenland","OPP","ANS-Arctic Natural Sciences","08/15/1993","09/02/1993","Jack Dibb","NH","University of New Hampshire","Standard Grant","Bernhard Lettau","01/31/1996","$118,449.00","Ernst Linder","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","O/D","5280","","$0.00","This is one of four coordinated projects that will make use of the              camp facilities established on the ice sheet in the interior of                 Greenland as part of the GISP-2 ice core drilling effort, in order              to investigate how atmospheric trace elements are deposited on the              ice and what kind of changes they undergo as they are being                     incorporated into the ice.  An understanding of such processes is               necessary in order to properly interpret the proxy climate data                 that can be recovered from ice cores.  While significant progress               has been made recently in extracting and analyzing ice cores,                   progress in understanding the air to snow transfer process for                  reactive chemical species has lagged behind.                                                                                                                    The major goal of this project is to understand the reasons for                 changes in the composition of snow at or near the surface of the                Greenland ice sheet that are observed to occur within days or weeks             after deposition.  It is known that the concentration of soluble                ionic species and aerosol-associated species may change rapidly                 with time, but the variability may be masked by small-scale spatial             heterogeneity.  A sampling protocol will be set up to characterize              the spatial variability on the one meter to one kilometer scale.                                                                                                Beryllium-7, a naturally-occurring radionuclide that is formed in               the stratosphere, will be used as an indicator for small aerosol                particles.  Its close association with atmospheric particulates and             half-life of 53 days make it a useful tracer of the incorporation               of aerosols in the snow and their post-depositional redistribution              within the snowpack"
"0425406","Collaborative Research: Particulate Organic Carbon in the Air and Snow at Summit, Greenland","OPP","ARC Rsch Support & Logistics, ANS-Arctic Natural Sciences","09/15/2004","09/07/2004","Jack Dibb","NH","University of New Hampshire","Standard Grant","William J. Wiseman, Jr.","08/31/2008","$262,873.00","Robert Griffin","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205, 5280","0000, 1039, 1079, OTHR","$0.00","<br/>This is a collaborative proposal by Principal Investigators at Georgia Institute of Technology, Universities of New Hampshire, and Wisconsin-Madison. Atmospheric aerosols are of concern because they can influence climate by altering the radiation balance of the Earth and are harmful to human health.  Fine particulate matter (particles having diameters less than 2.5 micrograms) contains a significant amount of both organic carbon (OC) and elemental carbon (EC), which can account for a considerable fraction of the fine particulate mass. The OC fraction is composed of a wide variety of compounds from both anthropogenic and natural sources. Little is known about the historical concentrations, sources and emissions of carbonaceous aerosols. Ice core concentrations of OC and specific organic compounds could yield information on the past influence of carbonaceous aerosols on climate and the sources of these aerosols. Before ice core concentrations of carbonaceous compounds related to particulate matter deposition can be evaluated, it is important to determine the link between the concentrations in air and snow. In addition, the extent to which carbonaceous aerosol is modified after deposition to snow needs to be determined before specific compounds can be used to infer past atmospheric concentrations. Preliminary results of water insoluble particulate organic carbon (IPOC) in a snow pit from Summit, Greenland show a decrease of ~ 50% in IPOC concentrations in the top 50 cm, hinting that early post depositional processes may be very important. These results are consistent with recent suggestions that organic carbon in surface snow may play an important role in snow photochemistry. The Principal Investigators will conduct a field study at Summit in 2006 to measure the concentrations of particulate OC, EC, and specific organic compounds that serve as source tracers in the air, surface snow, and snow pits. To assess the influence of post depositional processes in surface snow, they will measure the concentrations of water-soluble gas-phase organic compounds (WSGOC) in the atmospheric and firn air with the expectation that the degradation of IPOC in surface snow leads to the formation of WSGOC.   They will deposit carbon-13- and deuterium-labeled particulate organic compounds to surface snow and measure the change in concentration over the duration of the field season. In addition, they will conduct specific experiments where surface snow is shaded from solar radiation in order to determine the relative influence of photochemistry on the degradation of particulate organic compounds deposited to surface snow.  The research will yield insights into the processes that influence the concentrations of particulate carbon in the air and snow at Summit and will serve as the groundwork for future modeling, laboratory and field studies that will focus on the deposition, and transformation of particulate organic compounds in snow.<br/>Broader Impacts: The research will advance education through the training of several graduate and undergraduate students, including students from under-represented minority groups. The information will be disseminated through conference presentations, publications, and a webpage as well as within graduate and undergraduate courses.   The Principal Investigators will give presentations at K-12 schools. The research effort will result in the development of new measurement techniques as well as unique modifications to existing techniques. The project will yield insights into processes that are of importance to the atmospheric sciences as well as paleoclimate communities. The research will potentially open the door for studies that address the historical sources and impacts of aerosols based on the concentrations of specific organic compounds deposited in snow. <br/><br/>"
"9813550","Seasonal Differences in Air-Snow Chemical Relationships at Summit, Greenland","OPP","ARCSS-Arctic System Science","12/15/1998","12/08/1998","Donald Blake","CA","University of California-Irvine","Standard Grant","Michael T. Ledbetter","11/30/2001","$90,000.00","","drblake@uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","GEO","5219","1079, 5219, EGCH","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY                KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462   OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"9813333","Seasonal Differences in Air-Snow Chemical Relationships at Summit, Greenland","OPP","ARCSS-Arctic System Science","12/15/1998","07/23/2003","Lloyd Currie","MD","NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY","Interagency Agreement","Neil R. Swanberg","01/31/2004","$90,000.00","","lloyd.currie@nist.gov","100 BUREAU DRIVE STOP 1070","GAITHERSBURG","MD","208990003","3019756633","GEO","5219","1079, 5219, EGCH","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY                KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462   OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"9907197","Investigation of Photochemical Transformation within Snow and their Effect on Snow and Atmospheric Composition","OPP","ARC Rsch Support & Logistics, ARCSS-Arctic System Science, ANS-Arctic Natural Sciences","09/01/1999","06/27/2001","Richard Honrath","MI","Michigan Technological University","Continuing Grant","Jane V. Dionne","08/31/2003","$277,760.00","Sarah Green, Matthew Peterson","reh@mtu.edu","1400 TOWNSEND DR","HOUGHTON","MI","499311200","9064871885","GEO","5205, 5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197    OPP-9907469  OPP-9907330<br/>HONRATH, RICHARD   DIBB, JACK  ALBERT, MARY<br/>MICH. TECH. UNIVERSITY   UNIVERSITY NH CRREL<br/><br/>OPP-9907376    OPP-9907623  OPP-9907434<br/>SHEPSON, PAUL   BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY   UC-IRVINE  UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow.  The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow.  The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past.  The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities.  The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere.<br/><br/><br/><br/><br/>"
"9907330","Investigation of Photochemical Transformation within Snow and Their Effect on Snow and Atmospheric Composition","OPP","ARCSS-Arctic System Science, ANS-Arctic Natural Sciences","09/01/1999","07/27/2001","Mary Albert","MS","Department of Army Cold Regions Research & Engineering Lab","Interagency Agreement","Jane V. Dionne","08/31/2002","$166,205.00","","Mary.R.Albert@Dartmouth.edu","3909 Halls Ferry Road","Vicksburg","MS","391806133","6036464201","GEO","5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197    OPP-9907469  OPP-9907330<br/>HONRATH, RICHARD   DIBB, JACK  ALBERT, MARY<br/>MICH. TECH. UNIVERSITY   UNIVERSITY NH CRREL<br/><br/>OPP-9907376    OPP-9907623  OPP-9907434<br/>SHEPSON, PAUL   BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY   UC-IRVINE  UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow.  The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow.  The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past.  The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities.  The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere.<br/><br/>"
"9907376","Investigation of Photochemical Transformation within Snow and their Effect on Snow and Atmospheric Composition","OPP","ARCSS-Arctic System Science, ANS-Arctic Natural Sciences","09/01/1999","08/08/2001","Paul Shepson","IN","Purdue Research Foundation","Continuing Grant","Jane V. Dionne","08/31/2003","$106,100.00","","paul.shepson@stonybrook.edu","1281 WIN HENTSCHEL BLVD","WEST LAFAYETTE","IN","479064182","3174946200","GEO","5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197    OPP-9907469  OPP-9907330<br/>HONRATH, RICHARD   DIBB, JACK  ALBERT, MARY<br/>MICH. TECH. UNIVERSITY   UNIVERSITY NH CRREL<br/><br/>OPP-9907376    OPP-9907623  OPP-9907434<br/>SHEPSON, PAUL   BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY   UC-IRVINE  UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow.  The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow.  The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past.  The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities.  The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere.<br/><br/>"
"0230117","Collaborative Research: Antarctic Tropospheric Chemistry Investigation (ANTCI)","OPP","ANT Ocean & Atmos Sciences","08/15/2003","08/14/2003","Jack Dibb","NH","University of New Hampshire","Standard Grant","Kelly Falkner","07/31/2007","$75,323.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5113","0000, OTHR","$0.00","The proposed work is one component of a collaborative four-year study of the sulfur chemistry in the antarctic atmosphere, including two antarctic summer field seasons in 2003-04 and 2005-06.  The overall project, (ANTCI; Antarctic Tropospheric Chemistry Investigation), involves thirteen principal and senior investigators at seven institutions. <br/>The broad based goal of this program will be to enhance our understanding of the processes that control tropospheric levels of reactive hydrogen radicals, reactive nitrogen, sulfur, and other trace species over the Antarctic continent for the further purpose of improving the climatic interpretation of sulfur-based signals in antarctic ice core records.  The results will provide a far more comprehensive understanding of Antarctic atmospheric chemistry as well as lead directly to further insights about the atmospheric factors that influence the levels and distributions of climate proxy species in Antarctic ice cores.  It is based on and has evolved from a number of other sulfur studies during the last decade, including earlier studies by this group of investigators in the antarctic interior and at a coastal site.   This component is concerned with the quantification of organic acids in sampled air, using a mist chamber and ion chromatography.<br/>Major science objectives of the overall project will include: 1) evaluating the detailed dynamical and chemical processes that control spring and summertime levels of reactive radicals in the atmospheric surface layer at South Pole;  2) Assess the representativeness of the previously obtained South Pole and coastal measurements in the larger context of polar plateau processes; and 3) investigating the relative importance of the oxidative processes involved in the coast-to-plateau transport of reduced sulfur and determining the principal regions of chemical transition. Secondary objectives will include investigating snow/firn chemical species that undergo extensive exchange with the atmosphere, and  assessing the different chemical forms of the trace elements and their relationships to the levels of ozone and other oxidants.<br/> Atmospheric sulfur chemistry is an important component in climate change issues because both naturally and anthropogenically emitted sulfur compounds form minute particles in the atmosphere (so-called aerosols) that reflect solar radiation, produce atmospheric haze and acid rain, and affect ozone depletion.  Sulfate particles in the atmosphere may also act as condensation nuclei for water vapor and enhance global cloudiness.  The primary natural sources of sulfur are volcanic emissions and DMS production by oceanic phytoplankton.   On the millennial time scale the variability and natural background level of atmospheric aerosols can be reconstructed from the preserved paleorecords in ice cores.  It is however necessary to understand how the physical and chemical environment of the oxidation process affects the relative concentrations of the oxidation products that become buried in the ice.<br/>"
"1135432","FESD Type 1: Sun to Ice--Impacts on Earth of Extreme Solar Events","AGS","Front in Earth Sys Dynamics, EPSCoR Co-Funding","10/01/2011","09/25/2012","Harlan Spence","NH","University of New Hampshire","Standard Grant","Anne-Marie Schmoltner","09/30/2018","$5,000,000.00","Terry Forbes, Jack Dibb, Nathan Schwadron, Ruth Varner","Harlan.Spence@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","8016, 9150","1521, 4444, 9150, OTHR","$0.00","""Sun-to-Ice"" is a 5-year research project that explores extreme events generated by our Sun and their effects on the Earth.  The project draws together scientists from many different disciplines to tackle a question of growing importance to our society:  What are the extremes of solar activity that produce powerful space weather effects at Earth which pose risks to society?  Decades of research have prepared the undertaking of this study.  We know that the Sun is capable of creating explosive events and that these events generate dangerous streams of energetic charged particles that can arrive at the Earth moments later.  We also know that these solar particles can slam into our atmosphere and affect its chemistry, including in the ozone layer.  These same particles can cripple satellite systems we depend on in everyday life (GPS, communications, etc.), and pose radiation risks to astronauts and even to airline passengers.  However, we only have measured such events during the space age over the past 50 years, a brief wink of time compared to the age of the Sun and solar system.  <br/><br/>""Sun-to-Ice"" investigates extreme solar events and their effects on Earth by detailed studies of  the physical processes linking the Sun to Earth.  The project will study how solar eruptions lead to giant blasts of material called coronal mass ejections and how they evolve in space once they leave the Sun.  It investigates the processes by which these extreme solar events accelerate charged particles and how these particles are transported from the Sun to Earth. It also studies how these dangerous charged particles enter the Earth's atmosphere and how they change its chemical properties.  Finally, it will study how chemical signatures of these events are recorded in ice near the poles. By confirming a link between extreme solar activity and the ice core record, deep ice cores can thus be used as a means for unraveling the history of ancient solar activity and establishing the range of extreme solar events.  This project seeks to make breakthroughs in diverse, complex and interlinked systems that cross the boundaries between space physics, atmospheric, and ice core science, yielding insights into the genesis of extreme events and their impact on Earth."
"9417818","Ice Core Records from Monsoon Asia","AGS","Paleoclimate, ANS-Arctic Natural Sciences, Climate & Large-Scale Dynamics","05/01/1995","10/21/1999","Cameron Wake","NH","University of New Hampshire","Continuing Grant","Steven M. Colman","09/30/1999","$643,306.00","Paul Mayewski, Loren Meeker, Jack Dibb","cameron.wake@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1530, 5280, 5740","0000, OTHR","$0.00","Abstract  ATM-9417818  Wake, Cameron  University of New Hampshire  Title: Ice Core Records from Monsoon Asia    The highlands of central Asia possess a diversity of natural  archives from which detailed paleoclimatic records can be developed  (e.g., lake sediments, loess, tree rings, ice cores, glacier  fluctuations, geomorphologic features).  Despite this potential,  relatively little is known concerning climatic changes in the  region over time scales ranging from centuries to hundreds of  thousands of years.  The primary objective of this project is to  develop multi-variate, well-dated, high-resolution (annual)  paleoclimatic records for monsoon Asia for the last 500 to >1000  years.  This project will focus on the chemical and physical  analysis of deep (approximately 200m) firn/ice cores recovered from  two high elevation (>6000m) glaciers in the Nepalese Himalaya.   Time-series developed from the physical and chemical analysis of  the ice core will form the basis of a regional paleoclimatic  record.  The proposed ice core research in monsoon Asia represents  a key component of the Himalayan Interdisciplinary Paleoclimate  Project (HIPP).  HIPP is aimed at improving our understanding of  the behavior of the Indian and Plateau monsoons over the past 2000  years, 20,000 years, and beyond.  Multi-variate paleoclimatic  records from a wide variety of natural archives in the highlands of  Central Asia.  In addition, multivariate, high resolution ice core  records from the Himalayas will be compared directly with similar  detailed ice core data records recovered from Tibet, Peru,  Greenland and Antarctica, thereby developing a broader, more  globally comprehensive ice core data base from which to investigate  global change."
"9530579","Relationships Between Air and Snow Chemistry in Winter at   Summit, Greenland. (Cooperative Research with U.AZ, CRREL,  CMU, Univ. of Wisc.-Milwaukee, UC-Irvine)","OPP","ARCSS-Arctic System Science","09/01/1996","05/15/1997","Jack Dibb","NH","University of New Hampshire","Standard Grant","Michael T. Ledbetter","08/31/1998","$176,049.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5219","5219, EGCH","$0.00","The research is a collaborative project among researchers at six universities.  The researchers will extend their previous study of the record of atmospheric chemistry concentrations recorded I the glacial ice at Summit, Greenland form a summer-only study to a full year by adding a winter sampling program.  The ice core record from the Greenland Ice Sheet Project (GISP2) has been analyzed for traces of atmospheric chemistry but the results cannot be fully assessed until a complete annual record of present chemistry is available because the largest signal in the ice core results form snow that accumulates during the winter months.  A winter sampling program has been logistically impossible until this year.  A complete annual cycle of the record of how modern atmospheric record from GISP2 ice cores for the past 110,000 years."
"9122555","Atmospheric Radionuclide Studies at the GISP 2 Atmospheric  Sampling Camp","OPP","ANS-Arctic Natural Sciences","04/01/1992","04/08/1992","Jack Dibb","NH","University of New Hampshire","Standard Grant","Bernhard Lettau","09/30/1994","$71,547.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","O/D","5280","","$0.00","This project is a study of the processes active in determining the              characteristics of aerosols that are removed from the arctic                    atmosphere and deposited in the Greenland ice sheet.  These                     processes involve the dynamics of tropospheric and stratospheric                mass exchange, the efficiency with which aerosols and associated                chemical species are removed from the lower atmosphere, the                     relative importance of wet and dry deposition, and the early                    post-depositional chemical and concentration changes in the snow.               Knowledge of these processes is crucial to the reconstruction of                paleoatmospheres from the record that is preserved in the ice                   sheet.                                                                               Air sample filters and snow and ice samples collected at the               Atmospheric Chemistry Camp that is part of the Greenland Ice Core               drilling program will be analyzed for radionuclides, including                  Beryllium-7, Beryllium-10, Chlorine-36, and Lead-210.  Beryllium-7              is a cosmogenic radionuclide that is useful as a tracer of                      intrusions of stratospheric air, while Lead-210 results from the                decay of radon emitted from the Earth's surface and is a tracer for             continental air masses.  While Chlorine-36 is an important                      modulator in ozone chemistry, its ratio to Beryllium-10 may                     possibly become a method for dating ice cores older than 50,000                 years.  Results to date have been mixed because the ratio can                   fluctuate greatly over small depth intervals.  This project however             will obtain data on time scales short enough to determine whether               short term differences in the transport mechanism or seasonal                   variations in the efficiency of the removal process cause the                   observed fluctuations."
"0908588","Collaborative Research: The impact of bromine chemistry on the isotopic composition of nitrate at Summit, Greenland","OPP","ANS-Arctic Natural Sciences","09/15/2009","09/11/2009","Jack Dibb","NH","University of New Hampshire","Standard Grant","Henrietta Edmonds","08/31/2013","$286,305.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5280","0000, 1079, 9150, OTHR","$0.00","Nitrate is one of the major ions found in alpine and polar snow, yet it continues to be one of the least understood chemical components in ice core records. Recent work ahs shown nitrate isotope ratios to be a powerful tool for the study of nitrate in snow and ice cores. The isotopic composition of nitrate has been shown to contain information about the source of the nitrate (nitrogen oxides) and the oxidation processes that convert nitrogen oxides to nitrate in the atmosphere prior to deposition. Because hydroxyl and peroxy radicals have very different isotopic compositions than ozone, one can now distinguish the impact of the different oxidation processes that produce nitrate in the atmosphere. Seasonal observations of the oxygen isotopic composition of nitrate in snow at Summit, Greenland, cannot be understood in terms of standard, local photochemistry. The most likely causes of the model and observation discrepancy are that the box model lacks transport of nitrate from regions outside of Summit and the influence of halogen chemistry (i.e., BrO) on nitrate. Recent measurements suggest a higher than expected presence of BrO in the boundary layer above Summit. The aim of this project is to quantify the influence of bromine chemistry on nitrate production in the spring and summer. The approach includes field and laboratory measurements as well as modeling. During spring and summer field seasons, BrO and multiple gas-phase measurements will be conducted on-site, while isotopic analyses of snow and atmospheric samples will be completed in the laboratory. The oxygen isotopic composition of nitrate in snow and glacial ice holds potential for quantitatively reconstructing paleoatmospheric oxidant concentrations, but it is important to constrain how much this tracer reflects local versus regional or hemispheric scale chemistry. Furthermore, since BrO at Summit most likely originates from a natural source, and this source is affected by changes in climate, the influence of halogen chemistry on nitrogen oxides has important implications for the interpretation of recent and deep ice core records of nitrate."
"0455299","Collaborative Research:    Science Coordination for Summit Station, Greenland","OPP","ARC Rsch Support & Logistics","08/15/2005","07/06/2009","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Renee Crain","07/31/2011","$322,476.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5205","0000, 1079, OTHR","$0.00","This activity will continue support for an office that assists the community of scientist that uses an international research site on the summit of the Greenland ice sheet.  Over 20 groups from the U.S. and Europe are using the site and others have projects pending.  One key to success of this shared facility is to closely coordinate measurements, share facility resources and exchange data of common interest between investigators to make most efficient use of the facility and resources. Since this coordination goes well beyond what individual investigators can efficiently do through one-to-one interactions,  NSF has supported a Science Coordination Office (SCO) since 1999 to work with scientists, the logistic contractor and others to plan both near and long term activities that require strong involvement from the science community. <br/><br/>This proposal provides for continuation of the SCO, which has three main objectives:<br/><br/>Plan and coordinating measurements including sharing of facilities and personnel, data and requests to funding agencies for upgrades and maintenance to facilitate science;working with the logistics contractor and NSF to plan, develop and operate the  station to serve a growing international and multidisciplinary community while maintaining scientific integrity of the site during the transition; and carrying out strategic planning, working with international and national agencies who are involved with supporting activities at Summit, facilitating communication between investigators and reporting to funding agencies.<br/><br/>"
"9727093","Air-Snow Exchange of Reactive Nitrogen Oxides at Summit,    Greenland","OPP","ARCSS-Arctic System Science","02/01/1998","02/10/2000","Donald Blake","CA","University of California-Irvine","Continuing Grant","Michael T. Ledbetter","01/31/2001","$197,938.00","","drblake@uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","GEO","5219","5219, EGCH","$0.00","  ABSTRACT    OPP-9725252   OPP-9725463  DIBB, JACK   HONRATH, RICHARD  UNIVERSITY OF NH   MI TECHNOLOGICAL UNIVERSITY    OPP-9727093   OPP-9727418  BLAKE, DONALD  SHEPSON, PAUL  UNIVERSITY CA-IRVINE PURDUE UNIVERSITY    The project will determine the atmospheric concentration of nitrogen compounds in the atmosphere by conducting a field experiment at a field camp at the summit of the Greenland ice sheet.  The concentration of nitrogen compounds in the atmosphere will be compared to their concentration in freshly deposited snow so that the record of atmospheric chemistry that is retained in the permanent ice record at the site may be interpreted for changes in the chemistry of the troposphere that have occurred since human activities began to affect the atmosphere.  That record will lead to important conclusions about the human impacts of global change on the atmosphere and will allow an examination of the natural cycles of atmospheric chemistry over the past 100,000 years."
"9813462","Seasonal Differences in Air-Snow Chemical Relationships at  Summit, Greenland","OPP","ARCSS-Arctic System Science","12/15/1998","07/08/2002","Cliff Davidson","PA","Carnegie-Mellon University","Standard Grant","Neil R. Swanberg","11/30/2003","$102,979.00","","davidson@syr.edu","5000 FORBES AVE","PITTSBURGH","PA","152133815","4122688746","GEO","5219","1079, 5219, 9178, 9251, EGCH, SMET","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY                KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462                 OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"0309755","Collaborative Research: Factors Controlling Chemical Weathering in Regions of Very High Physical Weathering Rates","EAR","Hydrologic Sciences","08/15/2003","06/20/2008","Anne Carey","OH","Ohio State University Research Foundation -DO NOT USE","Continuing Grant","Thomas Torgersen","07/31/2009","$231,296.00","W. Berry Lyons","carey.145@osu.edu","1960 KENNY RD","Columbus","OH","432101016","6146888734","GEO","1579","1325, 9189, EGCH","$0.00","0309755<br/>Carey<br/>Over the past decade, a debate has taken place concerning the ultimate controls on chemical weathering at Earth's surface. Some have argued that the rate of physical weathering, not climate, is the major control on chemical weathering. Physical weathering is highest in areas of rapid tectonic uplift. Rapidly uplifting tectonic regimes with high frequency rainfall events are the dominant feature of many high-standing oceanic islands in the SW Pacific/Australasian region. High-standing islands (HSIs) there produce at least 33% of the sediment entering the marine environment annually. Because of this, HSIs have some of the highest physical weathering rates known on Earth. Research in our previous grant (EAR 0096285) determined chemical weathering rates in some New Zealand watersheds. Comparison of newly determined chemical weathering rates to the previously determined physical weathering rates showed that, although the ratio of chemical to physical weathering is low, the absolute rates of chemical weathering are some of the highest ever observed. Preliminary observations from Taiwan indicate that chemical weathering rates there are also very high. The current project is a return to New Zealand and Taiwan to collect water, suspended sediment and soil and sediment samples in order to conduct the following work: 1. Use a suite of radionuclides (7Be, 137Cs, 210Pb) to determine residence times of sediments in the soils and floodplains of two previously investigated watersheds in New Zealand; 2. Use a full suite of major, minor and trace element analyses to evaluate the physical and chemical weathering rates in New Zealand and Taiwan watersheds whose primary lithology is volcanic rocks; 3. Use data from activities 1 and 2 and the results of our previous research to develop a quantitative framework to evaluate the relationship between physical and chemical weathering rates, especially in these regions of very high physical weathering. <br/>At the locations where we collect soil and streambed sediment profiles for 7Be, 137Cs and 210Pb, we shall collect additional samples for future analysis of uranium and thorium series nuclides. These samples will be archived until time and funds permit, we shall analyze these samples using the ICP-MS at OSU's MARC analytical center. The data will be used for calculation of watershed residence times. We plan these additional activities in response to the reviewer comment that the original choice of nuclides had half-lives too short to be useful in calculating the likely watershed residence times. Using the uranium and thorium data, we can use the approaches of Plater et al. (1994), Vigier et al. (2001), Moreira-Nordemann (1980) and Marques et al. (2003) to calculate erosion rates and timescales, and watershed residence times.<br/>Broader impacts of the work will include training provided to graduate students and the building of international partnerships with New Zealand and Taiwanese scientists. The PIs plan to establish a website where all the data from the proposed research and from EAR 0096285 will be placed so that it will be accessible by the broad scientific community. This research has important societal relevance in contributing  to the overall understanding of CO2 concentration in the atmosphere. Because the chemical weathering of silicate minerals on the surface of Earth is thought to be the major control on the atmospheric CO2 concentration, this research has important implications for understanding the mechanisms of greenhouse gas regulation.<br/>This is a collaborative proposal among Drs. Carey and Lyons at The Ohio State University, Dr. Dibb at the University of New Hampshire, Dr. Kao of Academia Sinica, Taiwan, and Dr. Hicks of the National Institute of Water and Atmospheric Research, New Zealand. <br/>"
"9813441","Seasonal Differences in Air-Snow Chemical Relationships at Summit, Greenland","OPP","ARCSS-Arctic System Science","01/01/1999","01/05/1999","Mary Albert","MS","Department of Army Cold Regions Research & Engineering Lab","Interagency Agreement","Michael T. Ledbetter","12/31/2001","$90,611.00","","Mary.R.Albert@Dartmouth.edu","3909 Halls Ferry Road","Vicksburg","MS","391806133","6036464201","GEO","5219","1079, 5219, EGCH","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY                KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462   OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"9725463","Air-Snow Exchange of Reactive Nitrogen Oxides at Summit,    Greenland","OPP","ARC Rsch Support & Logistics, ARCSS-Arctic System Science","02/01/1998","01/13/2000","Richard Honrath","MI","Michigan Technological University","Continuing Grant","Michael T. Ledbetter","01/31/2001","$496,279.00","","reh@mtu.edu","1400 Townsend Drive","Houghton","MI","499311295","9064871885","GEO","5205, 5219","5219, EGCH","$0.00","  ABSTRACT    OPP-9725252   OPP-9725463  DIBB, JACK   HONRATH, RICHARD  UNIVERSITY OF NH   MI TECHNOLOGICAL UNIVERSITY    OPP-9727093   OPP-9727418  BLAKE, DONALD  SHEPSON, PAUL  UNIVERSITY CA-IRVINE PURDUE UNIVERSITY    The project will determine the atmospheric concentration of nitrogen compounds in the atmosphere by conducting a field experiment at a field camp at the summit of the Greenland ice sheet.  The concentration of nitrogen compounds in the atmosphere will be compared to their concentration in freshly deposited snow so that the record of atmospheric chemistry that is retained in the permanent ice record at the site may be interpreted for changes in the chemistry of the troposphere that have occurred since human activities began to affect the atmosphere.  That record will lead to important conclusions about the human impacts of global change on the atmosphere and will allow an examination of the natural cycles of atmospheric chemistry over the past 100,000 years."
"9907314","Investigation of Photochemical Transformation within Snow and Their Effect on Snow and Atmospheric Composition","PLR","ARCTIC RESEARCH AND EDUCATION, ARCTIC SYSTEM SCIENCE PROGRAM, ARCTIC NATURAL SCIENCES","09/01/1999","02/27/2001","Konrad Steffen","CO","University of Colorado at Boulder","Continuing grant","Jane V. Dionne","08/31/2002","$145,471.00","","koni@seaice.colorado.edu","3100 Marine Street, Room 481","Boulder","CO","803031058","3034926221","GEO","5208, 5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197 OPP-9907469 OPP-9907330<br/>HONRATH, RICHARD DIBB, JACK ALBERT, MARY<br/>MICH. TECH. UNIVERSITY UNIVERSITY NH CRREL<br/><br/>OPP-9907376 OPP-9907623 OPP-9907434<br/>SHEPSON, PAUL BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY UC-IRVINE UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow. The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow. The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past. The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities. The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere."
"2109023","Collaborative Research: Multi-phase Sulfur and Nitrogen Chemistry in Air and Snow during Alaskan Layered Pollution and Chemical Analysis (ALPACA)","AGS","Atmospheric Chemistry","06/15/2021","06/10/2021","Jack Dibb","NH","University of New Hampshire","Standard Grant","Sylvia Edgerton","05/31/2024","$194,683.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524","001E, 9150, 9188","$0.00","This collaborative effort will contribute to the interagency-supported Alaskan Layered Pollution and Chemical Analysis (ALPACA) program, that includes the NSF-funded Sustainably Navigating Arctic Pollution Through Engaging Communities (SNAP-TEC) project. This project focuses on chemical mechanisms for the conversion of sulfur dioxide to particulate sulfate under the cold, low-light conditions in Fairbanks Alaska. This research also will investigate the ability of snow chemistry to affect air quality. The results of this study will contribute to a better understanding of the chemical mechanisms for forming air pollution in northerly regions, such as in Fairbanks. <br/><br/>The following two hypotheses will be examined through a combination of field, laboratory, and modeling studies: (1) Brown carbon drives the oxidation of S(IV) to particle sulfate through reactions involving BrC-derived triplet excited states (3C*) and hydrogen peroxide (H2O2); and (2) The persistent winter snowpack has a significant influence on the oxidative capacity of the atmosphere (e.g., through release of HONO), as well as on the processing of sulfur and nitrogen. <br/><br/>One of the broader impacts of this research includes the development of science modules for local middle school students. The modules will be made freely available to teachers, homeschooling parents, and self-guided students. For the homeschooling audience, the PIs plan to supplement the activities with projects that utilize data from air monitoring networks that leverage active-learning principles. The homeschooling sub-focus is particularly important for Alaska Native and American Indian populations, who rely on homeschooling much more than other groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria."
"9909428","Air-Snow Exchange of Nitric and Nitrous Acids at South Pole","OPP","ANT Ocean & Atmos Sciences","01/01/2000","09/07/1999","Jack Dibb","NH","University of New Hampshire","Standard Grant","Bernhard Lettau","08/31/2002","$69,001.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","5113","0000, OTHR","$0.00","The proposed work is an addition to a four-year study of the sulfur chemistry in the antarctic atmosphere, including two summer field seasons at South Pole station, one in 1998-99 and the second to occur in 2000-01. Investigations of Sulfur Chemistry in the Antarctic Troposphere (ISCAT) is a major project, involving ten principal and senior investigators at five institutions with seven additional contributing investigators.<br/> <br/>During the 1998-99 field season ISCAT scientists found levels of reactive nitrogen in the atmospheric boundary layer at South Pole station that greatly exceeded levels predicted from standard gas phase tropospheric chemistry models.  Since it is highly unlikely that these nitrogen species could have been transported in from lower latitudes, it was supposed that there is a local source within the antarctic snow cover.  This supposition has enormous consequences because it means that the snow does not act as a simple accumulator and integrator of atmospheric trace gases, and that observed concentrations in snow and ice cores cannot be simply taken as reflecting atmospheric conditions at the time the snow was falling.<br/> <br/>In the 2000-01 season the observational protocol of ISCAT will include an expanded nitrogen oxide chemistry.  Nitric and nitrous acid will be measured both in the atmosphere and in the snow, with the reduced data available in near-real time to guide the ISCAT observational program. <br/>"
"8821960","Atmospheric Radionuclides in South Central Greenland","OPP","ANS-Arctic Natural Sciences","03/15/1989","04/13/1989","Jack Dibb","NH","University of New Hampshire","Standard Grant","Bernhard Lettau","08/31/1990","$37,299.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","O/D","5280","","$0.00","This project is a study of the processes that are active in determining         the characteristics of aerosols that are removed from the arctic                atmosphere and deposited in the Greenland ice sheet.  These processes           involve the dynamics of tropospheric and stratospheric mass exchange,           the efficiency with which aerosols and associated chemical species are          removed from the lower atmosphere, the relative importance of wet and           dry deposition, and the early post-depositional chemical and                    concentration changes in the snow.  Knowledge of these processes is             crucial to the reconstruction of paleoatmospheres from the record that          is preserved in the ice sheet.                                                                                                                                  Air sample filters and snow and ice samples collected in a year-long            effort at Dye-3 in southern Greenland will be analyzed for                      radionuclides, including Beryllium-7, Beryllium-10, Chlorine-36, and            Lead-210.  Beryllium-7 is a cosmogenic radionuclide that is useful as a         tracer of intrusions of stratospheric air, while Lead-210 results from          the decay of radon emitted from the Earth's surface and is a tracer for         continental air masses.  While Chlorine-36 is an important modulator in         ozone chemistry, its ratio to Beryllium-10 may possibly become a method         for dating ice cores older than 50,000 years.  Results to date have been        mixed because the ratio can fluctuate greatly over small depth                  intervals.  This project however will obtain data on time scales short          enough to determine whether short term differences in the transport             mechanism or seasonal variations in the efficiency of the removal               process cause the observed fluctuations."
"0612075","Collaborative Research:  Radical Chemistry over Sunlit Snow at Summit, Greenland","AGS","Atmospheric Chemistry","10/01/2006","05/06/2010","Jack Dibb","NH","University of New Hampshire","Continuing Grant","Anne-Marie Schmoltner","09/30/2010","$344,435.00","","jack.dibb@unh.edu","51 COLLEGE RD SERVICE BLDG 107","DURHAM","NH","038242620","6038622172","GEO","1524","0000, 9150, OTHR","$0.00","This project addresses the role of halogens in atmospheric chemistry at Summit, Greenland. Recent studies of chemical processing above and within sunlit snow have shown that polar regions are photochemically active and strongly oxidizing. In previous measurement campaigns at Summit, HO2 (peroxy radical) concentrations were found to be high and consistent with photochemical models; however, levels of OH (hydroxyl radical) were significantly elevated compared to steady-state model simulations. This occurred primarily during periods of high wind. This suggests two, not mutually exclusive, hypotheses: (1) episodic transport of reactive halogens from the marine boundary layer or free troposphere could lead to halogen activation in firn by heterogeneous reactions, and (2) local formation of reactive halogens in the photochemically active snow pack or on airborne ice during windy periods.<br/> <br/>This project involves measurements of a variety of chemical species in the Summit Greenland surface layer, including O3 (ozone), NO (nitrogen oxide), NO2 (nitrogen dioxide), H2O (water vapor), HONO (nitrous acid), RONO2 (organic nitrates), HCHO (formaldehyde), HCOOH (formic acid), CH3COOH (acetic acid), CO (carbon monoxide), CH4 (methane), reactive NMHCs (non-methane hydrocarbons), and a variety of halogen species, including BrO (bromine monoxide), IO (iodine monoxide), and OIO (iodine dioxide), as well as soluble gas phase bromide. Rates of photochemical reactions will be determined above and within the snow. Intensive sampling seasons are planned for summer 2007 (when sunlight is at a maximum), and spring 2008 (during rapid temperature changes). Measurements over a wide range of environmental conditions as well as transport regimes will help to discriminate the relative importance of halogens on the photochemical cycling of reactive hydrogen radicals (HOx). Field measurements will be interpreted with the aid of back trajectory tools (specifically, the FLEXPART model) and by employing a photochemical steady-state box model to determine the HOx cycling within the Summit boundary layer.<br/> <br/>If successful, this project will produce novel insights in chemical processes in an environment typical of polar regions, and improve our understanding of fundamental processes involving halogen compounds. The project will provide opportunities for graduate and undergraduate students to gain research experience. A broad program of public outreach is planned as well."
"9813442","Seasonal Differences in Air-Snow Chemical Relationships at Summit, Greenland","OPP","ARC Rsch Support & Logistics, ARCSS-Arctic System Science","12/15/1998","01/03/2001","Roger Bales","AZ","University of Arizona","Standard Grant","Neil R. Swanberg","11/30/2002","$103,364.00","","rbales@ucmerced.edu","888 N EUCLID AVE RM 510","TUCSON","AZ","857194824","5206266000","GEO","5205, 5219","0000, 1079, 5219, EGCH, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY                KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462   OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"9813549","Seasonal Differences in Air-Snow Chemical Relationships at Summit, Greenland","OPP","ARCSS-Arctic System Science","12/15/1998","10/25/2002","Jonathan Kahl","WI","University of Wisconsin-Milwaukee","Standard Grant","Neil R. Swanberg","11/30/2003","$89,717.00","","kahl@uwm.edu","3203 N DOWNER AVE","MILWAUKEE","WI","532113153","4142294853","GEO","5219","1079, 5219, EGCH","$0.00","ABSTRACT<br/><br/>OPP-9813312   OPP-9813442   OPP-9813550<br/>DIBB, JACK   BALES, ROGER                BLAKE, DONALD<br/>UNIVERSITY OF NH  UNIVERSITY OF AZ  UNIVERSITY OF CA<br/><br/>OPP-9813441   OPP-9813549<br/>ALBERT, MARY                KAHL, JONATHAN<br/>USACREEL   UNIVERSITY OF WI<br/><br/>OPP-9813462   OPP-9813333<br/>DAVIDSON, CLIFF   CURRIE, LLOYD<br/>CARNEGIE MELLON UNIVERSITY NATIONAL INST. OF SCIENCE AND TECHNOLOGY<br/><br/><br/>The investigators propose to continue an atmospheric sampling program that was initiated in winter <br/>1997-98 with a pilot program at 10,600 feet altitude at the summit of the Greenland Ice Cap. The 1997-98 pilot project was the first attempt to measure atmospheric chemistry during the winter season and the first attempt by NSF to support a science team at the Summit station during winter conditions.  The scientific success of the pilot project and the logistics lessons learned prove that the proposed continuation of a winterover sampling program is a viable method for determining the variables that control the transfer of the atmospheric chemistry into the ice core record. The calibration of the atmospheric chemical record with the snowfall record will be used to determine how the atmospheric record is transferred into the ice record.  The ultimate goal is to interpret the past atmospheric chemistry using samples of the Greenland Ice Sheet Two (GISP2) project ice core that was collected previously at the site. The100,000 year annual record of the GISP2 ice core will provide the opportunity to examine the record of atmospheric changes from both natural and anthropogenic causes.<br/>"
"9907623","Investigation of Photochemical Transformations within Snow and their Effect on Snow and Atmospheric Composition","OPP","ARC Rsch Support & Logistics, ARCSS-Arctic System Science, ANS-Arctic Natural Sciences","09/01/1999","08/08/2001","Donald Blake","CA","University of California-Irvine","Continuing Grant","Jane V. Dionne","08/31/2002","$128,398.00","Nicola Blake","drblake@uci.edu","160 ALDRICH HALL","IRVINE","CA","926970001","9498247295","GEO","5205, 5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197    OPP-9907469  OPP-9907330<br/>HONRATH, RICHARD   DIBB, JACK  ALBERT, MARY<br/>MICH. TECH. UNIVERSITY   UNIVERSITY NH CRREL<br/><br/>OPP-9907376    OPP-9907623  OPP-9907434<br/>SHEPSON, PAUL   BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY   UC-IRVINE  UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow.  The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow.  The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past.  The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities.  The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere.<br/><br/>"
"1049021","Collaborative Research:  Type 1: LOI: L02170303: Arctic Climate Response to Decadal Changes in Radiative Forcing from Aerosols and Ozone","OPP","OFFICE OF MULTIDISCIPLINARY AC, CHEMISTRY PROJECTS, ANS-Arctic Natural Sciences","02/15/2011","02/04/2011","Daniel Jacob","MA","Harvard University","Standard Grant","William J. Wiseman, Jr.","01/31/2015","$477,787.00","","djacob@fas.harvard.edu","1033 MASSACHUSETTS AVE 5TH FL","CAMBRIDGE","MA","021385369","6174955501","GEO","1253, 1991, 5280","1079, 8012","$0.00","Current general circulation models (GCMs) have difficulty reproducing the rapid Arctic warming and sea ice loss observed over the past decades. One possible factor is that they do not properly represent the radiative forcings from aerosols and tropospheric ozone that could be particularly important in the Arctic. This EaSM Type 1 project will develop an improved understanding of the distributions and decadal trends of aerosols and ozone in the Arctic, including black carbon (BC) deposition fluxes and albedo effects for snow and sea ice, and will study the implications for Arctic climate change over the 1980-2010 period. It will build an interdisciplinary partnership between atmospheric chemists using the GEOS-Chem CTM and cryosphere scientists using CCSM4, to better describe aerosol-chemistry-climate interactions in the Community Earth System Model (CESM). The project will take advantage of intensive observations during the International Polar Year (IPY) to test and improve the GEOS-Chem representation of aerosols, ozone, and BC deposition fluxes in the Arctic. A 30-year GEOS-Chem simulation (1980-2010) with evolving sources from human activity and fires will be conducted and evaluated against long-term records. Aerosols, ozone, and BC deposition fluxes from GEOS-Chem will be input to CCSM4 to simulate Arctic radiative forcing and climate response over the 30-year period. Ensemble sensitivity simulations conducted with CCSM4 will diagnose the perturbations to temperature, sea ice, and atmospheric circulation associated with these radiative forcings. Knowledge gained from this project will be used to evaluate the simulation of Arctic aerosols, tropospheric ozone, and BC deposition fluxes within CESM. Fully coupled aerosol-chemistry-climate simulations of the 1980-2010 period will be conducted in CESM to assess Arctic climate response from aerosols and ozone and to investigate climate feedbacks.  This project will also provide policy analysts with information on the role of aerosols and tropospheric ozone in driving Arctic climate change.  Two graduate students will be trained in interdisciplinary environmental modeling."
"9907434","Investigation of Photochemical Tranformations within Snow and their Effect on Snow and Atmospheric Composition","OPP","ARCTIC SYSTEM SCIENCE PROGRAM, ARCTIC NATURAL SCIENCES","09/01/1999","08/21/2001","Cort Anastasio","CA","University of California-Davis","Continuing grant","Jane V. Dionne","08/31/2003","$214,970.00","","canastasio@ucdavis.edu","OR/Sponsored Programs","Davis","CA","956186134","5307547700","GEO","5219, 5280","0000, 1079, OTHR","$0.00","ABSTRACT<br/><br/>OPP-9907197    OPP-9907469  OPP-9907330<br/>HONRATH, RICHARD   DIBB, JACK  ALBERT, MARY<br/>MICH. TECH. UNIVERSITY   UNIVERSITY NH CRREL<br/><br/>OPP-9907376    OPP-9907623  OPP-9907434<br/>SHEPSON, PAUL   BLAKE, DONALD ANASTASIO, CORT<br/>PURDUE UNIVERSITY   UC-IRVINE  UC-DAVIS<br/><br/>OPP-9907314<br/>STEFFAN, CONRAD<br/>UNIVERSITY OF COLORADO<br/><br/>The PIs propose a field sampling program at the summit of the Greenland ice cap to examine the effects of energy from the sun on the chemistry of organic compounds contained in the interstitial air trapped in snow.  The results of the research will be used to determine if the chemistry of the air/snow changes through time in response to fluctuations in light energy penetrating the snow.  The study is critical to developing a method for interpreting ice core records for the history of atmospheric chemistry in the past.  The photochemical process under study could lead to more accurate interpretations of past atmospheric conditions and provide better estimates of both natural and anthropogenic impacts on the atmosphere from changing climate or human activities.  The results of the research will also provide evidence of the role of the Greenland ice sheet on modern atmospheric chemistry that will be critical to understanding how high-latitude processes affect the atmosphere.<br/><br/>"
